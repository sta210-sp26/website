---
title: "SLR: Mathematical models for inference cont'd"
author: "Prof. Maria Tackett"
date: "01-29-2026"
date-format: "MMMM DD, YYYY"
footer: "ðŸ”— [sta210-sp26.github.io](https://sta210-sp26.github.io)"
logo: "../images/logo.png"
format: 
  revealjs: 
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: true
    incremental: false 
    chalkboard: true
    include-before: [ '<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']
  html: 
    output-file: 06-slr-math-models-contd-notes.html
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r setup}
#| include: false

library(countdown)

knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = 0.618,
  fig.retina = 3,
  dpi = 300,
  out.width = "80%",
  fig.align = "center"
)
```

## Announcements

-   Lab 01 **due TODAY** at 11:59pm

-   [Statistics experience](../hw/stats-experience.html) due April 21

-   SSMU Mini DataFest - February 8

    -   See [Ed Discussion](https://edstem.org/us/courses/91299/discussion/7577398) for announcement

## Topics

-   Use mathematical models to

    -   conduct a hypothesis test for the slope

    -   construct confidence intervals for the slope

    -   construct intervals for predictions

## Computational setup

```{r packages}
#| echo: true
#| message: false

# load packages
library(tidyverse)   # for data wrangling and visualization
library(tidymodels)  # for modeling
library(openintro)   # for the duke_forest dataset
library(scales)      # for pretty axis labels
library(knitr)       # for pretty tables
library(kableExtra)  # also for pretty tables
library(patchwork)   # arrange plots

# set default theme and larger font size for ggplot2
ggplot2::theme_set(ggplot2::theme_bw(base_size = 20))
```

# From last class

## Mathematical representation of the model {.midi}

$$
\begin{aligned}
Y &= \text{Model} + \text{Error} \\[8pt]
&= f(X) + \epsilon \\[8pt]
&= E(Y|X) + \epsilon \\[8pt]
&= \beta_0 + \beta_1 X + \epsilon
\end{aligned}
$$

where the errors are independent and normally distributed:

-   **independent**: Knowing the error term for one observation doesn't tell you anything about the error term for another observation
-   **normally distributed**: $\epsilon \sim N(0, \sigma_\epsilon^2)$

## Mathematical representation, visualized {.midi}

$$
Y|X \sim N(\beta_0 + \beta_1 X, \sigma_\epsilon^2)
$$

::::: columns
::: {.column width="70%"}
![Image source: *Introduction to the Practice of Statistics (5th ed)*](images/05/regression.png)
:::

::: {.column width="30%"}
-   Mean: $\beta_0 + \beta_1 X$, the predicted value based on the regression model
-   Variance: $\sigma_\epsilon^2$, constant across the range of $X$
    -   How do we estimate $\sigma_\epsilon^2$?
:::
:::::

## Regression standard error

Once we fit the model, we can use the residuals to estimate the **regression standard error**, the average distance between the observed values and the regression line

$$
\hat{\sigma}_\epsilon = \sqrt{\frac{\sum_\limits{i=1}^n(y_i - \hat{y}_i)^2}{n-2}} = \sqrt{\frac{\sum_\limits{i=1}^ne_i^2}{n-2}}
$$

## Standard error of $\hat{\beta}_1$

The **standard error of** $\hat{\beta}_1$ quantifies the sampling variability in the estimated slopes

$$
SE_{\hat{\beta}_1} = \hat{\sigma}_\epsilon\sqrt{\frac{1}{(n-1)s_X^2}}
$$

. . .

```{r}
#| echo: false

df_fit <- lm(price ~ area, data = duke_forest)

tidy(df_fit) |>
  kable(digits = 2) |>
  row_spec(2, background = "#D9E3E4")
```

# Mathematical models for inference for $\beta_1$

## Hypothesis test for $\beta_1$

```{r}
#| echo: false
tidy(df_fit) |>
  kable(digits = 2) |>
  row_spec(2, background = "#D9E3E4")
```

$$
H_0: \beta_1 = 0 \hspace{2mm} \text{ vs }\hspace{2mm} \beta_1 \neq 0
$$

## Hypothesis test for $\beta_1$

```{r}
#| echo: false
tidy(df_fit) |>
  kable(digits = 2) |>
  row_spec(2, background = "#D9E3E4")
```

$$
T = \frac{\hat{\beta}_1 - 0}{SE_{\hat{\beta}_1}} = \frac{159.48 - 0}{18.17} = 8.78
$$

. . .

```{r}
2 * pt(q = 8.78, df = 96, lower.tail = FALSE)
```

## Hypothesis test for $\beta_1$

```{r}
#| echo: false
tidy(df_fit) |>
  kable(digits = 2) |>
  row_spec(2, background = "#D9E3E4")
```

<br>

-   The data provide convincing evidence that the population slope $\beta_1$ is different from 0.
-   The data provide convincing evidence of a linear relationship between area and price of houses in Duke Forest.

# Confidence intervals

## Confidence interval for the slope

$$
\text{Estimate} \pm \text{ (critical value) } \times \text{SE}
$$

. . .

$$
\hat{\beta}_1 \pm t^* \times SE_{\hat{\beta}_1}
$$

where $t^*$ is calculated from a $t$ distribution with $n-2$ degrees of freedom

## Confidence interval: Critical value

:::::::: columns
:::::: {.column width="60%"}
::: {.fragment fragment-index="1"}
```{r}
#| echo: true

# confidence level: 95%
qt(0.975, df = nrow(duke_forest) - 2)
```
:::

::: {.fragment fragment-index="2"}
```{r}
# confidence level: 90%
qt(0.95, df = nrow(duke_forest) - 2)
```
:::

::: {.fragment fragment-index="3"}
```{r}
# confidence level: 99%
qt(0.995, df = nrow(duke_forest) - 2)
```
:::
::::::

::: {.column width="40%"}
```{r}
#| out.width: "100%"
#| echo: false

normTail(M = c(-1.984984, 1.984984), df = nrow(duke_forest) - 2, col = "#D9E3E4")
text(x = 0, y = 0.04, labels = "95%", cex = 2, col = "#5B888C")
```
:::
::::::::

## 95% CI for the slope: Calculation

```{r}
#| echo: false
tidy(df_fit) |> 
  kable(digits = 2) |>
  row_spec(2, background = "#D9E3E4")
```

$$\hat{\beta}_1 = 159.48 \hspace{15mm} t^* = 1.98 \hspace{15mm} SE_{\hat{\beta}_1} = 18.17$$

. . .

$$
159.48 \pm 1.98 \times 18.17 = (123.50, 195.46)
$$

## 95% CI for the slope: Computation

```{r}
#| echo: true

tidy(df_fit, conf.int = TRUE, conf.level = 0.95) |> 
  kable(digits = 2)
```

# Intervals for predictions

## Intervals for predictions {.midi}

-   Suppose we want to answer the question *"What is the predicted sale price of a Duke Forest house that is 2,800 square feet?"*
-   We said reporting a single estimate for the slope is not wise, and we should report a plausible range instead
-   Similarly, reporting a single prediction for a new value is not wise, and we should report a plausible range instead

```{r}
#| fig.width: 10
#| echo: false

x_new <- 2800
y_hat_x_new <- predict(df_fit, new_data = tibble(area = x_new)) 

pred_x_new <- predict(df_fit, tibble(area = x_new))


ggplot(duke_forest, aes(x = area, y = price)) +
  geom_segment(
    x = x_new, xend = x_new, y = y_hat_x_new-600000, yend = y_hat_x_new+600000,
    color = "#CDDBDC", size = 4
  ) +
  geom_segment(
    x = x_new, xend = x_new, y = y_hat_x_new-400000, yend = y_hat_x_new+400000,
    color = "#ADC3C5", size = 4
  ) +
  geom_segment(
    x = x_new, xend = x_new, y = y_hat_x_new-200000, yend = y_hat_x_new+200000,
    color = "#7B9FA3", size = 4
  ) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "#8F2D56") +
#  geom_segment(
 #   x = x_new, xend = x_new, y = 0, yend = y_hat_x_new,
  #  linetype = "dashed", color = "#5B888C"
  #) +
 # geom_segment(
  #  x = 0, xend = x_new, y = y_hat_x_new, yend = y_hat_x_new,
   # linetype = "dashed", color = "#5B888C"
#  ) +
  annotate("point", x = x_new, y = pred_x_new, size = 2, color = "magenta") +
  annotate("point", x = x_new, y =pred_x_new, size = 5, shape = "circle open", color = "#5B888C", stroke = 2) +
  scale_x_continuous(labels = label_number()) +
  scale_y_continuous(labels = label_dollar(), limits = c(000000, 1500000)) +
  labs(
    x = "Area (square feet)", y = "Sale price",
    title = "Houses in Duke Forest"
    )
```

## Two types of predictions

1.  Prediction for the mean: "What is the average predicted sale price of Duke Forest houses that are 2,800 square feet?"

2.  Prediction for an individual observation: "What is the predicted sale price of a Duke Forest house that is 2,800 square feet?"

. . .

::: question
-   Which would you expect to be more variable? The average prediction or the prediction for an individual observation?

-   Based on your answer, how would you expect the widths of plausible ranges for these two predictions to compare?
:::

## Uncertainty in predictions

**Confidence interval for the mean outcome:** $$\large{\hat{y} \pm t_{n-2}^* \times \color{purple}{\mathbf{SE}_{\hat{\boldsymbol{\mu}}}}}$$

. . .

**Prediction interval for an individual observation:** $$\large{\hat{y} \pm t_{n-2}^* \times \color{purple}{\mathbf{SE_{\hat{y}}}}}$$

## Standard errors

**Standard error of the mean outcome:** $$SE_{\hat{\mu}} = \hat{\sigma}_\epsilon\sqrt{\frac{1}{n} + \frac{(x-\bar{x})^2}{\sum\limits_{i=1}^n(x_i - \bar{x})^2}}$$

. . .

**Standard error of an individual outcome:** $$SE_{\hat{y}} = \hat{\sigma}_\epsilon\sqrt{1 + \frac{1}{n} + \frac{(x-\bar{x})^2}{\sum\limits_{i=1}^n(x_i - \bar{x})^2}}$$

## Standard errors

**Standard error of the mean outcome:** $$SE_{\hat{\mu}} = \hat{\sigma}_\epsilon\sqrt{\frac{1}{n} + \frac{(x-\bar{x})^2}{\sum\limits_{i=1}^n(x_i - \bar{x})^2}}$$

**Standard error of an individual outcome:** $$SE_{\hat{y}} = \hat{\sigma}_\epsilon\sqrt{\mathbf{\color{purple}{\Large{1}}} + \frac{1}{n} + \frac{(x-\bar{x})^2}{\sum\limits_{i=1}^n(x_i - \bar{x})^2}}$$

## Confidence interval

The 95% **confidence interval** for the *mean* outcome:

```{r}
#| echo: true
new_house <- tibble(area = 2800)

predict(df_fit, new_house, interval = "confidence", level = 0.95) |>
  kable()
```

```{r}
#| echo: false
new_house_ci <- predict(df_fit, new_house, interval = "confidence", level = 0.95)
```

. . .

We are 95% confident that mean sale price of Duke Forest houses that are 2,800 square feet is between `r dollar(new_house_ci[2])` and `r dollar(new_house_ci[3])`.

## Prediction interval

The 95% **prediction interval** for an *individual* outcome:

```{r}
#| echo: true
new_house <- tibble(area = 2800)

predict(df_fit, new_house, interval = "prediction", level = 0.95) |>
  kable()
```

```{r}
#| echo: false
new_house_pi <- predict(df_fit, new_house, interval = "prediction", level = 0.95)
```

. . .

We are 95% confident that predicted sale price of a Duke Forest house that is 2,800 square feet is between `r dollar(new_house_pi[2])` and `r dollar(new_house_pi[3])`.

## Comparing intervals

```{r}
#| out.width: "100%"
#| fig.width: 10
#| echo: false

df_fit2 <- linear_reg() |>
  fit(price ~ area, data = duke_forest)

new_houses <- tibble(area = seq(1000, 6500, 50))
new_houses_ci <- predict(df_fit2, new_data = new_houses, type = "conf_int", level = 0.95) |> 
  mutate(
    area = new_houses$area,
    type = "Confidence interval"
    )
new_houses_pi <- predict(df_fit2, new_data = new_houses, type = "pred_int", level = 0.95) |> 
  mutate(
    area = new_houses$area,
    type = "Prediction interval"
    )
new_houses_int <- bind_rows(new_houses_ci, new_houses_pi)

ggplot(duke_forest, aes(x = area, y = price)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "#8F2D56") +
  geom_line(data = new_houses_int,
            aes(x = area, y = .pred_lower, linetype = type, color = type),
            size = 1) +
  geom_line(data = new_houses_int,
            aes(x = area, y = .pred_upper, linetype = type, color = type),
            size = 1) +
  scale_x_continuous(labels = label_number()) +
  scale_y_continuous(labels = label_dollar(), limits = c(000000, 1500000)) +
  scale_color_manual(values = c("#5B888C", "#888c5b")) +
  labs(
    x = "Area (square feet)", y = "Sale price",
    color = "Type of interval", linetype = "Type of interval",
    title = "Houses in Duke Forest"
    ) +
  theme(
    legend.position = c(0.2, 0.85)
  )
```

## Extrapolation

Using the model to predict for values outside the range of the original data is **extrapolation**.

. . .

:::::: columns
:::: {.column width="45%"}
::: question
Calculate the prediction interval for the sale price of a "tiny house" in Duke Forest that is 225 square feet.
:::
::::

::: {.column width="55%"}
![](images/06/tiny-house.jpeg){fig-alt="Black tiny house on wheels" fig-align="center"}
:::
::::::

. . .

*No, thanks!*

## Recap

-   Defined mathematical models to conduct inference for the slope

-   Used mathematical models to

    -   calculate confidence interval for the slope

    -   conduct a hypothesis test for the slope

    -   construct intervals for predictions
