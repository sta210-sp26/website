[
  {
    "objectID": "labs/lab-06.html",
    "href": "labs/lab-06.html",
    "title": "Lab 06: Multinomial logistic regression",
    "section": "",
    "text": "ImportantDue date\n\n\n\nThis lab is due on Tuesday, April 15 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your team’s GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-1",
    "href": "labs/lab-06.html#exercise-1",
    "title": "Lab 06: Multinomial logistic regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nLet’s begin by doing the exploratory data analysis. Univariate and bivariate plots are shown below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWrite two observations from the univariate EDA.\nWrite two observations from the bivariate EDA.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-2",
    "href": "labs/lab-06.html#exercise-2",
    "title": "Lab 06: Multinomial logistic regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nMake all the variables factor variable types. Then, split the data into training (75%) and test (25%) sets. Use seed 210.\nHow many observations are in the training set?",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-3",
    "href": "labs/lab-06.html#exercise-3",
    "title": "Lab 06: Multinomial logistic regression",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nBriefly explain a multinomial logistic regression model is an appropriate model choice for predicting id using lineup, weapon and feature.\nUse the training data to fit a multinomial logistic model using only the main effects for lineup , weapon, and feature. Neatly display the model using 3 digits.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-4",
    "href": "labs/lab-06.html#exercise-4",
    "title": "Lab 06: Multinomial logistic regression",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nWhat is the baseline category for the response variable?\nWhat experimental conditions are described by the intercept?\nInterpret the coefficients of lineup for each part of the model in terms of the odds.\nUse the coefficients and inferential statistics to describe the association between lineup and id.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-5",
    "href": "labs/lab-06.html#exercise-5",
    "title": "Lab 06: Multinomial logistic regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nYou are considering a model that includes all possible interactions between the predictors lineup , weapon, and feature . You will use 5-fold cross validation to choose between the main effects model fit in Exercise 3 and the model with interaction effects.\n\n\n\n\n\n\nTip\n\n\n\nSee Cross Validation notes for relevant code.\n\n\n\nUse the training data and seed 210 to create 5 folds. How many observations are in the assessment set for each fold?\nFit the main effects model on the 5 folds.\nWhat is the average accuracy across all folds? What is the average AUC?",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-6",
    "href": "labs/lab-06.html#exercise-6",
    "title": "Lab 06: Multinomial logistic regression",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nFit the interaction model on the 5 folds from the previous exercise.\nWhat is the average accuracy across all folds? What is the average AUC?\nBased on the cross validation results, do you choose the main effects model or the model with interactions? Briefly explain your response.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-06.html#exercise-7",
    "href": "labs/lab-06.html#exercise-7",
    "title": "Lab 06: Multinomial logistic regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nIf needed, fit the model selected in the previous exercise on the full training data.\nNext, use the testing data to predict the classes of id, and make a confusion matrix of the actual versus predicted classes of id.\nLastly, use the confusion matrix to comment on the model performance.\n\n\n\n\n\n\nTip\n\n\n\nBelow is template code to compute predicted classes on a test set:\n\npred_class &lt;- predict(model_name, test_set, type = \"class\")\n\nSee Multinomial Logistic Regression: Inference + Prediction notes for additional help with code.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you’re having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you’ll find an entry called Container Manager (CMGR Coursework Containers).\n\nIf the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the course forum to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots).",
    "crumbs": [
      "Computing",
      "Troubleshooting"
    ]
  },
  {
    "objectID": "website-files/about.html",
    "href": "website-files/about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "project-draft.html",
    "href": "project-draft.html",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Thursday, February 13\nProject proposal \nExploratory data analysis \nPresentation + Presentation comments \nAnalysis draft + peer review \nWritten report \nProject highlights \nReproducibility + organization \nFinal project survey"
  },
  {
    "objectID": "project-draft.html#project-milestones",
    "href": "project-draft.html#project-milestones",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Thursday, February 13\nProject proposal \nExploratory data analysis \nPresentation + Presentation comments \nAnalysis draft + peer review \nWritten report \nProject highlights \nReproducibility + organization \nFinal project survey"
  },
  {
    "objectID": "project-draft.html#introduction",
    "href": "project-draft.html#introduction",
    "title": "Final project",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio using Quarto and GitHub, and your analysis and written report must be reproducible.\n\nLogistics\nYou will work on the project with your lab groups. The primary deliverables for the project are\n\nan in-person presentation about the exploratory data analysis and initial modeling\na written, reproducible final report detailing your analysis\na summary of your project highlights to share with the class\na GitHub repository containing all work from the project\n\nThere are intermediate milestones and peer review assignments throughout the semester to help you work towards the final deliverables."
  },
  {
    "objectID": "project-draft.html#research-topics",
    "href": "project-draft.html#research-topics",
    "title": "Final project",
    "section": "Research topics",
    "text": "Research topics\nThe goal of this milestone is to discuss topics and develop potential research questions your team is interested in investigating for the project. You are only developing ideas at this point; you do not need to have a data set identified at this point.\nDevelop three potential research topics. Include the following for each topic:\n\nA brief description of the topic\nA statement about your motivation for investigating this topic.\nThe potential audience(s), i.e., who might be most interested in this research?\nTwo or three potential research questions you could analyze about this topic.\nIdeas about the type of data you might use to answer this question or potential data sets you’re interested in using. [Note: The goal is to generate ideas at this point, so it is fine if you have not identified any particular data sets at this point.]\n\n\nSubmission\nWrite your responses in research-topics.qmd in your team’s project GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Thursday, February 13 at 11:59pm."
  },
  {
    "objectID": "project-draft.html#project-proposal",
    "href": "project-draft.html#project-proposal",
    "title": "Final project",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is for your team to identify the data set you’re interested in analyzing to investigate one of your potential research questions. You will also do some preliminary exploration of the response variable and begin thinking about the modeling strategy. If you’re unsure where to find data, you can use the list of potential data sources on the Tips + resources page as a starting point.\n\n\n\n\n\n\nImportant\n\n\n\nYou must the data set(s) in the proposal for the final project, unless instructed otherwise when given feedback.\n\n\nThe data set must meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.\n\ne.g., identifier variables such as “name”, “ID number”, etc. are not useful predictor variables.\ne.g., if you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nMay not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n\n\n\n\n\n\nWarningTypes of data sets to avoid\n\n\n\n\nData that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nData sets in which there is no information about how the data were originally collected\nData sets in which there are missing or unclear definitions about the observations and/or variables\n\n\n\nAsk a member of the teaching team if you’re unsure whether your data set meets the criteria.\nThe proposal will include the following sections:\n\nSection 1: Introduction\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the Research Questions milestone.\n\n\n\nAn introduction to the subject matter you’re investigating (citing any relevant literature)\nStatement of a well-developed research question.\nThe motivation for your research question and why it is important\nYour team’s hypotheses regarding the research question\n\nThis is a narrative about what you think regarding the research question, not formal statistical hypotheses.\n\n\n\n\nSection 2: Data description\n\nThe source of the data set\nA description of when and how the data were originally collected (by the original data curator, not necessarily how you found the data)\nA description of the observations and general characteristics being measured\n\n\n\nSection 3: Initial exploratory data analysis\n\nDescription of data cleaning you need to do to prepare for analysis (can focus on the response variable for now), such as joining data sets, imputing missing values, variable transformation, creating a new variable, etc.\nVisualizations, summary statistics, and narrative to describe the distribution of the response variable.\n\n\n\nSection 4: Analysis approach\n\na description of the potential predictor variables of interest\nregression model technique (multiple linear regression for quantitative response variable or logistic regression for a categorical response variable)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of the data folder. You do not need to include the data dictionary in the PDF document.\n\n\nSubmission\nWrite your narrative and analysis for Sections 1 - 4 in the proposal.qmd file in your team’s GitHub repo. Put the data set and the data dictionary in the data folder in the repo. Push the qmd and rendered pdf documents to GitHub by the deadline.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages.\nThe proposal is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.\n\nExcellent (9 - 10 points) : All required elements are completed and are accurate. The data set meets the requirements (or the team has otherwise discussed the data with Professor Tackett) and the data do not pose obvious violations to the modeling assumptions. There is a thoughtful and comprehensive description of the data and exploration of the response variable as described above. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong (7 - 8 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.\nSatisfactory (5 - 6 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (4 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling."
  },
  {
    "objectID": "project-draft.html#eda",
    "href": "project-draft.html#eda",
    "title": "Final project",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the previous milestones.\n\n\nThe purpose of this milestone is begin exploring the data and get early feedback on your data and analysis. You will submit a draft of the beginning of your report that includes the introduction and exploratory data analysis, with an emphasis on the EDA. It will also help you prepare for the presentation of the exploratory data analysis results.\nBelow is a brief description of the sections to include in this step:\n\nIntroduction\nThis section includes an introduction to the project motivation, background, data, and research question.\n\n\nExploratory data analysis\nThis section includes the following:\n\nDescription of the data set and key variables.\nExploratory data analysis of the response variable and key predictor variables.\n\nUnivariate EDA of the response and key predictor variables.\nBivariate EDA of the response and key predictor variables\nPotential interaction effects.\n\n\n\n\nSubmission\nWrite your draft introduction and exploratory data analysis in the written-report.qmd file in your team’s GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc. with code, warnings, and messages suppressed is about about 4 - 6 pages.\n\n\n\n\n\n\nTip\n\n\n\nYou can suppress code, warnings, and messages by including the following in the YAML:\nexecute: \n  echo: false\n  message: false\n  warning: false\n\n\nThe exploratory data analysis is worth 15 points and will be graded based on accurately and comprehensively addressing the criteria stated above, along with incorporating the feedback from the proposal. Points will be assigned based on a holistic review of the exploratory data analysis.\n\nExcellent (14 - 15 points) : All required elements are completed and are accurate. There is a thorough exploration of the data as described above, and the team has demonstrated a careful and thoughtful approach exploring the data and preparing it for analysis. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong: (11 - 13 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some revision of the work required before team is ready for modeling.\nSatisfactory (8 - 10 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (7 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling."
  },
  {
    "objectID": "project-draft.html#presentation",
    "href": "project-draft.html#presentation",
    "title": "Final project",
    "section": "Presentation",
    "text": "Presentation\n\n\n\n\n\n\nImportant\n\n\n\nPresentations will take place in class during labs. Presentation order will be announced in advance.\n\n\nYour team will do an in-person presentation that summarizes and showcases the work you’ve done on the project thus far. Because the presentations will take place while you’re still working on the project, it will also be an opportunity to receive feedback and suggestions as well as provide feedback to other teams. The presentation will focus on introducing the subject matter and research question, showcase key results from the exploratory data analysis, and discuss primary modeling strategies and/or results. The presentation should be supported by slides that serve as a brief visual addition to the presentation. The presentation and slides will be graded for content and clarity.\nYou can create your slides with any software you like (e.g., Keynote, PowerPoint, Google Slides, etc.). You can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\nThe presentation is expected to be between 5 to 8 minutes. It may not exceed 8 minutes, due to the limited time during lab.\nEvery team member is expected to speak in the presentation. Part of the grade will be whether every team member had a meaningful speaking role in the presentation.\n\nSlides\nThe slide deck should have no more than 6 content slides + 1 title slide to ensure you have enough time to discuss each slide. s Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the subject, motivation, and research question\nSlide 2: Introduce the data set\nSlide 3 - 4: Highlights from the EDA (be sure to include EDA for the response variable!)\nSlide 5: Initial modeling strategies / results\nSlide 6: Next steps and any questions you’d like to get feedback on\n\n\n\nSubmission\nYou can submit the presentation slides in two ways:\n\nPut a PDF of the slides or Quarto slides in the presentation folder in your team’s GitHub repo.\nPut the URL to your slides in the README of the presentation folder. If you share the URL, please make sure permissions are set so Prof. Tackett can view the slides.\n\n\n\n\n\n\n\nImportant\n\n\n\nSlides must be submitted by the start of your lab on the day of presentations. We will use a classroom computer for the presentations.\n\n\n\n\nGrading\nThe presentation is worth points. It will be graded based on the following:\n\nContent: The team told a unified story that clearly introduced the subject matter, research question, and exploration of the data.\nSlides: The presentation slides were organized, included clear and informative visualizations, and were easily readable.\nPresentation: The team’s communication style was clear and professional. The team divided the time well and stayed within the 8 minute time limit, with each team member making a meaningful contribution to the presentation.\n\n80% of the presentation grade will be the average of the teaching team scores and 20% will be the average of the peer scores."
  },
  {
    "objectID": "project-draft.html#presentation-comments",
    "href": "project-draft.html#presentation-comments",
    "title": "Final project",
    "section": "Presentation comments",
    "text": "Presentation comments\n\n\n\n\n\n\nImportant\n\n\n\nClick here to see the teams you’re scoring and a link to the feedback form.\nThis portion of the project is worth 2 points and will be assessed individually.\n\n\nYou will provide feedback on two teams’ presentations. The assigned teams and link to the feedback form will be available in advance of the presentations. Please provide all scores and comments by the end of the lab session. There will be a few minutes between each presentation to submit scores and comments.\nThe grade will be based on submitting the scores and comments for both of your assigned teams by the end of the presentation day, November 11."
  },
  {
    "objectID": "project-draft.html#draft-report-peer-review",
    "href": "project-draft.html#draft-report-peer-review",
    "title": "Final project",
    "section": "Analysis + peer review",
    "text": "Analysis + peer review\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\n\nDraft report\nWrite the draft in the written-report.qmd file in your project repo.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the body of the report, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model.\n\n\nGrading\nThe draft will be graded based on whether there is demonstration of a reasonable attempt at each of the sections described below in the written report file in the GitHub repo by the deadline.\n\n\n\nPeer review\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 221 is no exception. Each lab team will be assigned two other teams’ projects to review. Each team should push their draft to their GitHub repo by 10 am on the day their lab’s draft is due. The lab that week will be dedicated to the peer review, so your team will have time to review and provide quality feedback to two other teams.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided in the repo.\n\nSteps for peer review\n\n\n\n\n\n\nImportantPeer review assignments\n\n\n\nClick here to see the teams you’re peer reviewing.You’ll spend about 30 minutes reviewing each project.\n\n\n\nWhen you get to lab, you should have access to the GitHub repos for the teams you’re reviewing. In GitHub, search the repositories for project, and you should see the repos for the projects you’re reviewing. You will be able to read the files in the repo and post issues, but you cannot push changes to the repo. You will have access to the repo until the deadline for the peer review.\nYou may choose to all work on both peer reviews or have some team members focus on a single peer review. Either way there will be one peer review grade assigned per team.\nFor each team you’re reviewing:\n\nOpen that team’s repo, read the project draft, and browse the rest of the repo.\nGo to the Issues tab in that repo, click on New issue, and click on Get started for the Peer Review issue. Write your responses to the prompts in the issue. You will answer the the following questions:\n\nDescribe the goal of the project.\nDescribe the data set used in the project. What are the observations in the data? What is the source of the data? How were the data originally collected?\nConsider the exploratory data analysis (EDA). Describe one aspect of the EDA that is effective in helping you understand the data. Provide constructive feedback on how the team might improve the EDA.\nDescribe the statistical methods, analysis approach, and discussion of model assumptions, diagnostics, model fit.\nProvide constructive feedback on how the team might improve their analysis. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but also feel free to comment on aspects beyond the modeling.\nProvide constructive feedback on the interpretations and initial conclusion. What is most effective in the presentation of the results? What additional detail can the team provide to make the results and conclusions easier for the reader to understand?\nWhat aspect of this project are you most interested in and think would be interesting to highlight in the written report?\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?\n\n\n\n\n\nGrading\nThe peer review will be graded on the extent to which each comprehensively and constructively addresses the components on the peer review form. There will be one peer review grade per team."
  },
  {
    "objectID": "project-draft.html#written-report",
    "href": "project-draft.html#written-report",
    "title": "Final project",
    "section": "Written report",
    "text": "Written report\n\n\n\n\n\n\nImportant\n\n\n\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the code chunks are not visible and all messages and warnings are suppressed.\n\n\n\nYou will submit the PDF of your final report on GitHub.\nThe PDF you submit must match the .qmd in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including tables and visualizations, must be no more than 10 pages long. There is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will overwhelmingly be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\n\n\nResults\n\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report."
  },
  {
    "objectID": "project-draft.html#project-highlights",
    "href": "project-draft.html#project-highlights",
    "title": "Final project",
    "section": "Project highlights",
    "text": "Project highlights"
  },
  {
    "objectID": "project-draft.html#reproducibility-organization",
    "href": "project-draft.html#reproducibility-organization",
    "title": "Final project",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\nproposal.qmd & proposal.pdf: Project proposal\nresearch-questions.qmd & research-questions.pdf: Proposed research questions\n/data: Folder that contains the data set for the final project.\nproject.Rproj: File specifying the RStudio project\n/presentation: Folder with the presentation slides or link to slides.\n.gitignore: File that lists all files that are in the local RStudio project but not the GitHub repo\n/.github: Folder for peer review issue template\nAny other files should be neatly organized into clearly labeled folders.\n\nUpdate the README of the project repo with your project title and a few sentences (~ 2 -5) describing your final project.\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-draft.html#final-project-survey",
    "href": "project-draft.html#final-project-survey",
    "title": "Final project",
    "section": "Final project survey",
    "text": "Final project survey"
  },
  {
    "objectID": "project-draft.html#peer-teamwork-evaluation",
    "href": "project-draft.html#peer-teamwork-evaluation",
    "title": "Final project",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nThere will be an opportunity to provide feedback to Professor Tackett about each team member’s contribution to the project. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly."
  },
  {
    "objectID": "project-draft.html#overall-grading",
    "href": "project-draft.html#overall-grading",
    "title": "Final project",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nResearch topics\n3 pts\n\n\nProject proposal\n5 pts\n\n\nExploratory data analysis\n10 pts\n\n\nPresentation\n10 pts\n\n\nPresentation comments\n2 pts\n\n\nDraft report + peer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nProject highlights\n15 pts\n\n\nReproducibility + organization\n3 pts\n\n\nProject survey\n2 pts\n\n\n\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort."
  },
  {
    "objectID": "project-draft.html#late-work-policy",
    "href": "project-draft.html#late-work-policy",
    "title": "Final project",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.\nBe sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "project-tips.html",
    "href": "project-tips.html",
    "title": "Final project tips + resources",
    "section": "",
    "text": "Data sources\n\nSome resources that may be helpful as you find data:\n\nFiveThirtyEight data\nTidyTuesday\nData Is Plural\nR Data Sources for Regression Analysis\n\n\n\nOther data repositories\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies\n\n\n\n\nTips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your Qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.\n\n\n\nFormatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\nAn alternative approach is to add the following code to the YAML:\n\nexecute:\n  echo: false\n  warning: false\n  message: false\n\n\n\n\nHeaders\n\nUse headers to clearly label each section. Make sure there is a space between the last # and the title, so the header renders correctly. For example, ###Section Title will not render as header, but ### Section Title will.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\n\nResize plots and figures, so you have more space for the narrative.\n\nResize individual figures: Use the code chunk header {r plot1, fig.height = 3, fig.width = 5}, replacing plot1 with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig_width and fig_height options in your YAML header as shown below:\n\n\n\n---\ntitle: \"Your title\"\nauthor: \"Your names\"\nformat:\n  pdf:\n    fig-width: 7\n    fig-height: 5\n---\nReplace the height and width values with values appropriate for your write up.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\n\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\nIf you’re using base R function, i.e. when using the emplogit functions, put the code par(mfrow = c(rows,columns)) before the code to make the plots. For example, par(mfrow = c(2,3)) will arrange plots in a grid with 2 rows and 3 columns.\n\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\nUse coord_flip() to flip the x and y axes on the plot. This is useful if you a bar plot with an x-axis that is difficult to read due to overlapping text.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg |&gt;\n  count(manufacturer) |&gt;\n  mutate(manufacturer = str_to_title(manufacturer)) |&gt;\n  ggplot(aes(x = fct_reorder(manufacturer,n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  coord_flip() +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_bw() \n\n\n\n\n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel &lt;- lm(mpg ~ hp, data = mtcars)\ntidy(model) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document.\n\n\n\n\nAdditional resources\n\nExploring RStudio’s Visual Markdown Editor\nR for Data Science\nQuarto documentation:\n\nQuarto PDF Basics\nPresentations in Quarto\n\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "computing-r-resources.html",
    "href": "computing-r-resources.html",
    "title": "Resources for learning R",
    "section": "",
    "text": "Below are freely available resources to learn or review the following in R: data wrangling, data visualization, Quarto basics.",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#in-depth-introduction",
    "href": "computing-r-resources.html#in-depth-introduction",
    "title": "Resources for learning R",
    "section": "In-depth introduction",
    "text": "In-depth introduction\nCoursera: Data Visualization and Transformation with R by Mine Çetinkaya-Rundel and Elijah Meyer\n\nIncludes videos, readings, practice exercise, quizzes, and other resources\nYou can select content within the modules you want to complete.\nFocus on Modules 2 and 3. Review the content in Module 1 as needed.s\nClick here for instructions to register for Coursera for free as a Duke student",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#in-depth-review",
    "href": "computing-r-resources.html#in-depth-review",
    "title": "Resources for learning R",
    "section": "In-depth review",
    "text": "In-depth review\nData Science with R videos by Mine Çetinkaya-Rundel and Elijah Meyer\n\nVideos from the data science Coursera course\nFocus on videos on visualizing and summarizing data\nYou need to join the Coursera course to access the files from the code along videos.\n\nLearn R: An interactive introduction to data analysis with R\n\nHands-on tutorial that can be completed within the site (no RStudio required)\nFocus on Chapters 4 - 6",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#shorter-review",
    "href": "computing-r-resources.html#shorter-review",
    "title": "Resources for learning R",
    "section": "Shorter review",
    "text": "Shorter review\nR for Data Science (2nd ed) by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund\n\nFocus on Chapters 1 - 3, 10",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#additional-resources",
    "href": "computing-r-resources.html#additional-resources",
    "title": "Resources for learning R",
    "section": "Additional resources",
    "text": "Additional resources\n\nTidy Modeling with R by Max Kuhn & Julia Silge\nPosit Cheatsheets\nR workshops by Duke Center for Data and Visualization Sciences",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "ae/ae-01-movies.html",
    "href": "ae/ae-01-movies.html",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "",
    "text": "Important\n\n\n\nFor this AE, you will discuss the questions in groups and submit answers on Ed Discussion. This AE does not count towards the Application Exercise grade.\nWe will look at the relationship between budget and revenue for movies made in the United States in 1986 to 2020. The dataset is created based on data from the Internet Movie Database (IMDB).\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(viridis)\nlibrary(DT)"
  },
  {
    "objectID": "ae/ae-01-movies.html#data",
    "href": "ae/ae-01-movies.html#data",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Data",
    "text": "Data\nThe movies data set includes basic information about each movie including budget, genre, movie studio, director, etc. A full list of the variables may be found here.\n\nmovies &lt;- read_csv(\"https://raw.githubusercontent.com/danielgrijalva/movie-stats/master/movies.csv\")\n\nView the first 10 rows of data.\n\nmovies |&gt;\n  slice(1:10)\n\n# A tibble: 10 × 15\n   name   rating genre  year released score  votes director writer star  country\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;  \n 1 The S… R      Drama  1980 June 13…   8.4 9.27e5 Stanley… Steph… Jack… United…\n 2 The B… R      Adve…  1980 July 2,…   5.8 6.5 e4 Randal … Henry… Broo… United…\n 3 Star … PG     Acti…  1980 June 20…   8.7 1.20e6 Irvin K… Leigh… Mark… United…\n 4 Airpl… PG     Come…  1980 July 2,…   7.7 2.21e5 Jim Abr… Jim A… Robe… United…\n 5 Caddy… R      Come…  1980 July 25…   7.3 1.08e5 Harold … Brian… Chev… United…\n 6 Frida… R      Horr…  1980 May 9, …   6.4 1.23e5 Sean S.… Victo… Bets… United…\n 7 The B… R      Acti…  1980 June 20…   7.9 1.88e5 John La… Dan A… John… United…\n 8 Ragin… R      Biog…  1980 Decembe…   8.2 3.30e5 Martin … Jake … Robe… United…\n 9 Super… PG     Acti…  1980 June 19…   6.8 1.01e5 Richard… Jerry… Gene… United…\n10 The L… R      Biog…  1980 May 16,…   7   1   e4 Walter … Bill … Davi… United…\n# ℹ 4 more variables: budget &lt;dbl&gt;, gross &lt;dbl&gt;, company &lt;chr&gt;, runtime &lt;dbl&gt;"
  },
  {
    "objectID": "ae/ae-01-movies.html#analysis",
    "href": "ae/ae-01-movies.html#analysis",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Analysis",
    "text": "Analysis\nWe begin by looking at how the average gross revenue (gross) has changed over time. Since we want to visualize the results, we will choose a few genres of interest for the analysis.\n\ngenre_list &lt;- c(\"Comedy\", \"Action\", \"Animation\", \"Horror\")\n\n\nmovies |&gt;\n  filter(genre %in% genre_list) |&gt; \n  group_by(genre,year) |&gt;\n  summarise(avg_gross = mean(gross)) |&gt;\n  ggplot(mapping = aes(x = year, y = avg_gross, color=genre)) +\n    geom_point() + \n    geom_line() +\n    ylab(\"Average Gross Revenue (in US Dollars)\") +\n    ggtitle(\"Gross Revenue Over Time\") +\n    scale_color_viridis_d()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat do you observe from the plot?\n\n\n\nNext, let’s see the relationship between a movie’s budget and its gross revenue.\n\nmovies |&gt;\n  filter(genre %in% genre_list, budget &gt; 0) |&gt; \n  ggplot(mapping = aes(x=log(budget), y = log(gross), color=genre)) +\n  geom_point() +\n  geom_smooth(method=\"lm\",se=FALSE) + \n  xlab(\"Log-transformed Budget\")+\n  ylab(\"Log-transformed Gross Revenue\") +\n  facet_wrap(~ genre) + \n  scale_color_viridis_d()"
  },
  {
    "objectID": "ae/ae-01-movies.html#exercises",
    "href": "ae/ae-01-movies.html#exercises",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Exercises",
    "text": "Exercises\n\nSuppose we fit a regression model for each genre that uses budget to predict gross revenue. What are the signs of the correlation between budget and gross and the slope in each regression equation?\nSuppose we fit the regression model from the previous question. Which genre would you expect to have the smallest residuals, on average (residual = observed revenue - predicted revenue)?\nPost your response on ED Discussion.\nhttps://edstem.org/us/courses/70992/discussion/5951333\n[Time permitting] Discuss the following: Notice in the graph above that budget and gross are log-transformed. Why are the log-transformed values of the variables displayed rather than the original values (in U.S. dollars)? Post your group’s response in the AE 01 Movie Budgets comments on Ed Discussion."
  },
  {
    "objectID": "ae/ae-01-movies.html#references",
    "href": "ae/ae-01-movies.html#references",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "References",
    "text": "References\n\ngithub.com/danielgrijalva/movie-stats\nInternet Movie Database"
  },
  {
    "objectID": "ae/ae-01-movies.html#appendix",
    "href": "ae/ae-01-movies.html#appendix",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of genres in the data set:\n\nmovies |&gt; \n  arrange(genre) |&gt; \n  select(genre) |&gt;\n  distinct() |&gt;\n  datatable()"
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html",
    "href": "ae/ae-10-logistic-compare.html",
    "title": "AE 10: Comparing logistic regression models",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-10 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE."
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#packages",
    "href": "ae/ae-10-logistic-compare.html#packages",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#response-to-leukemia-treatment",
    "href": "ae/ae-10-logistic-compare.html#response-to-leukemia-treatment",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Response to Leukemia treatment",
    "text": "Response to Leukemia treatment\nToday’s data is from a study where 51 untreated adult patients with Acute Myeloid Leukemia who were given a course of treatment, and they were assessed as to their response to the treatment.1\nThe goal of today’s analysis is to use pre-treatment factors to predict how likely it is a patient will respond to the treatment.\nWe will use the following variables:\n\nAge: Age at diagnosis (in years)\nSmear: Differential percentage of blasts\nInfil: Percentage of absolute marrow leukemia infiltrate\nIndex: Percentage labeling index of the bone marrow leukemia cells\nBlasts: Absolute number of blasts, in thousands\nTemp: Highest temperature of the patient prior to treatment, in degrees Fahrenheit\nResp: 1 = responded to treatment or 0 = failed to respond\n\n\nleukemia &lt;- read_csv(\"data/leukemia.csv\") |&gt;\n  mutate(Resp = factor(Resp))"
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#comparing-models",
    "href": "ae/ae-10-logistic-compare.html#comparing-models",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Comparing models",
    "text": "Comparing models\n\nConsider a model with all the pre-treatment variables: Age, Smear, Infil, Index, Blasts and Temp. Fit a model using these six variables to predict whether a patient responded to the treatment. Call the model full_model. Display the model.\n\n\n# add code\n\n\nBased on the model, which pre-treatment variables are statistically significant using a threshold of \\(\\alpha = 0.05\\)? (We will talk more about inference for logistic regression coefficients in an upcoming lecture.)\nFit a model that only includes the statistically significant predictors. Call the model reduced_model.\n\n\n# add code\n\n\nUse a drop-in-deviance test to compare a model that includes only the significant predictors to the full model. Which model do you choose based on the results of this test?\n\n\n# add code\n\n\nIs your choice based on AIC consistent with your choice from the previous exercise? What about a choice based on BIC?\n\n\n# add code"
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#submission",
    "href": "ae/ae-10-logistic-compare.html#submission",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#footnotes",
    "href": "ae/ae-10-logistic-compare.html#footnotes",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe data set is from the Stat2Data R package. This AE is adapted from exercises in Stat 2.↩︎"
  },
  {
    "objectID": "ae/ae-06-model-compare.html",
    "href": "ae/ae-06-model-compare.html",
    "title": "AE 06: Model comparison",
    "section": "",
    "text": "Important\n\n\n\nRender, commit, and push your responses to GitHub by the end of class.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#data",
    "href": "ae/ae-06-model-compare.html#data",
    "title": "AE 06: Model comparison",
    "section": "Data",
    "text": "Data\nWhich variables help us predict the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.\nThe variables we’ll focus on for this analysis are\n\nTip: amount of the tip\nParty: number of people in the party\nMeal: Time of day (Lunch, Dinner, Late Night)\nAge: Age category of person paying the bill (Yadult, Middle, SenCit)\nDay: Day of the week (includes every day but Monday)\n\nView the data set to see the remaining variables.\n\ntips &lt;- read_csv(\"data/tip-data.csv\")"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-1",
    "href": "ae/ae-06-model-compare.html#exercise-1",
    "title": "AE 06: Model comparison",
    "section": "Exercise 1",
    "text": "Exercise 1\nSplit the data into training (80%) and testing (20%) sets. Use seed 2025."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-2",
    "href": "ae/ae-06-model-compare.html#exercise-2",
    "title": "AE 06: Model comparison",
    "section": "Exercise 2",
    "text": "Exercise 2\nUse the training data to fit a model using Party, Age, and Meal to predict tips. Compute the \\(R^2\\) and \\(Adj. R^2\\) for this model."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-3",
    "href": "ae/ae-06-model-compare.html#exercise-3",
    "title": "AE 06: Model comparison",
    "section": "Exercise 3",
    "text": "Exercise 3\nNow fit a model predicting tips using Party, Age, and Meal, such that the effect of party can differ by Meal. Compute \\(R^2\\) and \\(Adj. R^2\\) for this model."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-4",
    "href": "ae/ae-06-model-compare.html#exercise-4",
    "title": "AE 06: Model comparison",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nWhich model do you choose - the model from Exercise 2 or Exercise 3? Why?\nCompute RMSE for the selected model."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-5",
    "href": "ae/ae-06-model-compare.html#exercise-5",
    "title": "AE 06: Model comparison",
    "section": "Exercise 5",
    "text": "Exercise 5\nNow let’s use the testing data to assess the performance of the model selected in Exercise 4.\n\nCompute the predicted tips for the testing data. Add the predictions to the testing data set.\nCompute RMSE and \\(R^2\\) for the testing data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-6",
    "href": "ae/ae-06-model-compare.html#exercise-6",
    "title": "AE 06: Model comparison",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nHow do RMSE compare between the training and testing data?\nHow does \\(R^2\\) compare between the training and testing data?\nIs this what you expect? Why?"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-7",
    "href": "ae/ae-06-model-compare.html#exercise-7",
    "title": "AE 06: Model comparison",
    "section": "Exercise 7",
    "text": "Exercise 7\nWhy can we use \\(R^2\\) as an assessment of performance on the testing data even if we can’t use it to compare models?"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#to-submit-the-ae",
    "href": "ae/ae-06-model-compare.html#to-submit-the-ae",
    "title": "AE 06: Model comparison",
    "section": "To submit the AE:",
    "text": "To submit the AE:\n\n\n\n\n\n\nImportant\n\n\n\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-11-multinomial.html",
    "href": "ae/ae-11-multinomial.html",
    "title": "AE 11: Multinomial logistic regression",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-10 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE."
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-1",
    "href": "ae/ae-11-multinomial.html#exercise-1",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nCreate a plot to visualize the relationship between the response, viewcat and the primary variable of interest in this analysis, viewenc. What do you observe from the plot?"
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-2",
    "href": "ae/ae-11-multinomial.html#exercise-2",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nCreate a plot to visualize the relationship between the response, viewcat and age. What do you observe from the plot?"
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-3",
    "href": "ae/ae-11-multinomial.html#exercise-3",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nFit a model using the ageCent and viewenc to understand the odds a child is in a given category of viewcat. Display the model including 95% confidence intervals for the coefficients."
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-4",
    "href": "ae/ae-11-multinomial.html#exercise-4",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nWhat is the baseline category for viewcat? What is the baseline category for viewenc?\nInterpret the intercept associated with the odds of a child being in the category viewcat == 2 versus the baseline.\nInterpret the effect of age in terms of the odds of a child being in the category viewcat == 2 versus the baseline. Based on the confidence interval for the coefficient, is the numeric predictor a statistically significant predictor of viewership?"
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-5",
    "href": "ae/ae-11-multinomial.html#exercise-5",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nShould the interaction between ageCent and viewenc be included in the model? Show any analysis used to make your conclusion."
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-6",
    "href": "ae/ae-11-multinomial.html#exercise-6",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nThe primary objective of the experiment was to understand the effect of encouragement on viewership. Does encouragement have a significant effect on viewership after adjusting for age? If so, describe the effect. Otherwise, explain why not."
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-7",
    "href": "ae/ae-11-multinomial.html#exercise-7",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nUse the model selected in Exercise 5 to compute the predicted probabilities and predicted classes for viewcat.\nMake a confusion matrix.\nWhat percentage of observations were correctly classified?"
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-8",
    "href": "ae/ae-11-multinomial.html#exercise-8",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nAssess the overall model performance.\nWere there particular categories in which the model has a harder time differentiating?"
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html",
    "href": "ae/ae-08-multicollinearity.html",
    "title": "AE 08: Multicollinearity",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-08 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)\nlibrary(rms) #calculate VIF"
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-1",
    "href": "ae/ae-08-multicollinearity.html#exercise-1",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nFit the regression model using high temperature, average temperature, season, and precipitation to predict volume.\nAre there any coefficients that may be not what you expected?"
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-2",
    "href": "ae/ae-08-multicollinearity.html#exercise-2",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 2",
    "text": "Exercise 2\nUse the formula\n\\[\nVIF_j = \\frac{1}{1 - R^2_j}\n\\]\nto calculate the VIF for avgtemp."
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-3",
    "href": "ae/ae-08-multicollinearity.html#exercise-3",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 3",
    "text": "Exercise 3\nBased on the VIF from the previous exercise, does avgtemp have a linear dependency with one or more other predictors? Explain."
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-4",
    "href": "ae/ae-08-multicollinearity.html#exercise-4",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nUse the vif function to compute VIF for all the predictors in Exercise 1.\nAre there predictors with near-linear dependencies? If so, which ones?"
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-5",
    "href": "ae/ae-08-multicollinearity.html#exercise-5",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 5",
    "text": "Exercise 5\nLet’s address the issue of multicollinearity. Choose a strategy to address the multicollinearity. Apply it, then use relevant statistics to select a final model."
  },
  {
    "objectID": "ae/ae-04-bootstrap.html",
    "href": "ae/ae-04-bootstrap.html",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-04 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#data",
    "href": "ae/ae-04-bootstrap.html#data",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\n\nglimpse(duke_forest)\n\nRows: 98\nColumns: 13\n$ address    &lt;chr&gt; \"1 Learned Pl, Durham, NC 27705\", \"1616 Pinecrest Rd, Durha…\n$ price      &lt;dbl&gt; 1520000, 1030000, 420000, 680000, 428500, 456000, 1270000, …\n$ bed        &lt;dbl&gt; 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4, 5, 3, 4, 4, 3,…\n$ bath       &lt;dbl&gt; 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0, 2.0, 3.0, 3.0,…\n$ area       &lt;dbl&gt; 6040, 4475, 1745, 2091, 1772, 1950, 3909, 2841, 3924, 2173,…\n$ type       &lt;chr&gt; \"Single Family\", \"Single Family\", \"Single Family\", \"Single …\n$ year_built &lt;dbl&gt; 1972, 1969, 1959, 1961, 2020, 2014, 1968, 1973, 1972, 1964,…\n$ heating    &lt;chr&gt; \"Other, Gas\", \"Forced air, Gas\", \"Forced air, Gas\", \"Heat p…\n$ cooling    &lt;fct&gt; central, central, central, central, central, central, centr…\n$ parking    &lt;chr&gt; \"0 spaces\", \"Carport, Covered\", \"Garage - Attached, Covered…\n$ lot        &lt;dbl&gt; 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.79, 0.53, 0.73,…\n$ hoa        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ url        &lt;chr&gt; \"https://www.zillow.com/homedetails/1-Learned-Pl-Durham-NC-…"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#exploratory-data-analysis",
    "href": "ae/ae-04-bootstrap.html#exploratory-data-analysis",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#model",
    "href": "ae/ae-04-bootstrap.html#model",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Model",
    "text": "Model\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#bootstrap-confidence-interval",
    "href": "ae/ae-04-bootstrap.html#bootstrap-confidence-interval",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Bootstrap confidence interval",
    "text": "Bootstrap confidence interval\n\n1. Calculate the observed fit (slope)\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159.\n\n\n\n\n2. Take n_iter bootstrap samples and fit models to each one.\nFill in the code, then set eval: true .\n\nn_iter = 100\nset.seed(091222)\n\nboot_fits &lt;- ______ |&gt;\n  specify(______) |&gt;\n  generate(reps = ____, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n\nWhy do we set a seed before taking the bootstrap samples?\nMake a histogram of the bootstrap samples to visualize the bootstrap distribution.\n\n# Code for histogram\n\n\n\n\n3. Compute the 95% confidence interval as the middle 95% of the bootstrap distribution\nFill in the code, then set eval: true .\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = _____, \n  level = ____,\n  type = \"percentile\"\n)"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#changing-confidence-level",
    "href": "ae/ae-04-bootstrap.html#changing-confidence-level",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nModify the code from Step 3 to create a 90% confidence interval.\n\n# Code for the 90% confidence interval\n\n\n\nModify the code from Step 3 to create a 99% confidence interval.\n\n# Code for the 99% confidence interval\n\n\nWhich confidence level produces the most accurate confidence interval (90%, 95%, 99%)? Explain\nWhich confidence level produces the most precise confidence interval (90%, 95%, 99%)? Explain\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-04 repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "prepare/prepare-lec03.html",
    "href": "prepare/prepare-lec03.html",
    "title": "Prepare for Lecture 03: Simple linear regression",
    "section": "",
    "text": "📖 Read Simple linear regression, Section 4.1 - 4.6\n📖 Read Simple linear regression, Section 4.8"
  },
  {
    "objectID": "prepare/prepare-lec06.html",
    "href": "prepare/prepare-lec06.html",
    "title": "Prepare for Lecture 06: Inference - Mathematical models",
    "section": "",
    "text": "📖 Read Inference for simple linear regression, Section 5.9"
  },
  {
    "objectID": "prepare/prepare-lec05.html",
    "href": "prepare/prepare-lec05.html",
    "title": "Prepare for Lecture 05: Inference - permutation tests",
    "section": "",
    "text": "📖 Read Inference for simple linear regression, Section 5. 1- 5.3\n📖 Read Inference for simple linear regression, Section 5.6 - 5.8"
  },
  {
    "objectID": "prepare/prepare-lec10.html",
    "href": "prepare/prepare-lec10.html",
    "title": "Prepare for Lecture 10: Inference + Model conditions",
    "section": "",
    "text": "📖 Read Model conditions"
  },
  {
    "objectID": "prepare/prepare-lec18.html",
    "href": "prepare/prepare-lec18.html",
    "title": "Prepare for Lecture 18: Logistic regression - Prediction",
    "section": "",
    "text": "📖 Classification module in Google Machine Learning Crash Course"
  },
  {
    "objectID": "hw/hw-02.html",
    "href": "hw/hw-02.html",
    "title": "HW 02: Multiple linear regression",
    "section": "",
    "text": "Important\n\n\n\nThis assignment is due on Tuesday, February 11 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-1",
    "href": "hw/hw-02.html#exercise-1",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nThere are some observations that have missing data for any of the variables of interest .\n\nRemove observations that have missing data for any of the variables of interest - Size, Theme, Pages, and Amazon_Price. Your updated data set will have 374 observations.\nWhat is a disadvantage of dropping observations that have missing values, instead of using a method to impute, i.e., fill in, the missing data? How might dropping these observations impact the generalizability of conclusions?",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-2",
    "href": "hw/hw-02.html#exercise-2",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nVisualize the distributions of the predictor variables Size and Pages. Neatly arrange the plots using the patchwork package.\nUse the plots in part (a) to write an observation about each distribution.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-3",
    "href": "hw/hw-02.html#exercise-3",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nThe distribution of Theme is shown below. The bars are ordered by the frequency they occur in the data set.\n\nlegos |&gt;\n  count(Theme) |&gt;\nggplot(aes(x = fct_reorder(Theme, n), y = n)) +\n  geom_col() + \n    labs(title = \"Lego Set Theme\", \n         x = \"Theme\", \n         y = \"Number of LEGO sets\") + \n  coord_flip()\n\n\n\n\n\n\n\n\n\nWhat is one reason we may want to avoid putting the variable Theme in a model as is?\nWe will create a new variable that collapses some of the levels of Theme. Make a new variable called Theme_Col that has levels for the top four most frequent themes, then the category Other for all other themes.\nHow many observations are in each level for the new variable created in part (b)?\n\n\n\n\n\n\n\nNote\n\n\n\nYou will use Theme_Col, the collapsed Theme variable, for the remainder of the assignment.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-4",
    "href": "hw/hw-02.html#exercise-4",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nFit a model using Size, Pages, and Theme_Col to predict Amazon_Price. Fit the model such that the intercept has a meaningful interpretation. Neatly display the model using three digits.\nInterpret the intercept in the context of the data.\nThe model output suggests that as the number of pages in the instruction booklet increases, the price of the set on Amazon is expected to increase. On the surface, it does not seem that the number of pages in the booklet would be a major predictor of the price on Amazon. What do you think this variable is actually measuring or is actually representing?",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-5",
    "href": "hw/hw-02.html#exercise-5",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nNow let’s consider a model that allows for different effects of pages based on theme.\n\nMake a plot that can be used to visualize the effect of pages on the Amazon.com price based on the theme.\nBased on the plot in part (a), does the effect of the number of pages appear to differ based on theme? Briefly explain why or why not.\nModify the model from Exercise 4 such that the effect of the number of pages differs based on the theme. The intercept should still have a meaningful interpretation. Neatly display the model using three digits.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-6",
    "href": "hw/hw-02.html#exercise-6",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nDescribe the effect of pages for the baseline level in the context of the data.\nDescribe the effect of pages for LEGOS in the Star Wars theme in the context of the data.\nBased on the p-values, do the data provide evidence that the effect of pages differs based on theme? Briefly explain. You can use a threshold of 0.05 for your assessment.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-7",
    "href": "hw/hw-02.html#exercise-7",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nCompute RMSE for the model in Exercise 5. Interpret this value in the context of the data.\nCompute \\(R^2\\) for the model in Exercise 5. Interpret this value in the context of the data.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#perceived-threat-of-covid-19",
    "href": "hw/hw-02.html#perceived-threat-of-covid-19",
    "title": "HW 02: Multiple linear regression",
    "section": "Perceived threat of COVID-19",
    "text": "Perceived threat of COVID-19\n\n\n\n\n\n\nImportant\n\n\n\nUse the following paper for Exercises 8 and 9.\n\n\nGarbe, Rau, and Toppe (2020) aimed to examine the relationship between personality traits, perceived threat of Covid-19 and stockpiling toilet paper. For this study, researchers conducted an online survey March 23 - 29, 2020 and used the results to fit multiple linear regression models to draw conclusions about their research questions. From their survey, they collected data on adults across 35 countries. Given the small number of responses from people outside of the United States, Canada, and Europe, only responses from people in these three locations were included in the regression analysis.\nLet’s consider their results for the model looking at the effect on perceived threat of Covid-19. The model can be found on page 6 of the paper. The perceived threat of Covid was quantified using the responses to the following survey question:\n\nHow threatened do you feel by Coronavirus? [Users select on a 10-point visual analogue scale (Not at all threatened to Extremely Threatened)]\n\nAs stated on page 5 of the paper “To ease interpretation, continuous variables were z-standardized and categorical variables were dummy-coded in all models.”\nClick here to access a PDF of the paper.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-8",
    "href": "hw/hw-02.html#exercise-8",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nInterpret the coefficient of Age (0.072) in the context of the analysis.\nInterpret the coefficient of Place of residence in the context of the analysis. You can assume Emotionality = 0 in the interpretation.\nThe model includes an interaction between Place of residence and Emotionality. The authors describe Emotionality as a measure of “fearfulness, anxiety, dependence, sentimentality”. What does the coefficient for the interaction (0.101) mean in the context of the data?\n\n\n\n\n\n\n\nImportant\n\n\n\nThe following are general questions about linear regression. They are not specific to any of the previous analyses.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-9",
    "href": "hw/hw-02.html#exercise-9",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nProve that the maximum value of \\(R^2\\) must be less than 1 if the data set contains observations such that there are different observed values of the response for the same value of the predictor (e.g., the data set contains observations \\((x_i, y_i)\\) and \\((x_j, y_j)\\) such that \\(x_i = x_j\\) and \\(y_i \\neq y_j\\) .",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#exercise-10",
    "href": "hw/hw-02.html#exercise-10",
    "title": "HW 02: Multiple linear regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nIn lecture we discussed how the distribution of the error terms (and thus the distribution of the response variable \\(Y\\)) for a given value of the predictor \\(X\\) has a variance of \\(\\sigma^2_{\\epsilon}\\). Therefore, we are assuming this variance is the same for all values of the predictor when we conduct inference.\nBriefly explain why this assumption is important when we conduct inference based on mathematical models but is not necessary for conducting simulation-based inference.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-02.html#footnotes",
    "href": "hw/hw-02.html#footnotes",
    "title": "HW 02: Multiple linear regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExercise 9 is based on an exercise in Montgomery, Peck, and Vining (2021) .↩︎",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "hw/hw-01.html",
    "href": "hw/hw-01.html",
    "title": "HW 01: Simple linear regression",
    "section": "",
    "text": "Important\n\n\n\nThis assignment is due on Tuesday, January 28 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#instructions",
    "href": "hw/hw-01.html#instructions",
    "title": "HW 01: Simple linear regression",
    "section": "Instructions",
    "text": "Instructions\nType your responses to each question in your Quarto document. Write all narrative using complete sentences and include informative axis labels and titles on visualizations. Use a reproducible workflow by periodically rendering the Quarto document, writing an informative commit message, and pushing the updated .qmd and .pdf files to GitHub.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#part-1-exploratory-data-analysis",
    "href": "hw/hw-01.html#part-1-exploratory-data-analysis",
    "title": "HW 01: Simple linear regression",
    "section": "Part 1: Exploratory data analysis",
    "text": "Part 1: Exploratory data analysis\n\nExercise 1\nCreate a histogram of the distribution of the predictor variable bachelors and calculate appropriate summary statistics. Use the visualization and summary statistics to describe the distribution. Include an informative title and axis labels on the plot.\n\n\nExercise 2\nLet’s view the data in another way. Use the code below to make a map of the United States with the color of the counties filled in based on the percent of residents 25 years old and older who have a Bachelor’s degree. Fill in title and axis labels.\nThen use the plot answer the following:\n\nWhat are 2 observations you have from the map?\nWhat is a feature that is apparent in the map that wasn’t as easily apparent from the histogram in the previous exercise? What is a feature that is apparent in the histogram that is not as easily apparent from the map?\n\n\n\n#| fig.show: hide \n#| message: false \n\ncounty_map_data &lt;- left_join(county_data_sample, map_data_sample) \n\nggplot(data = map_data_all) + \n  geom_polygon(aes(x = long, y = lat, group = group), \n    fill = \"lightgray\", color = \"white\" \n    ) + \n  geom_polygon(data = county_map_data, aes(x = long, y = lat, group = group, \n    fill = bachelors) \n    ) + \n  labs( \n    x = \"Longitude\", \n    y = \"Latitude\", \n    fill = \"_____\", \n    title = \"_____\" \n  ) + \n  scale_fill_viridis_c(labels = label_percent(scale = 1)) + \n  coord_quickmap() \n\n\n\nExercise 3\nCreate a visualization of the relationship between bachelors and median_household_income and calculate the correlation. Use the visualization and correlation to describe the relationship between the two variables.\n\nThis is a good place to render, commit, and push changes to your hw-01 repo on GitHub. Write an informative commit message (e.g. “Completed exercises 1 - 3”), and push every file to GitHub by clicking the check box next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#part-2-modeling",
    "href": "hw/hw-01.html#part-2-modeling",
    "title": "HW 01: Simple linear regression",
    "section": "Part 2: Modeling",
    "text": "Part 2: Modeling\n\nExercise 4\nWe will use a linear regression model to describe the relationship between bachelors and median_household_income.\nWrite the form of the statistical (theoretical) model we will use for this task using mathematical notation. Use variable names (bachelors and median_household_income) in the equation for your model1.\n\n\n\n\n\n\nTip\n\n\n\nWrite median household income in LaTex as\n\\text{median\\_household\\_income}\nto make it properly render in the .pdf document.\n\n\n\n\nExercise 5\n\nFit the regression line corresponding to the statistical model in the previous exercise. Neatly display the model output using 3 digits.\nWrite the equation of the fitted model using mathematical notation. Use variable names (bachelors and median_household_income) in the equation.\n\n\n\nExercise 6\n\nInterpret the slope in the context of the data.\nIs it useful to interpret the intercept for this data? If so, write the interpretation in the context of the data. Otherwise, briefly explain why not.\n\n\nThis is a good place to render, commit, and push changes to your hw-01 repo on GitHub. Write an informative commit message (e.g. “Completed exercises 4 -6”), and push every file to GitHub by clicking the check box next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#part-3-inference-for-the-u.s.",
    "href": "hw/hw-01.html#part-3-inference-for-the-u.s.",
    "title": "HW 01: Simple linear regression",
    "section": "Part 3: Inference for the U.S.",
    "text": "Part 3: Inference for the U.S.\nWe will use the data from these 600 randomly selected counties to draw conclusions about the relationship between the percent of adults age 25 and older with a bachelor’s degree and median household income for the over 3,000 counties in the United States.\n\nExercise 7\n\nWhat is the population in this analysis? What is the sample?\nIs it reasonable to treat the sample in this analysis as representative of the population? Briefly explain why or why not.\n\n\n\nExercise 8\nNext, compute a 98% bootstrap confidence interval for the slope. Use set.seed(2025) and 1000 iterations. Show all relevant code and output used to compute the interval.\nWrite the 98% confidence interval using 3 digits.\n\n\nExercise 9\n\nInterpret the interval from the previous exercise in the context of the data.\nSuppose you wanted to evaluate the claim that there is no linear relationship between the percent of adults age 25 and older with a bachelor’s degree and median household income for counties in the United States. In other words, you want to evaluate the claim that \\(\\beta_1 = 0\\) in the model written in Exercise 4.\nDoes the confidence interval from the previous exercise support this claim? Briefly explain why or why not.\n\n\nNow is a good time to render your document again if you haven’t done so recently, commit (with an informative commit message), and push all updates.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#footnotes",
    "href": "hw/hw-01.html#footnotes",
    "title": "HW 01: Simple linear regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nClick here for a guide on writing mathematical symbols using LaTex.↩︎",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-05.html",
    "href": "hw/hw-05.html",
    "title": "HW 05",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "STA 210 - Regression Analysis",
    "section": "",
    "text": "In STA 210, students will learn how linear and logistic regression models are used to explore multivariable relationships and apply these methods to answer relevant and engaging questions using a data-driven approach. Students will develop computing skills to implement a reproducible data analysis workflow and gain experience communicating statistical results. Throughout the semester, students will work on a team project where they will develop a research question, answer it using methods learned in the course, and share results through a written report and presentation.\nTopics include applications of linear and logistic regression, interpretation, diagnostics, model selection, and model assessment. Students will gain experience using the computing tools R and GitHub to analyze real-world data from a variety of fields. This class emphasizes data analysis over mathematical theory.\n\n\n100-level Statistical Science course or Statistical Science 230, 231, or 240L",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#pre-requisites",
    "href": "overview.html#pre-requisites",
    "title": "STA 210 - Regression Analysis",
    "section": "",
    "text": "100-level Statistical Science course or Statistical Science 230, 231, or 240L",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#teaching-assistants",
    "href": "overview.html#teaching-assistants",
    "title": "STA 210 - Regression Analysis",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\n\n\n\n\nName\nRole\n\n\nSylvia Vincent\nHead TA\nLab 01L leader\nLab 02L leader\n\n\nIshrit Gupta\nLab 02L leader\n\n\nKareena Legare\nLab 01L helper\n\n\n\nSee Canvas for office hours times and locations.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "hw/hw-04.html",
    "href": "hw/hw-04.html",
    "title": "HW 04: Logistic regression",
    "section": "",
    "text": "ImportantDue date\n\n\n\nThis assignment is due on Tuesday, April 8 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#learning-goals",
    "href": "hw/hw-04.html#learning-goals",
    "title": "HW 04: Logistic regression",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the assignment you will be able to…\n\nUse logistic regression to explore the relationship between a binary response variable and multiple predictor variables\nConduct exploratory data analysis for logistic regression\nInterpret coefficients of logistic regression model\nUse statistics to help choose the best fit model\nUse the logistic regression model for prediction and classification",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#getting-started",
    "href": "hw/hw-04.html#getting-started",
    "title": "HW 04: Logistic regression",
    "section": "Getting started",
    "text": "Getting started\n\nGo to the sta210-sp25 organization on GitHub. Click on the repo with the prefix hw-04. It contains the starter documents you need to complete the lab.\nClone the repo and start a new project in RStudio. See the Lab 00 for details on cloning a repo and starting a new project in R.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#packages",
    "href": "hw/hw-04.html#packages",
    "title": "HW 04: Logistic regression",
    "section": "Packages",
    "text": "Packages\nThe following packages will be used for this assignment.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\n\n# add other packages as needed",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-1",
    "href": "hw/hw-04.html#exercise-1",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nWhy do you think the authors chose to only include data from people who were eligible to vote for at least four election cycles?",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-2",
    "href": "hw/hw-04.html#exercise-2",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nLet’s prepare the data for analysis and modeling.\n\nCreate a new variable called frequent_voter that takes the value 1 if the voter_category is “always” and 0 otherwise.\nMake a table of the distribution of frequent_voter.\nWhat percentage of the respondents in the data say they voted “in all or all-but-one of the elections they were eligible in”?",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-3",
    "href": "hw/hw-04.html#exercise-3",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nThe variable Q30 contains the respondent’s political party identification. Make a new variable, party_id, that simplifies Q30 into three categories: “Democrat”, “Republican”, “Independent/Neither”, The category “Independent/Neither” will also include respondents who did not answer the question. Make party_id a factor and relevel it so that it is consistent with the ordering of the responses in Question 30 of the survey.\n\nMake a plot of the distribution of party_id.\nWhich category of party_id occurs most frequently in this data set?",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-4",
    "href": "hw/hw-04.html#exercise-4",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nIn the FiveThirtyEight article, the authors include visualizations of the relationship between the voter category and demographic variables such as race, age, education, etc.\n\nMake a segmented barplot (also known as a stacked barplot) displaying the distribution of frequent_voter for each category of party_id. Make the plot such that the percentages (instead of counts) are displayed.\nUse the plot to describe the relationship between these two variables.\n\n\n\n\n\n\n\nTip\n\n\n\nSee the plots of demographic information by voting history in the FiveThirtyEight article for examples of segmented bar plots.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-5",
    "href": "hw/hw-04.html#exercise-5",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nLet’s start by fitting a model using the demographic factors - ppage, educ, race, gender, income_cat - to predict the odds a person is a frequent voter.\n\nSplit the data into training (75%) and testing sets (25%). Use a seed of 29.\nFit the model on the training data. Display the model using 3 digits.\nConsider the relationship between ppage and one’s voting behavior. Interpret the coefficient of ppage in the context of the data in terms of the odds a person is a frequent voter.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-6",
    "href": "hw/hw-04.html#exercise-6",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nShould party identification be added to the model? Use a drop-in-deviance test to determine if party identification should be added to the model fit in the previous exercise. Include the hypotheses in mathematical notation, the output from the test, and the conclusion in the context of the data.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-7",
    "href": "hw/hw-04.html#exercise-7",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nDisplay the model chosen from the previous exercise using 3 digits.\nThen use the model selected to write a short paragraph (2 - 5 sentences) describing the effect (or lack of effect) of political party on the odds a person is a frequent voter. The paragraph should include an indication of which levels (if any) are statistically significant along with specifics about the differences in the odds between the political parties, as appropriate.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-8",
    "href": "hw/hw-04.html#exercise-8",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nIn the article, the authors write\n\n“Nonvoters were more likely to have lower incomes; to be young; to have lower levels of education; and to say they don’t belong to either political party, which are all traits that square with what we know about people less likely to engage with the political system.”\n\nConsider the model you selected in Exercise 6. Is it consistent with this statement? Briefly explain why or why not.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-9",
    "href": "hw/hw-04.html#exercise-9",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nUse the testing data to produce the ROC curve and calculate the area under curve (AUC) for the model selected in Exercise 6. Write 1 - 2 sentences describing how well the model fits the data.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-04.html#exercise-10",
    "href": "hw/hw-04.html#exercise-10",
    "title": "HW 04: Logistic regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nYou have been tasked by a local political organization to identify adults in the community who are frequent voters. These adults will receive targeted political mailings that will be different from the mailings sent to adults who are not frequent voters. You will use the model selected in Exercise 6 to identify the frequent voters.\nMake a confusion matrix based on the cut-off probability of 0.25. Use the confusion matrix to calculate the following:\n\nSensitivity\nSpecificity\nFalse negative rate\nFalse positive rate",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "hw/hw-03.html",
    "href": "hw/hw-03.html",
    "title": "HW 03: Multiple linear regression",
    "section": "",
    "text": "ImportantDue date\n\n\n\nThis assignment is due on Tuesday, March 18 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#data-age-of-abalones",
    "href": "hw/hw-03.html#data-age-of-abalones",
    "title": "HW 03: Multiple linear regression",
    "section": "Data: Age of abalones",
    "text": "Data: Age of abalones\nThe data for this analysis contains measurements for abalones, a type of marine snail. These measurements were collected and analyzed by researchers in Warwick et al. (1994). Click here for the publication.\nThe 4177 abalones in this study can be reasonably treated as a random sample.\nThe data are available in the file abalone.csv in the data folder. This analysis will focus on the following variables:\n\nSex: Male (M), Female (F), Infant (I)\nLength: Longest shell measurement (in millimeters)\nDiameter: Measured perpendicular to length (in millimeters)\nHeight : Measured with meat in shell (in millimeters)\nWhole_Weight: Total weight of abalone (in grams)\nAge: Age (in year)\n\nThe goal of the analysis is to use a variety of measurements from abalones to explain variability in the age.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-1",
    "href": "hw/hw-03.html#exercise-1",
    "title": "HW 03: Multiple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nFit a model using Sex, Length, Diameter, Height and Whole_Weight to understand variability in Age. Neatly display the model using 3 digits.\nCheck the four model conditions - Linearity, Constant Variance, Normality, and Independence. For each condition: (1) state whether or not it is satisfied; (2) explain your response showing any visualizations and/or statistics used to make your assessment.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-2",
    "href": "hw/hw-03.html#exercise-2",
    "title": "HW 03: Multiple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nNow let’s take a look at the model diagnostics.\n\nAre there any influential observations in the data set? Briefly explain, showing any work or output used to make the determination.\nConsider the observation with the highest value for Cook’s distance. What is the value of leverage for this observation? Does this observation have large leverage? Briefly explain, showing any work or output used to make the determination.\nAgain consider the observation with the highest value for Cook’s distance. What is the standardized residual for this observation? Is this observation an outlier? Briefly explain showing any work or output used to make the determination.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-3",
    "href": "hw/hw-03.html#exercise-3",
    "title": "HW 03: Multiple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nNow let’s look at the relationship between predictors.\n\nCompute the Variance Inflation Factors (VIF) for the model from Exercise 1. Display the results.\nUse the equation for VIF to “manually” compute the VIF for Whole_Weight.\nWhat predictors appear to be collinear?\nSelect a strategy to fit a model that does not have an issue with multicollinearity.\n\nBriefly describe your strategy.\nSelect a final model.\nBriefly explain your selection, showing the work and statistics used to choose a final model.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#data-2000-u.s.-presidential-election1",
    "href": "hw/hw-03.html#data-2000-u.s.-presidential-election1",
    "title": "HW 03: Multiple linear regression",
    "section": "Data: 2000 U.S. Presidential Election1",
    "text": "Data: 2000 U.S. Presidential Election1\n\nWe will examine data about the 2000 U.S. presidential election between George W. Bush and Al Gore. It was one of the closest elections in history that ultimately came down to the state of Florida. One county in particular, Palm Beach County, was at the center of the controversy due to the design of their ballots - the infamous butterfly ballots. It is believed that many people who intended to vote for Al Gore accidentally voted for Pat Buchanan due to how the spots to mark the candidate were arranged next to the names.\nThe variables in the data are\n\nCounty: County name\nBush2000: Number of votes for George W. Bush\nBuchanan2000: Number of votes for Pat Buchanan\n\nThe data are available in the file florida-votes-2000.csv in the data folder of your repo.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-4",
    "href": "hw/hw-03.html#exercise-4",
    "title": "HW 03: Multiple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nThe goal is to fit a model that uses the number of votes for Bush to predict the number of votes for Buchanan. Using this model, we’ll investigate whether the data support the claim that votes for Gore may have accidentally gone to Buchanan.\n\nVisualize the relationship between the number of votes for Buchanan versus the number of votes for Bush. Describe what you observe in the visualization, including a description of the relationship between the votes for Buchanan and votes for Bush.\nWhat is the county with the extreme outlier number of votes for Buchanan? Create a new data frame that doesn’t include the outlying county. You will use this updated data frame for the remainder of this exercise and Exercise 5.\nFit a model to predict the number of votes for Buchanan based on the number of votes for Bush in the county.\n\nMake a plot of the standardized residuals versus the fitted values.\nIs the constant variance condition satisfied? Briefly explain.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-5",
    "href": "hw/hw-03.html#exercise-5",
    "title": "HW 03: Multiple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nNow let’s consider potential models with transformations on the response and/or predictor variables. The four candidate models are the following:\n\n\n\nModel\nResponse variable\nPredictor variable\n\n\n\n\n1 (from previous exercise)\nBuchanan2000\nBush2000\n\n\n2\nlog(Buchanan2000)\nBush2000\n\n\n3\nBuchanan2000\nlog(Bush2000)\n\n\n4\nlog(Buchanan2000)\nlog(Bush2000)\n\n\n\nWhich model best fits the data? Briefly explain, showing any work and output used to determine the response. (Note: Use the data set without the outlying county to find the candidate models.)",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#exercise-6",
    "href": "hw/hw-03.html#exercise-6",
    "title": "HW 03: Multiple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nUse the model you chose in the previous exercise to compute the predicted number of votes for Buchanan in the outlying county identified in Exercise 4. If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).\nCompute the 95% prediction interval for this county. If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).\nIt is assumed that some of the votes for Buchanan in that county were actually intended to be for Gore. Based on your results in the previous question, does your model support this claim?\n\nIf no, briefly explain.\nIf yes, about how many votes were possibly intended for Gore? Show any calculations and output used to determine your answer. If you selected a model with a transformation, be sure to report your answer in terms of votes, not log(votes).",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-03.html#footnotes",
    "href": "hw/hw-03.html#footnotes",
    "title": "HW 03: Multiple linear regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis analysis was motivated by exercises in Ledolter (2003).↩︎",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/stats-experience.html",
    "href": "hw/stats-experience.html",
    "title": "Statistics Experience",
    "section": "",
    "text": "Important\n\n\n\nThis assignment is due on Tuesday, April 15 at 11:59pm.\nThe world of statistics and data science is vast and continually growing! The goal of the statistics experience assignments is to help you engage with the statistics and data science communities outside of the classroom.\nYou may submit the statistics experience assignment anytime between now and the deadline.\nEach experience has two parts:\n1️⃣ Have a statistics experience.\n2️⃣ Make a slide reflecting on your experience.\nYou must complete both parts to receive credit. The statistics experience will count as a homework grade.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "href": "hw/stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "title": "Statistics Experience",
    "section": "Part 1: Experience statistics outside of the classroom",
    "text": "Part 1: Experience statistics outside of the classroom\nComplete an activity in one of the categories below. Under each category are suggested activities. You do not have to do one these suggested activities. You are welcome to find other activities as long as they are related to statistics/data science and they fit in one of the six categories. If there is an activity you’d like to do but you’re not sure if it qualifies for the statistics experience, just ask!\n\nCategory 1: Attend a talk or conference\nAttend an talk, panel, or conference related to statistics or data science. If you are attending a single talk or panel, it must be at least 30 minutes to count towards the statistics experience. The event can be in-person or online.\n\n\nCategory 2: Talk with a statistician/ data scientist\nTalk with someone who uses statistics in their daily work. This could include a professor, professional in industry, graduate student, etc.\n\n\nCategory 3: Listen to a podcast / watch video\nListen to a podcast or watch a video about statistics and data science. The podcasts / videos must be (1) one podcast or video that is at least 30 minutes or (2) multiple podcasts and/or videos that are at least 30 minutes combined.\nA few suggestions are below:\n\nStats + Stories Podcast\nCausal Inference Podcast\nposit::conf talks (formally called rstudio::conf)\n\n2024 conference\n2023 conference\n2022 conference\n2021 conference\n\n\nThis list is not exhaustive. You may listen to other podcasts or watch other statistics/data science videos not included on this list. Ask Professor Tackett if you are unsure whether a particular podcast or video will count towards the statistics experience.\n\n\nCategory 4: Participate in a data science competition or challenge\nParticipate in a statistics or data science competition. You can participate individually or with a team.\nNote: DataFest will be April 4 - 6 in Penn Pavilion. Click here to learn more.\n\n\nCategory 5: Read a book on statistics/data science\nThere are a lot of books about statistics, data science, and related topics. A few suggestions are below. If you decide to read a book that isn’t on this list, ask Professor Tackett to make sure it counts toward the experience. Many of these books are available through Duke library.\n\nWeapons of Math Destruction by Cathy O’Neil\nHow Charts Lie: Getting Smarter about Visual Information by Alberto Cairo\nThe Theory that Would Not Die by Sharon Bertsch McGrayne\nThe Art of Statistics: How to learn from data by David Spiegelhalter\nThe Lady Tasting Tea by David Salsburg\nList of books about data science ethics\n\nThis list is not exhaustive.\n\n\nCategory 6: TidyTuesday\nYou may also participate in a TidyTuesday challenge. New data sets are announced on Monday afternoons.You can find more information about TidyTuesday and see the data in the TidyTuesday GitHub repo.\nA few guidelines:\n✅ Create a GitHub repo for your TidyTuesday submission. Your repo should include\n\nThe R Markdown file with all the code needed to reproduce your visualization.\nA README that includes an image of your final visualization and a short summary (~ 1 paragraph) about your visualization.\n\n✅ The visualization should include features or customization that are beyond what we’ve done in class .\n✅ Include the link to your GitHub repo in the slide summarizing your experience.\n\n\nCategory 7: CURV - connecting, uplifting, and recognizing voices\nCURV is a project by Dr. Jo Hardin at Pomona College to highlight statisticians and data scientists from groups who have been historically marginalized in the discipline.\n\n\n\n\n\n\nFor this statistics experience, you can contribute to the CURV data base. If there is a scholar you would like to suggest for the data base, submit your suggestion as an issue or pull request on the CURV GitHub repo and create a sample CURV page.\nA few guidelines:\n✅ Create a draft of the CURV page for your suggested scholar. For reference, click here for the CURV page for W.E.B. Du Bois. The page must be created in a Quarto document.\n\n\n\n\n\n\nTip\n\n\n\nYou can find the Quarto documents for current scholars in the data base in the CURV GitHub repo. You can use one of these as a template to format your page.\n\n\n✅ Make a pull request to the CURV GitHub repo to add the .qmd file for your suggested scholar, OR open an issue with a link to the .qmd file for your suggested scholar. You can ask a member of the teaching team if you have questions about how to do this.\n✅ Include the URL to your pull request or issue in your one-slide reflection.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#part-2-reflect-on-your-experience",
    "href": "hw/stats-experience.html#part-2-reflect-on-your-experience",
    "title": "Statistics Experience",
    "section": "Part 2: Reflect on your experience",
    "text": "Part 2: Reflect on your experience\nMake one slide summarizing and reflecting on your experience. Submit the slide as a PDF on Gradescope.\nInclude the following on your slide:\n\nDescription of the experience\n\nName and brief description of the event/podcast/competition/etc.\n\nSomething you learned\n\nWrite 2 - 4 sentences about something you learned or found particularly interesting or unexpected.\n\nConnection to STA 221\n\nWrite 2 - 4 sentences about how the experience connects to what we’ve done in the course.\n\nCitation or link to web page for event/competition/etc.\n\nNo citation needed if you do an interview.\n\n\nMake sure the slide includes the information mentioned above and is easily readable (i.e. use a reasonable font size!). Creativity on the experience and slide design is encouraged!",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/stats-experience.html#submission",
    "href": "hw/stats-experience.html#submission",
    "title": "Statistics Experience",
    "section": "Submission",
    "text": "Submission\nThis assignment is due on Tuesday, April 15. Standard homework late policy applies. More submission instructions to come.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "prepare/prepare-lec22.html",
    "href": "prepare/prepare-lec22.html",
    "title": "Prepare for Lecture 22: Multinomial Logistic Regression pt2",
    "section": "",
    "text": "📖 juliasilge.com/blog/multinomial-volcano-eruptions\n📖 juliasilge.com/blog/nber-papers"
  },
  {
    "objectID": "prepare/prepare-lec04.html",
    "href": "prepare/prepare-lec04.html",
    "title": "Prepare for Lecture 04: Inference - bootstrap confidence intervals",
    "section": "",
    "text": "📖 Read Inference for simple linear regression, Section 5. 1- 5.3\n📖 Read Bootstrap confidence intervals, Section 5.5"
  },
  {
    "objectID": "prepare/prepare-lec07.html",
    "href": "prepare/prepare-lec07.html",
    "title": "Prepare for Lecture 06: Multiple linear regression",
    "section": "",
    "text": "📖 Read Multiple linear regression, Section 7.1 - 7.4\n📖 Read Multiple linear regression, Section 7.6.1"
  },
  {
    "objectID": "prepare/prepare-lec02.html",
    "href": "prepare/prepare-lec02.html",
    "title": "Prepare for Lecture 02: The big picture",
    "section": "",
    "text": "📖 Read R for Data Science, Introduction: What you will learn\n📖 Read GitHub for supporting, reusing, contributing, and failing safely\n🎥 Watch Meet the Toolkit: R + RStudio\n🎥 Watch Meet the Toolkit: Quarto"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html",
    "href": "ae/ae-07-exam-01-review.html",
    "title": "AE 07: Exam 01 review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-07- to get started.\nRender, commit, and push your responses to GitHub by the end of class."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#packages",
    "href": "ae/ae-07-exam-01-review.html#packages",
    "title": "AE 07: Exam 01 review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#trail-users",
    "href": "ae/ae-07-exam-01-review.html#trail-users",
    "title": "AE 07: Exam 01 review",
    "section": "Trail users",
    "text": "Trail users\nThe Pioneer Valley Planning Commission (PVPC) collected data for ninety days from April 5, 2005 to November 15, 2005. Data collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\nWe will use regression analysis to predict the number of trail users based on weather and other features describing the day.\nThe variables we’ll focus on for this analysis are\n\nvolume estimated number of trail users that day (number of breaks recorded)\nhightemp daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\ndaytype one of “weekday” or “weekend”\n\nView the data set1 to see the remaining variables.\n\nrail_trail &lt;- read_csv(\"data/rail-trail.csv\")"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#exploratory-analysis",
    "href": "ae/ae-07-exam-01-review.html#exploratory-analysis",
    "title": "AE 07: Exam 01 review",
    "section": "Exploratory analysis",
    "text": "Exploratory analysis\n\nExercise 1\nVisualize, summarize, and describe the distribution of volume.\n\n\nExercise 2\n\nVisualize and describe the relationship between hightemp and volume.\nModify the plot to consider if the relationship between these variables differs by daytype."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#modeling",
    "href": "ae/ae-07-exam-01-review.html#modeling",
    "title": "AE 07: Exam 01 review",
    "section": "Modeling",
    "text": "Modeling\nFit a model using hightemp and daytype to predict the volume for this trail.\n\nExercise 3\n\nWrite the statistical model.\nFit the model and write the estimated regression equation. Neatly display the results using 3 digits and the 90% confidence interval for the coefficients.\n\n\n\nExercise 4\nInterpret the slope of hightemp in the context of the data.\n\n\nExercise 5\n\nDoes it make sense to interpret the intercept? Explain your reasoning.\nIf not, what can we do to make the interpretation meaningful?"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#inference-for-coefficients",
    "href": "ae/ae-07-exam-01-review.html#inference-for-coefficients",
    "title": "AE 07: Exam 01 review",
    "section": "Inference for coefficients",
    "text": "Inference for coefficients\n\nExercise 6\nThe following code can be used to create a bootstrap distribution for the model coefficients. Describe what each line of code does, supplemented by any visualizations that might help with your description.\n\nset.seed(1234)\n\n1boot_dist &lt;- rail_trail |&gt;\n2  specify(volume ~ hightemp + daytype) |&gt;\n3  generate(reps = 100, type = \"bootstrap\") |&gt;\n4  fit()\n\n\n1\n\n___\n\n2\n\n___\n\n3\n\n___\n\n4\n\n___\n\n\n\n\n\n\nExercise 7\nUse the bootstrap distribution created in Exercise 6, boot_dist, to construct a 90% confidence interval for the coefficient of hightemp using bootstrapping and the percentile method and interpret it in context of the data.\n\n\nExercise 8\nConduct a hypothesis test for the coefficient of hightemp significance level using permutation with 100 reps. State the hypotheses in words and mathematical notation. Also include a visualization of the null distribution of the slope with the observed slope marked as a vertical line.\n\n\nExercise 9\nNow repeat Exercises 7 and 8 using approaches based on mathematical models. You can reference output from previous exercises and/or write new code as needed."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#inference-for-prediction",
    "href": "ae/ae-07-exam-01-review.html#inference-for-prediction",
    "title": "AE 07: Exam 01 review",
    "section": "Inference for prediction",
    "text": "Inference for prediction\n\nExercise 10\nBased on your model, predict the volume for a weekday with high temperature of degrees.\n\n\nExercise 11\nSuppose you’re asked to construct a confidence and a prediction interval for your finding in the previous exercise. Which one would you expect to be wider and why? In your answer clearly state the difference between these intervals.\n\n\nExercise 12\nNow construct the intervals and comment on whether your guess is confirmed."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#interaction-terms",
    "href": "ae/ae-07-exam-01-review.html#interaction-terms",
    "title": "AE 07: Exam 01 review",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nExercise 13\nNow fit the model using hightemp and daytype to predict volume such that the effect of hightemp can differ by daytype.\n\n\nExercise 14\n\nWrite the estimated regression equation for weekends.\nWrite the estimated regression equation for weekdays.\n\n\n\nExercise 15\nAccording to this model, does the effect of hightemp differ for weekends vs. weekdays? Explain."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#model-comparison",
    "href": "ae/ae-07-exam-01-review.html#model-comparison",
    "title": "AE 07: Exam 01 review",
    "section": "Model comparison",
    "text": "Model comparison\n\nExercise 16\nWhich model is a better fit for the data - the model with or without the interaction? Show any work to support your choice.\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-07- repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#footnotes",
    "href": "ae/ae-07-exam-01-review.html#footnotes",
    "title": "AE 07: Exam 01 review",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package.↩︎"
  },
  {
    "objectID": "ae/ae-02-life-expectancy.html",
    "href": "ae/ae-02-life-expectancy.html",
    "title": "AE 02: Life expectancy and healthcare expenditure",
    "section": "",
    "text": "Important\n\n\n\nFor this AE, you will discuss the questions in groups. This AE does not count towards the Application Exercise grade.\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-02-life-expectancy.html#introduction",
    "href": "ae/ae-02-life-expectancy.html#introduction",
    "title": "AE 02: Life expectancy and healthcare expenditure",
    "section": "Introduction",
    "text": "Introduction\nThe data set comes from Zarulli et al. (2021), who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThis AE will focus on the following variables:\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic area. ( from the World Health Organization)\nhealth_pct_gdp: Spending on healthcare goods and services, expressed as a percentage of GDP. It excludes capital health expenditures such as buildings, machinery, information technology and stocks of vaccines for emergency or outbreaks.\n\nClick here for the original research paper and a full list of variables in the original data set.\n\nlife_exp &lt;- read_excel(\"data/life-expectancy-data.xlsx\") |&gt; \n  rename(life_exp = `Life_expectancy_at_birth`, \n         health_pct_gdp = `Domestic_general_government_health_expenditure_pct_of_GDP`)\n\n\nlife_exp |&gt;\n  select(life_exp, health_pct_gdp) |&gt;\n  glimpse()\n\nRows: 140\nColumns: 2\n$ life_exp       &lt;dbl&gt; 63.8, 78.2, 59.9, 76.2, 74.6, 83.0, 81.3, 72.5, 71.8, 7…\n$ health_pct_gdp &lt;dbl&gt; 5, 41, 44, 74, 16, 68, 73, 20, 18, 61, 84, 66, 21, 74, …"
  },
  {
    "objectID": "ae/ae-02-life-expectancy.html#exercises",
    "href": "ae/ae-02-life-expectancy.html#exercises",
    "title": "AE 02: Life expectancy and healthcare expenditure",
    "section": "Exercises",
    "text": "Exercises\nWe begin by visualizing the distributions of life expectancy, health expenditure percentage, and the relationship between these two variables.\n\np1 &lt;- ggplot(life_exp, aes(x = life_exp)) +\n  geom_histogram() + \n  labs(x = \"Life expectancy\")\n\np2 &lt;- ggplot(life_exp, aes(x = health_pct_gdp)) +\n  geom_histogram() + \n  labs(x = \"% Health expenditure\")\n\np3 &lt;- ggplot(life_exp, aes(x = health_pct_gdp, y = life_exp)) +\n  geom_point() + \n  labs(x = \"% Health expenditure\", \n       y = \"Life expectancy\")\n\n(p1 | p2) / p3\n\n\n\n\n\n\n\n\n\nExercise 1\nDescribe the relationship between life expectancy and healthcare expenditure as a percentage of the GDP. Comment on how we expect the life expectancy to change as the percentage on healthcare expenditure changes.\n\n\nExercise 2\nSuppose you want to fit a model so you can use the healthcare expenditure as a percentage of GDP to predict life expectancy. Would a model of the form\n\\[\\text{life_exp} = \\beta_0 + \\beta_1 ~ \\text{health_pct_gdp} + \\epsilon\\]\nbe a useful model for the data? Why or why not?"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html",
    "href": "ae/ae-12-exam-02-review.html",
    "title": "AE 12: Exam 02 Review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-12 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE."
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#packages",
    "href": "ae/ae-12-exam-02-review.html#packages",
    "title": "AE 12: Exam 02 Review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(pROC)"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-1",
    "href": "ae/ae-12-exam-02-review.html#exercise-1",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 1",
    "text": "Exercise 1\nSuppose you fit a simple linear regression model.\n\nDraw or describe a scatterplot that contains an observation with large leverage but low Cook’s distance.\nDraw or describe a scatterplot that contains an observation with large leverage and high Cook’s distance.\nDraw or describe a scatterplot that contains an observation with a large studentized residual."
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#data-credit-cards",
    "href": "ae/ae-12-exam-02-review.html#data-credit-cards",
    "title": "AE 12: Exam 02 Review",
    "section": "Data: Credit cards",
    "text": "Data: Credit cards\nThe data for this analysis is about credit card customers. It can be found in the file credit.csv. The following variables are in the data set:\n\nincome: Income in $1,000’s\nlimit: Credit limit\nrating: Credit rating\ncards: Number of credit cards\nage: Age in years\neducation: Number of years of education\nown: A factor with levels No and Yes indicating whether the individual owns their home\nstudent: A factor with levels No and Yes indicating whether the individual was a student\nmarried: A factor with levels No and Yes indicating whether the individual was married\nregion: A factor with levels South, East, and West indicating the region of the US the individual is from\nbalance: Average credit card balance in $.\n\nThe objective of this analysis is to predict whether a person has maxed out their credit card, i.e., had $0 average card balance.\n\ncredit &lt;- read_csv(\"data/credit.csv\") |&gt;\n  mutate(maxed = factor(if_else(balance == 0, 1, 0)))"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-2",
    "href": "ae/ae-12-exam-02-review.html#exercise-2",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWhy is logistic regression the best modeling approach for this analysis?\nDescribe where each of the following show up in the analysis:\n\nlog-odds …\nodds\nprobabilities"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-3",
    "href": "ae/ae-12-exam-02-review.html#exercise-3",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe’ll start by splitting the model into training and testing data. Then we’ll using the training data to fit a model for predicting the odds of maxed = 1 using income, rating, and region.\n\n# make training and test sets\nset.seed(210)\ncredit_split &lt;- initial_split(credit, prop = 0.8)\ncredit_train &lt;- training(credit_split)\ncredit_test &lt;- testing(credit_split)\n\ncredit_fit &lt;- glm(maxed ~ income + rating + region, data = credit_train, \n                  family = \"binomial\")\n\ntidy(credit_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n10.097\n1.687\n5.987\n0.000\n\n\nincome\n0.115\n0.026\n4.444\n0.000\n\n\nrating\n-0.058\n0.009\n-6.428\n0.000\n\n\nregionSouth\n-0.632\n0.715\n-0.884\n0.377\n\n\nregionWest\n-0.332\n0.724\n-0.458\n0.647\n\n\n\n\n\nThe logistic regression model takes the following form:\n\\[\n\\log(\\frac{\\pi_i}{1 - \\pi_i}) = \\beta_0 + \\beta_1 ~ income + \\beta_2 ~ rating + \\beta_3 ~ regionSouth + \\beta_4 ~ regionWest\n\\]\n\nWrite the interpretation of income in terms of the odds of maxing out a credit card.\nUse the equation above to show the expected change in the odds of maxing out a credit card when the credit rating increases by 10 points. Assume income and region are constant. Write your answer in terms of \\(\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4\\).\nSuppose there are two individuals. Individual 1 has an income of $64,000, a credit rating of 590, and is from the South region. Individual 2 has an income of $135,000, a credit rating of 695, and is from the East region. Use the equation above to show how the odds of maxing out a credit card differ between Individual 1 and Individual 2. Write your answer in terms of \\(\\beta_0, \\beta_1, \\beta_2\\), etc."
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-4",
    "href": "ae/ae-12-exam-02-review.html#exercise-4",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 4",
    "text": "Exercise 4\nWe consider adding the interaction between region and income to the current model. We’ll use a drop-in-deviance test to determine whether or not to add the interaction term.\n\nState the null and alternative hypotheses in words and using mathematical notation.\nDescribe what the test statistic \\(G\\) means in the context of the data.\nShow why the degrees of freedom for the test statistic are equal to 2.\nConduct the drop-in-deviance test and state your conclusion in the context of the data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-5",
    "href": "ae/ae-12-exam-02-review.html#exercise-5",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 5",
    "text": "Exercise 5\nNow let’s evaluate the performance of the selected model using the testing data.\nCreate a confusion matrix using a cutoff probability of 0.3.\n\n# add code here\n\n\nWhat is the sensitivity? What does it mean in the context of the data ?\nWhat is the specificity? What does it mean in the context of the data?\nWhat is the false positive rate? What does it mean in the context of the data?\nWhat is the false negative rate? What does it mean in the context of the data?"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-6",
    "href": "ae/ae-12-exam-02-review.html#exercise-6",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 6",
    "text": "Exercise 6\nProduce the ROC curve.\n\n# add code here\n\n\nDescribe how you can use this curve to select a cutoff probability (rather than just going with 0.5)."
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-7",
    "href": "ae/ae-12-exam-02-review.html#exercise-7",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 7",
    "text": "Exercise 7\nQuestions about checking conditions for logistic regression:\n\nDo we assess conditions on the training or testing set?\nWhy do we not consider categorical predictors when checking linearity?\nWhy do we not need to check constant variance for logistic regression?"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html",
    "href": "ae/ae-05-sim-testing.html",
    "title": "AE 05: Permutation test for the slope",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-05 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#data",
    "href": "ae/ae-05-sim-testing.html#data",
    "title": "AE 05: Permutation test for the slope",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\nGoal: Use statistical inference to evaluate whether there is a relationship between the age of the house at time of sale and its price."
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#exploratory-data-analysis",
    "href": "ae/ae-05-sim-testing.html#exploratory-data-analysis",
    "title": "AE 05: Permutation test for the slope",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\nLet’s begin by creating a new variable that is the age of the house in 2020.\n\nduke_forest &lt;- duke_forest |&gt;\n  mutate(age_2020 = 2020 - year_built)\n\nNow let’s visualize the relationship between the age of the house in 2020 and the sales price.\n\nggplot(duke_forest, aes(x = age_2020, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Age in 2020 (years)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and age of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#model",
    "href": "ae/ae-05-sim-testing.html#model",
    "title": "AE 05: Permutation test for the slope",
    "section": "Model",
    "text": "Model\n\ndf_fit &lt;- lm(price ~ age_2020, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n690891.015\n68637.793\n10.066\n0.000\n\n\nage_2020\n-2473.935\n1225.191\n-2.019\n0.046"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#hypothesis-test",
    "href": "ae/ae-05-sim-testing.html#hypothesis-test",
    "title": "AE 05: Permutation test for the slope",
    "section": "Hypothesis test",
    "text": "Hypothesis test\n\n\n\n\n\n\nTip\n\n\n\nFor code chunks with fill-in-the-blank code, change code chunk option to #| eval: true once you’ve filled in the code.\n\n\n\nState the null and alternative hypotheses\nWrite the null and alternative hypotheses in words and mathematical notation.\n\n\nGenerate null distribution using permutation\nFill in the code, then set eval: true .\n\nn = 100\nset.seed(01232025)\n\nnull_dist &lt;- _____ |&gt;\n  specify(______) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = _____, type = \"permute\") |&gt;\n  fit()\n\n\n\nVisualize distribution\n\n# Code for histogram of null distribution\n\n\n\nCalculate the p-value.\n\n# get observed fit \nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ age_2020) |&gt;\n  fit()\n\n# calculate p-value\nget_p_value(\n  ____,\n  obs_stat = ____,\n  direction = \"two-sided\"\n)\n\n\n\nState conclusion\nWrite your conclusion in the context of the data. You can use 0.05 as the decision-making threshold."
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#bootstrap-ci-time-permitting",
    "href": "ae/ae-05-sim-testing.html#bootstrap-ci-time-permitting",
    "title": "AE 05: Permutation test for the slope",
    "section": "Bootstrap CI (time permitting)",
    "text": "Bootstrap CI (time permitting)\n\nConstruct the bootstrap CI\nConstruct a 95% bootstrap confidence interval.\n\n\nDraw conclusion\n\nInterpret the interval in the context of the data.\nIs the interval consistent with the conclusion from your hypothesis test? Briefly explain why or why not.\n\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-05 repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-03-slr.html",
    "href": "ae/ae-03-slr.html",
    "title": "AE 03: Simple linear regression",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-03 repo to get started. If you do not see an ae-03 repo, use the link below to create one:\nhttps://classroom.github.com/a/jxxCTVVo\nThis AE does not count towards the participation grade.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-1",
    "href": "ae/ae-03-slr.html#exercise-1",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nVisualizations for the univariate and bivariate exploratory data analysis of daily bike rentals and temperature are below.\n\np1 &lt;- ggplot(bikeshare, aes(x = count)) +\n  geom_histogram(binwidth = 250) + \n  labs(x = \"Daily bike rentals\")\n\np2 &lt;- ggplot(bikeshare, aes(x = temp_orig)) +\n  geom_histogram() + \n  labs(x = \"Temperature (Celsius)\")\n\np3 &lt;- ggplot(bikeshare, aes(y = count, x = temp_orig)) +\n  geom_point() + \n  labs(x = \"Temperature (Celsius)\", \n       y = \"Daily bike rentals\")\n\n(p1 | p2) / p3\n\n\n\n\n\n\n\n\nThere appears to be one day with a very small number of bike rentals. What was the day? Why were the number of bike rentals so low on that day? Hint: You can Google the date to figure out what was going on that day."
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-2",
    "href": "ae/ae-03-slr.html#exercise-2",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nIn the raw data, seasons are coded as 1, 2, 3, 4, numeric values that correspond to winter, spring, summer, and fall respectively. Complete the code below to make season a categorical variable with levels corresponding to season names stored in the original order.\n\nbikeshare &lt;- bikeshare |&gt;\n  mutate(season = case_when(\n    season == 1 ~ \"Winter\", \n    season == 2 ~ \"Spring\", \n    season == 3 ~ \"Summer\", \n    season == 4 ~ \"Fall\"\n  ))"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-3",
    "href": "ae/ae-03-slr.html#exercise-3",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe want to evaluate whether the relationship between temperature and daily bike rentals is the same for each season. To answer this question, begin by creating a scatter plot of daily bike rentals vs. temperature faceted by season.\n\n# add code developed during livecoding here"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-4",
    "href": "ae/ae-03-slr.html#exercise-4",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nWhich season appears to have the strongest relationship between temperature and daily bike rentals? Why do you think the relationship is strongest in this season?\nWhich season appears to have the weakest relationship between temperature and daily bike rentals? Why do you think the relationship is weakest in this season?"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-5",
    "href": "ae/ae-03-slr.html#exercise-5",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nFilter your data for the season with the strongest apparent relationship between temperature and daily bike rentals.\n\n# add code developed during livecoding here"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-6",
    "href": "ae/ae-03-slr.html#exercise-6",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nUsing the data from Exercise 5, fit a linear model to predict daily bike rentals using temperature for this season.\n\n# add code developed during livecoding here"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-7",
    "href": "ae/ae-03-slr.html#exercise-7",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nUse the output to write out the estimated regression equation."
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-8",
    "href": "ae/ae-03-slr.html#exercise-8",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nInterpret the slope in the context of the data.\nDoes it make sense to interpret the intercept? If so, interpret the intercept in the context of the data. Otherwise, explain why not."
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-9",
    "href": "ae/ae-03-slr.html#exercise-9",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nSuppose you work for a bike share company in Durham, NC, and they want to predict daily bike rentals in 2024. What is one reason you might recommend they use your analysis for this task? What is one reason you would recommend they not use your analysis for this task?"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html",
    "href": "ae/ae-09-prob-odds.html",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-09 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-1",
    "href": "ae/ae-09-prob-odds.html#exercise-1",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nWhat is the probability a randomly selected respondent has heard a lot about AI?\nWhat are the odds a randomly selected respondent has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-2",
    "href": "ae/ae-09-prob-odds.html#exercise-2",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWhat is the probability a randomly selected respondent who is concerned about increased use of AI in daily life has heard a lot about AI?\nWhat are the odds a randomly selected respondent who is concerned about increased use of AI in daily life has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-3",
    "href": "ae/ae-09-prob-odds.html#exercise-3",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 3",
    "text": "Exercise 3\nMake a plot to visualize the relationship between how much a respondent has heard about AI and being concerned with increased use of AI in daily life. Use the plot to describe the relationship between the two variables."
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-4",
    "href": "ae/ae-09-prob-odds.html#exercise-4",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nHow do the odds of being concerned about increased use of AI in daily life for a randomly selected respondent who has heard nothing about AI compare to the odds for a randomly selected respondent who has heard a lot about AI?\nHow do the odds of being concerned about increased use of AI in daily life for a randomly selected respondent who has heard a little about AI compare to the odds for a randomly selected respondent who has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-5",
    "href": "ae/ae-09-prob-odds.html#exercise-5",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 5",
    "text": "Exercise 5\nWe can use a logistic regression model to understand the relationship between how much someone has heard about AI and whether they are concerned about increased use of AI in daily life. (We will discuss this in detail next class, but will get a preview for now.)\nLet \\(p\\) be the probability a randomly selected respondent is concerned about increased use of AI in daily life. The statistical model is\n\\[\n\\begin{aligned}\n\\log\\Big(\\frac{p_i}{1-p_i}\\Big) = \\beta_0 &+ \\beta_1\\boldsymbol{1}(ai\\_heard_i = \\text{A little}) \\\\ &+ \\beta_2\\mathbf{1}(ai\\_heard_i = \\text{Nothing}) \\\\  &+ \\beta_3\\mathbf{1}(ai\\_heard_i = \\text{Refused})\n\\end{aligned}\n\\]\nThe code and output to fit this model is shown below:\n\nai_concern_fit &lt;- glm(ai_concern ~ ai_heard, data = pew_data,\n                      family = \"binomial\")\ntidy(ai_concern_fit) |&gt; \n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.065\n0.031\n-2.082\n0.037\n\n\nai_heardA little\n0.383\n0.040\n9.504\n0.000\n\n\nai_heardNothing at all\n-0.276\n0.079\n-3.505\n0.000\n\n\nai_heardRefused\n-0.697\n0.459\n-1.520\n0.129\n\n\n\n\n\n\nInterpret the intercept in the context of the data in terms of the log-odds of being concerned about increased use of AI in daily life.\nInterpret the coefficient of ai_heardA little in the context of the data in terms of the log-odds of being concerned about increased use of AI in daily life.\nInterpret the coefficient of ai_heardNothing at all in the context of the data in terms of the odds of being concerned about the increased use of AI in daily life. How does this compare to your response to Exercise 4?\n\n\n\n\n\n\n\nImportantSubmission\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "support.html",
    "href": "support.html",
    "title": "Course support",
    "section": "",
    "text": "We expect everyone will have questions at some point in the semester, so we want to make sure you can identify when that is and feel comfortable seeking help.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#lectures-and-labs",
    "href": "support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#office-hours",
    "href": "support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage you to take advantage of them!\nMake a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours on the course Canvas site.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#ed-discussion",
    "href": "support.html#ed-discussion",
    "title": "Course support",
    "section": "Ed Discussion",
    "text": "Ed Discussion\nOutside of class and office hours, any general questions about course content or assignments should be posted on Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts on Ed Discussion before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#email",
    "href": "support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nIf you have questions about personal matters that are not appropriate for the class discussion forum (e.g. illness, accommodations, etc.), you may me at maria.tackett@duke.edu. If you email me, please include “STA 210” in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#academic-support",
    "href": "support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#mental-health-and-wellness",
    "href": "support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\n\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well being. If you have concerns about a student’s behavior or health visit the website for resources and assistance. Go to studentaffairs.duke.edu/dukereach\nCounseling and Psychological Services (CAPS): CAPS services include individual, group, and couples counseling services, health coaching, psychiatric services, and workshops and discussions. (919) 660-1000 or students.duke.edu/wellness/caps\nTimelyCare (formerly known as Blue Devils Care): An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#technology-accommodations",
    "href": "support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nHighly aided students who have limited access to computers may request loaner laptops through the DukeLIFE Technology Assistance Program. Please note that supplies are limited.\nNote that we will be using Duke’s computational resources in this course. These resources are freely available to you. As long as your computer can connect to the internet and open a browser window, you can perform the necessary computing for this course. All software we use is open-source and/or freely available.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#course-materials-costs",
    "href": "support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.).",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#assistance-with-zoom-or-canvas",
    "href": "support.html#assistance-with-zoom-or-canvas",
    "title": "Course support",
    "section": "Assistance with Zoom or Canvas",
    "text": "Assistance with Zoom or Canvas\nFor technical help with Canvas or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Canvas here.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Duke University Department of Statistical Science, go to the Duke Container Manager website, cmgr.oit.duke.edu/containers.\nIf this is your first time accessing the containers, click on reserve STA210 on the Reservations available menu on the right. You only need to do this once, and when you do, you’ll see this container moved to the My reservations menu on the left.\nNext, click on STA210 under My reservations to access the RStudio instance you’ll use for the course.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio containers\n🔗 for Duke Container Manager\n\n\nCourse GitHub organization\n🔗 for GitHub\n\n\nCourse Canvas site\n🔗 for Canvas\n\n\nDiscussion forum\n🔗 to Ed Discussion\n\n\nAssignment submission\n🔗 to Gradescope",
    "crumbs": [
      "Useful links"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "STA 210 Syllabus",
    "section": "",
    "text": "Lecture\nTue & Thu 3:05 - 4:20pm\nOld Chemistry 116\n\n\nLab 01\nMon 3:05 - 4:20pm\nOld Chemistry 001\n\n\nLab 02\nMon 4:40 - 5:55pm\nPerkins Link #5\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nRole\n\n\n\n\nProf. Maria Tackett\nInstructor\n\n\nSylvia Vincent\nHead TA\nLab 01L leader\n\n\nIshrit Gupta\nLab 02L leader\n\n\nKareena Legare\nLab 01L helper\n\n\n\nSee Canvas for office hours.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-info",
    "href": "syllabus.html#course-info",
    "title": "STA 210 Syllabus",
    "section": "",
    "text": "Lecture\nTue & Thu 3:05 - 4:20pm\nOld Chemistry 116\n\n\nLab 01\nMon 3:05 - 4:20pm\nOld Chemistry 001\n\n\nLab 02\nMon 4:40 - 5:55pm\nPerkins Link #5\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nRole\n\n\n\n\nProf. Maria Tackett\nInstructor\n\n\nSylvia Vincent\nHead TA\nLab 01L leader\n\n\nIshrit Gupta\nLab 02L leader\n\n\nKareena Legare\nLab 01L helper\n\n\n\nSee Canvas for office hours.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "STA 210 Syllabus",
    "section": "Course description",
    "text": "Course description\nIn STA 210, students will learn how linear and logistic regression models are used to explore multivariable relationships and apply these methods to answer relevant and engaging questions using a data-driven approach. Students will develop computing skills to implement a reproducible data analysis workflow and gain experience communicating statistical results. Throughout the semester, students will work on a team project where they will develop a research question, answer it using methods learned in the course, and share results through a written report and presentation.\nTopics include applications of linear and logistic regression, interpretation, diagnostics, model selection, and model assessment. Students will gain experience using the computing tools R and GitHub to analyze real-world data from a variety of fields. This class emphasizes data analysis over mathematical theory.\n\nPrerequisites\n100-level Statistical Science course or Statistical Science 230, 231, or 240L",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-learning-objectives",
    "href": "syllabus.html#course-learning-objectives",
    "title": "STA 210 Syllabus",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze real-world data to answer questions about multivariable relationships.\nuse R to fit and evaluate linear and logistic regression models.\nassess whether a proposed model is appropriate and describe its limitations.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "STA 210 Syllabus",
    "section": "Course materials",
    "text": "Course materials\nWhile there is no official textbook for the course; readings will primarily be made available as they are assigned. We will use the statistical software R. Students will be able to access R through Docker containers provided by Duke Office of Information Technology. See the computing page for more information.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-community",
    "href": "syllabus.html#course-community",
    "title": "STA 210 Syllabus",
    "section": "Course community",
    "text": "Course community\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive. Please update your gender pronouns in Duke Hub. You can find instructions to do so here. You can learn more at the Center for Sexual and Gender Diversity’s website.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website, https://sta210-sp25.netlify.app.\nLinks to Zoom meetings may be found in Canvas. Periodic announcements will be sent via email and will also be available through Ed Discussion and Canvas Announcements. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nEmail\nIf you have questions about assignment extensions, accommodations, or any other matter not appropriate for the class discussion forum, please email me directly at maria.tackett@duke.edu. If you email me, please include “STA 210” in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#five-tips-for-success",
    "href": "syllabus.html#five-tips-for-success",
    "title": "STA 210 Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. Your TAs and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TAs, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you’re not sure about the homework, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings and other preparation work.\nDo the homework and lab.The earlier you start, the better. It’s not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example.)\nDon’t procrastinate. The content builds upon what was taught in previous weeks, so if something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, etc. Don’t let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours and work with a member of the teaching team to help you identify a good (re)starting point.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#getting-help-in-the-course",
    "href": "syllabus.html#getting-help-in-the-course",
    "title": "STA 210 Syllabus",
    "section": "Getting help in the course",
    "text": "Getting help in the course\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours1 to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. You are encouraged to use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the class discussion forum Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts in Ed Discussion before adding a new question. If you know the answer to a question posted in the discussion forum, you are encouraged to respond!\n\nCheck out the Support page for more resources.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#what-to-expect-in-the-course",
    "href": "syllabus.html#what-to-expect-in-the-course",
    "title": "STA 210 Syllabus",
    "section": "What to expect in the course",
    "text": "What to expect in the course\n\nLectures and labs\nLectures and labs are designed to be interactive, so you gain experience applying new concepts and learning from each other. My role as instructor is to introduce you to new methods, tools, and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities during the lectures and labs. You are expected to prepare for class by completing assigned readings, attend all lecture and lab sessions, and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded based on completing what we do in class.\nYou are expected to bring a laptop, tablet, or any device with internet and a keyboard to each class so that you can participate in the in-class exercises. Please make sure your device is fully charged before you come to class, as the number of outlets in the classroom will not be sufficient to accommodate everyone.\n\n\nTeams\nYou will be assigned to a team at the beginning of the semester. You are encouraged to sit with your teammates in lecture and you will also work with them in the lab sessions. All team members are expected to contribute equally to the completion of the group activities, labs and the final project. You will be asked to complete teamwork evaluations and self-reflections throughout the semester. Failure to adequately contribute to an assignment can result in a penalty to your score relative to the team’s overall mark.\nYou are expected to make use of the provided GitHub repository as the central collaborative platform. Commits to this repository will be used as one of several metrics of each team member’s relative contribution for each project.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#activities-assessment",
    "href": "syllabus.html#activities-assessment",
    "title": "STA 210 Syllabus",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nYou will be assessed based on six components: application exercises, homework, labs, exams, project, and teamwork.\n\nLabs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation and communication. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s Git repository in the course’s GitHub organization as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab, and there will be periodic peer evaluation on the team collaboration. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks and explain concepts. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be two exams in this course. Each exam will include a closed-notes in-class component and an open-note take-home component. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. The exams will focus on both conceptual understanding and application through analysis and computational tasks. The exams will be based on content in reading assignments, lectures, application exercises, homework, and lab assignments. More detail about the exams will be given during the semester.\n\n\nProject\nThe purpose of the final project is to apply what you’ve learned to analyze an interesting data-driven research question. The project will be completed with your lab teams, and each team will present their work through a written report and presentation. More information about the project will be provided during the semester. You can learn more on the final project page.\n\n\nParticipation (Application exercises + teamwork)\n\nApplication exercises\nYou will get the most out of the course if you actively participate in class and when working with your team. Parts of some lectures will be dedicated to working on Application Exercises (AEs). AEs are submitted by pushing your work to the relevant GitHub repo.\nAEs will be graded based on making a good-faith effort to attempt all questions covered in class. You are welcome to, but not required, to work on AEs beyond lecture.\nSuccessful effort on at least 80% of AEs will result in full credit for AEs in the final course grade.\n\n\nTeamwork\nGiven the collaborative nature of statistics and data science work, teamwork will be a key part of this course. You will work in teams for in-class activities, lab assignments, and the final course project. There will be periodic peer and self-evaluations to reflect on the team’s collaboration. These evaluations will be counted as part of the participation grade.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "STA 210 Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n30%\n\n\nFinal project\n15%\n\n\nLabs\n10%\n\n\nExam 01\n20%\n\n\nExam 02\n20%\n\n\nParticipation (AEs + Teamwork)\n5%\n\n\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "STA 210 Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nDuke Community Standard\nAll students must adhere to the Duke Community Standard(DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard, students agree:\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;and\nI will act if the Standard is compromised.\n\n\n\n\n\n\nAcademic honesty\nTL;DR: Don’t cheat!\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nFor the projects and team labs, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project or team labs across teams.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of artificial intelligence (AI): You should treat AI tools, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:2 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning. (2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\nAI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\nNo AI tools for narrative: Unless instructed otherwise, AI is not permitted for writing narrative on assignments. In general, you may use AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\n\nIf you are unsure if the use of a particular resource complies with the academic honesty policy, please ask a member of the teaching team.\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one’s own work, following proper citation of sources, adhering to guidance around group work projects,and more).Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback in a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nHomework and labs may be submitted up to 2 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThe late work policy for exams will be provided with the exam instructions.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email me at maria.tackett@duke.edu before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let me know if you need help contacting your academic dean.\n\n\nRegrade Requests\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the final project presentations.\n\n\nAttendance policy\nEvery student is expected to attend and participate in lecture and labs. There may be times, however, when you cannot attend class. Lecture recordings are available upon request for students who have an excused absence. See the Lecture recording request policy for more detail. If you miss a lecture, make sure to review the material and complete the application exercise, if applicable, before the next lecture. Labs dedicated to completing the lab assignment and collaborating with your lab team. If you miss a lab session, make sure to communicate with your lab TA and teammates about how you can make up your contribution. If you know you’re going to miss a lab session and you’re feeling well enough to do so, notify your lab TA and teammates ahead of time.\nMore details on Trinity attendance policies are available here.\n\n\nLecture recording request\nLectures will be recorded on Panopto and will be made available to students with an excused absence upon request. Videos shared with such students will be available for a week after the lecture date. To request a particular lecture’s video, please fill out the form at the link below. Please submit the form within 24 hours of missing lecture to ensure you have sufficient time to watch the recording. Please also make sure that any official documentation, such as STINFs, Dean’s excuses, NOVAPs, and quarantine/removal from class notices from student health are also uploaded to the form.\n🔗 https://forms.office.com/r/RPkWfBB4vf\nAbout one week before each exam, the class recordings will be available to all students. These recordings will be available until the start of the exam.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#accommodations",
    "href": "syllabus.html#accommodations",
    "title": "STA 210 Syllabus",
    "section": "Accommodations",
    "text": "Accommodations\n\nAcademic accommodations\nIf you need accommodations for this class, you will need to register with the Student Disability Access Office (SDAO) and provide them with documentation related to your needs. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.\n\n\nReligious accommodations\nStudents are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: trinity.duke.edu/undergraduate/academic-policies/religious-holidays",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#academic-and-wellness-support",
    "href": "syllabus.html#academic-and-wellness-support",
    "title": "STA 210 Syllabus",
    "section": "Academic and wellness support",
    "text": "Academic and wellness support\n\nAcademic Resource Center\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.\n\n\nCAPS\nDuke Counseling & Psychological Services (CAPS) helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS recognizes that we are living in unprecedented times and that the changes, challenges and stressors brought on by the COVID-19 pandemic have impacted everyone, often in ways that are tax our well-being. CAPS offers many services to Duke undergraduate students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#important-dates",
    "href": "syllabus.html#important-dates",
    "title": "STA 210 Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nJanuary 8: Classes begin\nJanuary 20: Martin Luther King Jr. Day holiday.\nJanuary 22: Drop/Add ends\nMarch 10 - 14: Spring break\nMarch 26: Last day to withdraw with “W”\nNovember 27 - 29: Thanksgiving recess\nApril 23: Classes end\nApril 24 - 27: Reading period\nApril 28 - May 3: Final exam period\n\nClick here for the full Duke academic calendar.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "STA 210 Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOffice hours are times the teaching team set aside each week to meet with students. Click here to learn more about how to effectively use office hours.↩︎\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D.↩︎↩︎",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "website-files/index.html",
    "href": "website-files/index.html",
    "title": "website-files",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Sunday, February 16\nProject proposal due Thursday, February 27\nExploratory data analysis due Thursday, March 20\nPresentation + Presentation comments due Monday, March 31 (in lab)\nAnalysis draft + peer review due Monday, 21 (peer review in lab)\nWritten report due Wednesday, April 30\nProject highlights due Friday, May 2\nReproducibility + organization due Friday, May 2\nFinal project survey due Saturday, May 3",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-milestones",
    "href": "project.html#project-milestones",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Sunday, February 16\nProject proposal due Thursday, February 27\nExploratory data analysis due Thursday, March 20\nPresentation + Presentation comments due Monday, March 31 (in lab)\nAnalysis draft + peer review due Monday, 21 (peer review in lab)\nWritten report due Wednesday, April 30\nProject highlights due Friday, May 2\nReproducibility + organization due Friday, May 2\nFinal project survey due Saturday, May 3",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#introduction",
    "href": "project.html#introduction",
    "title": "Final project",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio using Quarto and GitHub, and your analysis and written report must be reproducible.\n\nLogistics\nYou will work on the project with your lab groups. The primary deliverables for the project are\n\nan in-person presentation about the exploratory data analysis and initial modeling\na written, reproducible final report detailing your analysis\na summary of your project highlights to share with the class\na GitHub repository containing all work from the project\n\nThere are intermediate milestones and peer review assignments throughout the semester to help you work towards the primary deliverables.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#research-topics",
    "href": "project.html#research-topics",
    "title": "Final project",
    "section": "Research topics",
    "text": "Research topics\nThe goal of this milestone is to discuss topics and develop potential research questions your team is interested in investigating for the project. You are only developing ideas at this point; you do not need to have a data set identified right now.\nDevelop three potential research topics. Include the following for each topic:\n\nA brief description of the topic\nA statement about your motivation for investigating this topic\nThe potential audience(s), i.e., who might be most interested in this research?\nTwo or three potential research questions you could analyze about this topic. (Note: These are draft questions at this point. You will finalize the questions in the next stage of the project.)\nIdeas about the type of data you might use to answer this question or potential data sets you’re interested in using. (Note: The goal is to generate ideas at this point, so it is fine if you have not identified any particular data sets at this point.)\n\n\nSubmission\nWrite your responses in research-topics.qmd in your team’s project GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Sunday, February 16 at 11:59pm. There is no Gradescope submission.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-proposal",
    "href": "project.html#project-proposal",
    "title": "Final project",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is for your team to identify the data set you’re interested in analyzing to investigate one of your potential research topics. You will also do some preliminary exploration of the response variable and begin thinking about the modeling strategy. If you’re unsure where to find data, you can use the list of potential data sources on the Tips + resources page as a starting point.\n\n\n\n\n\n\nImportant\n\n\n\nYou must use the data set(s) in the proposal for the final project, unless instructed otherwise when given feedback.\n\n\nThe data set must meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.\n\ne.g., identifier variables such as “name”, “ID number”, etc. are not useful predictor variables.\ne.g., if you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nMay not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n\n\n\n\n\n\nWarningTypes of data sets to avoid\n\n\n\n\nData that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nData sets in which there is no information about how the data were originally collected\nData sets in which there are missing or unclear definitions about the observations and/or variables\n\n\n\nAsk a member of the teaching team if you’re unsure whether your data set meets the criteria.\nThe proposal will include the following sections:\n\nSection 1: Introduction\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the Research Topics milestone.\n\n\n\nAn introduction to the subject matter you’re investigating (citing any relevant literature)\nStatement of a well-developed research question.\nThe motivation for your research question and why it is important\nYour team’s hypotheses regarding the research question\n\nThis is a narrative about what you think regarding the research question, not formal statistical hypotheses.\n\n\n\n\nSection 2: Data description\n\nThe source of the data set\nA description of when and how the data were originally collected (by the original data curator, not necessarily how you found the data)\nA description of the observations and general characteristics being measured\n\n\n\nSection 3: Data processing\n\nDescription of data processing you need to do to prepare for analysis, such as joining multiple data sets, handling missing data, etc.\nVisualizations, summary statistics, and narrative to describe the distribution of the response variable.\n\n\n\nSection 4: Analysis approach\n\na description of the potential predictor variables of interest\nregression model technique (multiple linear regression for quantitative response variable or logistic regression for a categorical response variable)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of the data folder. You do not need to include the data dictionary in the PDF document.\n\n\nSubmission\nWrite your narrative and analysis for Sections 1 - 4 in the proposal.qmd file in your team’s GitHub repo. Put the data set and the data dictionary in the data folder in the repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Thursday, February 27 at 11:59pm.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages.\nThe proposal is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.\n\nExcellent (5 points) : All required elements are completed and are accurate. The data set meets the requirements (or the team has otherwise discussed the data with Professor Tackett) and the data do not pose obvious violations to the modeling assumptions. There is a thoughtful and comprehensive description of the data, any data processing, and exploration of the response variable as described above. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong (3 - 4 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.\nSatisfactory (2 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (1 point): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#eda",
    "href": "project.html#eda",
    "title": "Final project",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the previous milestones.\n\n\nThe purpose of this milestone is begin exploring the data and get early feedback on your data and analysis. You will submit a draft of the beginning of your report that includes the introduction and exploratory data analysis, with an emphasis on the EDA. It will also help you prepare for the presentation of the exploratory data analysis results.\nBelow is a brief description of the sections to include in this step:\n\nIntroduction\nThis section includes an introduction to the project motivation, background, data, and research question.\n\n\nExploratory data analysis\nThis section includes the following:\n\nDescription of the data set and key variables.\nExploratory data analysis of the response variable and key predictor variables.\n\nUnivariate EDA of the response and key predictor variables.\nBivariate EDA of the response and key predictor variables\nPotential interaction effects.\n\n\n\n\nSubmission\nWrite your draft introduction and exploratory data analysis in the written-report.qmd file in your team’s GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc. with code, warnings, and messages suppressed is about 4 - 6 pages (It is OK to be over this page limit at this stage in the project.)\n\n\n\n\n\n\nTip\n\n\n\nYou can save space by suppressing code, warnings, and messages by including the following in the YAML:\nexecute:\n  echo: false\n  message: false\n  warning: false\n\n\nThe exploratory data analysis is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above, along with incorporating the feedback from the proposal. Points will be assigned based on a holistic review of the exploratory data analysis.\n\nExcellent (9 - 10 points) : All required elements are completed and are accurate. There is a thorough exploration of the data as described above, and the team has demonstrated a careful and thoughtful approach exploring the data and preparing it for analysis. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong: (7 - 8 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some revision of the work required before team is ready for modeling.\nSatisfactory (5 - 6 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (4 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#presentation",
    "href": "project.html#presentation",
    "title": "Final project",
    "section": "Presentation",
    "text": "Presentation\n\n\n\n\n\n\nImportant\n\n\n\nPresentations will take place in class during labs. Presentation order will be announced in advance.\n\n\nYour team will do an in-person presentation that summarizes and showcases the work you’ve done on the project thus far. Because the presentations will take place while you’re still working on the project, it will also be an opportunity to receive feedback and suggestions as well as provide feedback to other teams. The presentation will focus on introducing the subject matter and research question, showcase key results from the exploratory data analysis, and discuss primary modeling strategies and/or results. The presentation should be supported by slides that serve as a brief visual addition to the presentation. The presentation and slides will be graded for content and clarity.\nYou can create your slides with any software you like (e.g., Keynote, PowerPoint, Google Slides, etc.). You can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\nThe presentation is expected to be between 5 to 8 minutes. It may not exceed 8 minutes, due to the limited time during lab.\nEvery team member is expected to speak in the presentation. Part of the grade will be whether every team member had a meaningful speaking role in the presentation.\n\nSlides\nThe slide deck should have no more than 6 content slides + 1 title slide to ensure you have enough time to discuss each slide. s Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the subject, motivation, and research question\nSlide 2: Introduce the data set\nSlide 3 - 4: Highlights from the EDA (be sure to include EDA for the response variable!)\nSlide 5: Initial modeling strategies / results (if applicable)\nSlide 6: Next steps and any questions you’d like to get feedback on\n\n\n\nSubmission\nYou can submit the presentation slides in two ways:\n\nPut a PDF of the slides or Quarto slides in the presentation folder in your team’s GitHub repo.\nPut the URL to your slides in the README of the presentation folder. If you share the URL, please make sure permissions are set so Prof. Tackett can view the slides.\n\n\n\n\n\n\n\nImportant\n\n\n\nSlides must be submitted by the start of your lab on the day of presentations. We will use a classroom computer for the presentations.\n\n\n\n\nGrading\nThe presentation is worth points. It will be graded based on the following:\n\nContent: The team told a unified story that clearly introduced the subject matter, research question, and exploration of the data.\nSlides: The presentation slides were organized, included clear and informative visualizations, and were easily readable.\nPresentation: The team’s communication style was clear and professional. The team divided the time well and stayed within the 8 minute time limit, with each team member making a meaningful contribution to the presentation.\n\n80% of the presentation grade will be the average of the teaching team scores and 20% will be the average of the peer scores.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#presentation-comments",
    "href": "project.html#presentation-comments",
    "title": "Final project",
    "section": "Presentation comments",
    "text": "Presentation comments\n\n\n\n\n\n\nImportant\n\n\n\nClick here to see the teams you’re scoring and a link to the feedback form.\nThis portion of the project is worth 2 points and will be assessed individually.\n\n\nYou will provide feedback on two teams’ presentations. The assigned teams and link to the feedback form will be available in advance of the presentations. Please provide all scores and comments by the end of the lab session. There will be a few minutes between each presentation to submit scores and comments.\nThe grade will be based on submitting the scores and comments for both of your assigned teams by the end of the presentation day.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#draft-report-peer-review",
    "href": "project.html#draft-report-peer-review",
    "title": "Final project",
    "section": "Analysis + peer review",
    "text": "Analysis + peer review\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\n\nDraft report\nWrite the draft in the written-report.qmd file in your project repo.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the body of the report, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model.\n\n\nGrading\nThe draft will be graded based on whether there is demonstration of a reasonable attempt at each of the sections described below in the written report file in the GitHub repo by the deadline.\n\n\n\nPeer review\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams’ projects to review. Each team should push their draft to their GitHub repo by 10 am on the day their lab’s draft is due. The lab that week will be dedicated to the peer review, so your team will have time to review and provide quality feedback to two other teams.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided in the repo.\n\nSteps for peer review\n\n\n\n\n\n\nImportantPeer review assignments\n\n\n\nClick here to see the teams you’re peer reviewing.You’ll spend about 30 minutes reviewing each project.\n\n\n\nWhen you get to lab, you should have access to the GitHub repos for the teams you’re reviewing. In GitHub, search the repositories for project, and you should see the repos for the projects you’re reviewing. You will be able to read the files in the repo and post issues, but you cannot push changes to the repo. You will have access to the repo until the deadline for the peer review.\nYou may choose to all work on both peer reviews or have some team members focus on a single peer review. Either way there will be one peer review grade assigned per team.\nFor each team you’re reviewing:\n\nOpen that team’s repo, read the project draft, and browse the rest of the repo.\nGo to the Issues tab in that repo, click on New issue, and click on Get started for the Peer Review issue. Write your responses to the prompts in the issue. You will answer the following questions:\n\nDescribe the goal of the project.\nDescribe the data set used in the project. What are the observations in the data? What is the source of the data? How were the data originally collected?\nConsider the exploratory data analysis (EDA). Describe one aspect of the EDA that is effective in helping you understand the data. Provide constructive feedback on how the team might improve the EDA.\nDescribe the statistical methods, analysis approach, and discussion of model assumptions, diagnostics, model fit.\nProvide constructive feedback on how the team might improve their analysis. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but also feel free to comment on aspects beyond the modeling.\nProvide constructive feedback on the interpretations and initial conclusion. What is most effective in the presentation of the results? What additional detail can the team provide to make the results and conclusions easier for the reader to understand?\nWhat aspect of this project are you most interested in and think would be interesting to highlight in the written report?\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?\n\n\n\n\n\nGrading\nThe peer review will be graded on the extent to which each comprehensively and constructively addresses the components on the peer review form. There will be one peer review grade per team.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#written-report",
    "href": "project.html#written-report",
    "title": "Final project",
    "section": "Written report",
    "text": "Written report\n\n\n\n\n\n\nImportant\n\n\n\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the code chunks are not visible and all messages and warnings are suppressed.\n\n\n\nYou will submit the PDF of your final report on GitHub.\nThe PDF you submit must match the .qmd in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including tables and visualizations, must be no more than 10 pages long. There is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will overwhelmingly be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the variables in the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.\n\n\n\nResults\nThis is where you will output and discuss the final model.\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe model fit is clearly assessed, and interesting findings from the model are clearly described. The model conditions and diagnostics are thoroughly and accurately assessed for the final model, if not previously discussed in the methodology. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model’s predictive power is thoroughly assessed.\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted and labeled. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-highlights",
    "href": "project.html#project-highlights",
    "title": "Final project",
    "section": "Project highlights",
    "text": "Project highlights\n\n\n\n\n\n\nImportant\n\n\n\nYour project highlights will be posted as a reply to the “Final project highlights” thread under the Discussions tab on Canvas.\nYou are welcome to but not required to put the highlights in your project repo.\n\n\nThe project highlights are an opportunity to share an overview of your project and final results with your peers! Choose one of the following formats to share your highlights:\n\nOption 1: Structured Abstract\nA structured abstract extends on a traditional abstract by separating the content into separate sections. The abstract will be about 200 - 400 words and will be split into the following sections:\n\nProject title\nBackground (also called Objectives in some journals)\nMethods\nResults\nConclusions\n\nBelow are some examples of structured abstracts. These examples are here to give you an idea of what a structured abstract looks like; you are not required (or expected) to exactly replicate any one of these abstracts.\n\n\nStructured abstract example 1\nStructured abstract example 2\nTips for writing abstracts (see Example Abstract 4: A Structured Abstract)\n\n\n\nOption 2: Summary slides\nThis is a good option if you would like to include some visualizations and output along with a short narrative describing the project highlights. These slides can be organized similarly as the structured abstract (option 1) with a slide for each section:\n\nTitle slide\nBackground\nMethods\nResults\nConclusions\n\n\n\nOption 3: Summary video\nThis is a good option if you would like to record a short presentation sharing your project highlights. You may use slides following a similar structure as Option 2 or find another creative way to present your results! The video should be no longer that 3 minutes.\n\n\nGrading criteria\nThe project highlights will be graded based on how clarity of the summary and neatly done abstracts, slides, or video.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#reproducibility-organization",
    "href": "project.html#reproducibility-organization",
    "title": "Final project",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Project title and team name\n\nOptional: Short project summary\n\nwritten-report.qmd & written-report.pdf: Final written report\nproposal.qmd & proposal.pdf: Project proposal\nresearch-topics.qmd & research-topics.pdf: Proposed research questions\n/data: Folder that contains the data set for the final project.\n\n/data/README.md: Data dictionary and source for data set\n\nproject.Rproj: File specifying the RStudio project\n/presentation: Folder with the presentation slides or link to slides.\n.gitignore: File that lists all files that are in the local RStudio project but not the GitHub repo\n/.github: Folder for peer review issue template\nAny other files should be neatly organized into clearly labeled folders.\n\nUpdate the README of the project repo with your project title and team members’ names.\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#final-project-survey",
    "href": "project.html#final-project-survey",
    "title": "Final project",
    "section": "Final project survey",
    "text": "Final project survey\nYou will complete a short survey about the project. You will receive the survey via email.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#peer-teamwork-evaluation",
    "href": "project.html#peer-teamwork-evaluation",
    "title": "Final project",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nThere will be an opportunity to provide feedback to Professor Tackett about each team member’s contribution to the project. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#overall-grading",
    "href": "project.html#overall-grading",
    "title": "Final project",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nResearch topics\n3 pts\n\n\nProject proposal\n5 pts\n\n\nExploratory data analysis\n10 pts\n\n\nPresentation\n10 pts\n\n\nPresentation comments\n2 pts\n\n\nDraft report + peer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nProject highlights\n15 pts\n\n\nReproducibility + organization\n3 pts\n\n\nProject survey\n2 pts\n\n\n\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Team understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Team understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Team has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Team is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%*: Team is not making a sufficient effort.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#late-work-policy",
    "href": "project.html#late-work-policy",
    "title": "Final project",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.\nBe sure to turn in your work early to avoid any technological mishaps.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  }
]