[
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you’re having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you’ll find an entry called Container Manager (CMGR Coursework Containers).",
    "crumbs": [
      "Computing",
      "Troubleshooting"
    ]
  },
  {
    "objectID": "computing-troubleshooting.html#footnotes",
    "href": "computing-troubleshooting.html#footnotes",
    "title": "Computing troubleshooting",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThese troubleshooting steps are from https://sta199-f25.github.io/computing-troubleshooting.html↩︎",
    "crumbs": [
      "Computing",
      "Troubleshooting"
    ]
  },
  {
    "objectID": "website-files/about.html",
    "href": "website-files/about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "project-draft.html",
    "href": "project-draft.html",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Thursday, February 13\nProject proposal \nExploratory data analysis \nPresentation + Presentation comments \nAnalysis draft + peer review \nWritten report \nProject highlights \nReproducibility + organization \nFinal project survey"
  },
  {
    "objectID": "project-draft.html#project-milestones",
    "href": "project-draft.html#project-milestones",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Thursday, February 13\nProject proposal \nExploratory data analysis \nPresentation + Presentation comments \nAnalysis draft + peer review \nWritten report \nProject highlights \nReproducibility + organization \nFinal project survey"
  },
  {
    "objectID": "project-draft.html#introduction",
    "href": "project-draft.html#introduction",
    "title": "Final project",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio using Quarto and GitHub, and your analysis and written report must be reproducible.\n\nLogistics\nYou will work on the project with your lab groups. The primary deliverables for the project are\n\nan in-person presentation about the exploratory data analysis and initial modeling\na written, reproducible final report detailing your analysis\na summary of your project highlights to share with the class\na GitHub repository containing all work from the project\n\nThere are intermediate milestones and peer review assignments throughout the semester to help you work towards the final deliverables."
  },
  {
    "objectID": "project-draft.html#research-topics",
    "href": "project-draft.html#research-topics",
    "title": "Final project",
    "section": "Research topics",
    "text": "Research topics\nThe goal of this milestone is to discuss topics and develop potential research questions your team is interested in investigating for the project. You are only developing ideas at this point; you do not need to have a data set identified at this point.\nDevelop three potential research topics. Include the following for each topic:\n\nA brief description of the topic\nA statement about your motivation for investigating this topic.\nThe potential audience(s), i.e., who might be most interested in this research?\nTwo or three potential research questions you could analyze about this topic.\nIdeas about the type of data you might use to answer this question or potential data sets you’re interested in using. [Note: The goal is to generate ideas at this point, so it is fine if you have not identified any particular data sets at this point.]\n\n\nSubmission\nWrite your responses in research-topics.qmd in your team’s project GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Thursday, February 13 at 11:59pm."
  },
  {
    "objectID": "project-draft.html#project-proposal",
    "href": "project-draft.html#project-proposal",
    "title": "Final project",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is for your team to identify the data set you’re interested in analyzing to investigate one of your potential research questions. You will also do some preliminary exploration of the response variable and begin thinking about the modeling strategy. If you’re unsure where to find data, you can use the list of potential data sources on the Tips + resources page as a starting point.\n\n\n\n\n\n\nImportant\n\n\n\nYou must the data set(s) in the proposal for the final project, unless instructed otherwise when given feedback.\n\n\nThe data set must meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.\n\ne.g., identifier variables such as “name”, “ID number”, etc. are not useful predictor variables.\ne.g., if you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nMay not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n\n\n\n\n\n\nWarningTypes of data sets to avoid\n\n\n\n\nData that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nData sets in which there is no information about how the data were originally collected\nData sets in which there are missing or unclear definitions about the observations and/or variables\n\n\n\nAsk a member of the teaching team if you’re unsure whether your data set meets the criteria.\nThe proposal will include the following sections:\n\nSection 1: Introduction\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the Research Questions milestone.\n\n\n\nAn introduction to the subject matter you’re investigating (citing any relevant literature)\nStatement of a well-developed research question.\nThe motivation for your research question and why it is important\nYour team’s hypotheses regarding the research question\n\nThis is a narrative about what you think regarding the research question, not formal statistical hypotheses.\n\n\n\n\nSection 2: Data description\n\nThe source of the data set\nA description of when and how the data were originally collected (by the original data curator, not necessarily how you found the data)\nA description of the observations and general characteristics being measured\n\n\n\nSection 3: Initial exploratory data analysis\n\nDescription of data cleaning you need to do to prepare for analysis (can focus on the response variable for now), such as joining data sets, imputing missing values, variable transformation, creating a new variable, etc.\nVisualizations, summary statistics, and narrative to describe the distribution of the response variable.\n\n\n\nSection 4: Analysis approach\n\na description of the potential predictor variables of interest\nregression model technique (multiple linear regression for quantitative response variable or logistic regression for a categorical response variable)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of the data folder. You do not need to include the data dictionary in the PDF document.\n\n\nSubmission\nWrite your narrative and analysis for Sections 1 - 4 in the proposal.qmd file in your team’s GitHub repo. Put the data set and the data dictionary in the data folder in the repo. Push the qmd and rendered pdf documents to GitHub by the deadline.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages.\nThe proposal is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.\n\nExcellent (9 - 10 points) : All required elements are completed and are accurate. The data set meets the requirements (or the team has otherwise discussed the data with Professor Tackett) and the data do not pose obvious violations to the modeling assumptions. There is a thoughtful and comprehensive description of the data and exploration of the response variable as described above. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong (7 - 8 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.\nSatisfactory (5 - 6 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (4 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling."
  },
  {
    "objectID": "project-draft.html#eda",
    "href": "project-draft.html#eda",
    "title": "Final project",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the previous milestones.\n\n\nThe purpose of this milestone is begin exploring the data and get early feedback on your data and analysis. You will submit a draft of the beginning of your report that includes the introduction and exploratory data analysis, with an emphasis on the EDA. It will also help you prepare for the presentation of the exploratory data analysis results.\nBelow is a brief description of the sections to include in this step:\n\nIntroduction\nThis section includes an introduction to the project motivation, background, data, and research question.\n\n\nExploratory data analysis\nThis section includes the following:\n\nDescription of the data set and key variables.\nExploratory data analysis of the response variable and key predictor variables.\n\nUnivariate EDA of the response and key predictor variables.\nBivariate EDA of the response and key predictor variables\nPotential interaction effects.\n\n\n\n\nSubmission\nWrite your draft introduction and exploratory data analysis in the written-report.qmd file in your team’s GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc. with code, warnings, and messages suppressed is about about 4 - 6 pages.\n\n\n\n\n\n\nTip\n\n\n\nYou can suppress code, warnings, and messages by including the following in the YAML:\nexecute: \n  echo: false\n  message: false\n  warning: false\n\n\nThe exploratory data analysis is worth 15 points and will be graded based on accurately and comprehensively addressing the criteria stated above, along with incorporating the feedback from the proposal. Points will be assigned based on a holistic review of the exploratory data analysis.\n\nExcellent (14 - 15 points) : All required elements are completed and are accurate. There is a thorough exploration of the data as described above, and the team has demonstrated a careful and thoughtful approach exploring the data and preparing it for analysis. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong: (11 - 13 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some revision of the work required before team is ready for modeling.\nSatisfactory (8 - 10 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (7 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling."
  },
  {
    "objectID": "project-draft.html#presentation",
    "href": "project-draft.html#presentation",
    "title": "Final project",
    "section": "Presentation",
    "text": "Presentation\n\n\n\n\n\n\nImportant\n\n\n\nPresentations will take place in class during labs. Presentation order will be announced in advance.\n\n\nYour team will do an in-person presentation that summarizes and showcases the work you’ve done on the project thus far. Because the presentations will take place while you’re still working on the project, it will also be an opportunity to receive feedback and suggestions as well as provide feedback to other teams. The presentation will focus on introducing the subject matter and research question, showcase key results from the exploratory data analysis, and discuss primary modeling strategies and/or results. The presentation should be supported by slides that serve as a brief visual addition to the presentation. The presentation and slides will be graded for content and clarity.\nYou can create your slides with any software you like (e.g., Keynote, PowerPoint, Google Slides, etc.). You can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\nThe presentation is expected to be between 5 to 8 minutes. It may not exceed 8 minutes, due to the limited time during lab.\nEvery team member is expected to speak in the presentation. Part of the grade will be whether every team member had a meaningful speaking role in the presentation.\n\nSlides\nThe slide deck should have no more than 6 content slides + 1 title slide to ensure you have enough time to discuss each slide. s Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the subject, motivation, and research question\nSlide 2: Introduce the data set\nSlide 3 - 4: Highlights from the EDA (be sure to include EDA for the response variable!)\nSlide 5: Initial modeling strategies / results\nSlide 6: Next steps and any questions you’d like to get feedback on\n\n\n\nSubmission\nYou can submit the presentation slides in two ways:\n\nPut a PDF of the slides or Quarto slides in the presentation folder in your team’s GitHub repo.\nPut the URL to your slides in the README of the presentation folder. If you share the URL, please make sure permissions are set so Prof. Tackett can view the slides.\n\n\n\n\n\n\n\nImportant\n\n\n\nSlides must be submitted by the start of your lab on the day of presentations. We will use a classroom computer for the presentations.\n\n\n\n\nGrading\nThe presentation is worth points. It will be graded based on the following:\n\nContent: The team told a unified story that clearly introduced the subject matter, research question, and exploration of the data.\nSlides: The presentation slides were organized, included clear and informative visualizations, and were easily readable.\nPresentation: The team’s communication style was clear and professional. The team divided the time well and stayed within the 8 minute time limit, with each team member making a meaningful contribution to the presentation.\n\n80% of the presentation grade will be the average of the teaching team scores and 20% will be the average of the peer scores."
  },
  {
    "objectID": "project-draft.html#presentation-comments",
    "href": "project-draft.html#presentation-comments",
    "title": "Final project",
    "section": "Presentation comments",
    "text": "Presentation comments\n\n\n\n\n\n\nImportant\n\n\n\nClick here to see the teams you’re scoring and a link to the feedback form.\nThis portion of the project is worth 2 points and will be assessed individually.\n\n\nYou will provide feedback on two teams’ presentations. The assigned teams and link to the feedback form will be available in advance of the presentations. Please provide all scores and comments by the end of the lab session. There will be a few minutes between each presentation to submit scores and comments.\nThe grade will be based on submitting the scores and comments for both of your assigned teams by the end of the presentation day, November 11."
  },
  {
    "objectID": "project-draft.html#draft-report-peer-review",
    "href": "project-draft.html#draft-report-peer-review",
    "title": "Final project",
    "section": "Analysis + peer review",
    "text": "Analysis + peer review\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\n\nDraft report\nWrite the draft in the written-report.qmd file in your project repo.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the body of the report, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model.\n\n\nGrading\nThe draft will be graded based on whether there is demonstration of a reasonable attempt at each of the sections described below in the written report file in the GitHub repo by the deadline.\n\n\n\nPeer review\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 221 is no exception. Each lab team will be assigned two other teams’ projects to review. Each team should push their draft to their GitHub repo by 10 am on the day their lab’s draft is due. The lab that week will be dedicated to the peer review, so your team will have time to review and provide quality feedback to two other teams.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided in the repo.\n\nSteps for peer review\n\n\n\n\n\n\nImportantPeer review assignments\n\n\n\nClick here to see the teams you’re peer reviewing.You’ll spend about 30 minutes reviewing each project.\n\n\n\nWhen you get to lab, you should have access to the GitHub repos for the teams you’re reviewing. In GitHub, search the repositories for project, and you should see the repos for the projects you’re reviewing. You will be able to read the files in the repo and post issues, but you cannot push changes to the repo. You will have access to the repo until the deadline for the peer review.\nYou may choose to all work on both peer reviews or have some team members focus on a single peer review. Either way there will be one peer review grade assigned per team.\nFor each team you’re reviewing:\n\nOpen that team’s repo, read the project draft, and browse the rest of the repo.\nGo to the Issues tab in that repo, click on New issue, and click on Get started for the Peer Review issue. Write your responses to the prompts in the issue. You will answer the the following questions:\n\nDescribe the goal of the project.\nDescribe the data set used in the project. What are the observations in the data? What is the source of the data? How were the data originally collected?\nConsider the exploratory data analysis (EDA). Describe one aspect of the EDA that is effective in helping you understand the data. Provide constructive feedback on how the team might improve the EDA.\nDescribe the statistical methods, analysis approach, and discussion of model assumptions, diagnostics, model fit.\nProvide constructive feedback on how the team might improve their analysis. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but also feel free to comment on aspects beyond the modeling.\nProvide constructive feedback on the interpretations and initial conclusion. What is most effective in the presentation of the results? What additional detail can the team provide to make the results and conclusions easier for the reader to understand?\nWhat aspect of this project are you most interested in and think would be interesting to highlight in the written report?\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?\n\n\n\n\n\nGrading\nThe peer review will be graded on the extent to which each comprehensively and constructively addresses the components on the peer review form. There will be one peer review grade per team."
  },
  {
    "objectID": "project-draft.html#written-report",
    "href": "project-draft.html#written-report",
    "title": "Final project",
    "section": "Written report",
    "text": "Written report\n\n\n\n\n\n\nImportant\n\n\n\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the code chunks are not visible and all messages and warnings are suppressed.\n\n\n\nYou will submit the PDF of your final report on GitHub.\nThe PDF you submit must match the .qmd in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including tables and visualizations, must be no more than 10 pages long. There is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will overwhelmingly be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\n\n\nResults\n\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report."
  },
  {
    "objectID": "project-draft.html#project-highlights",
    "href": "project-draft.html#project-highlights",
    "title": "Final project",
    "section": "Project highlights",
    "text": "Project highlights"
  },
  {
    "objectID": "project-draft.html#reproducibility-organization",
    "href": "project-draft.html#reproducibility-organization",
    "title": "Final project",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\nproposal.qmd & proposal.pdf: Project proposal\nresearch-questions.qmd & research-questions.pdf: Proposed research questions\n/data: Folder that contains the data set for the final project.\nproject.Rproj: File specifying the RStudio project\n/presentation: Folder with the presentation slides or link to slides.\n.gitignore: File that lists all files that are in the local RStudio project but not the GitHub repo\n/.github: Folder for peer review issue template\nAny other files should be neatly organized into clearly labeled folders.\n\nUpdate the README of the project repo with your project title and a few sentences (~ 2 -5) describing your final project.\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-draft.html#final-project-survey",
    "href": "project-draft.html#final-project-survey",
    "title": "Final project",
    "section": "Final project survey",
    "text": "Final project survey"
  },
  {
    "objectID": "project-draft.html#peer-teamwork-evaluation",
    "href": "project-draft.html#peer-teamwork-evaluation",
    "title": "Final project",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nThere will be an opportunity to provide feedback to Professor Tackett about each team member’s contribution to the project. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly."
  },
  {
    "objectID": "project-draft.html#overall-grading",
    "href": "project-draft.html#overall-grading",
    "title": "Final project",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nResearch topics\n3 pts\n\n\nProject proposal\n5 pts\n\n\nExploratory data analysis\n10 pts\n\n\nPresentation\n10 pts\n\n\nPresentation comments\n2 pts\n\n\nDraft report + peer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nProject highlights\n15 pts\n\n\nReproducibility + organization\n3 pts\n\n\nProject survey\n2 pts\n\n\n\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort."
  },
  {
    "objectID": "project-draft.html#late-work-policy",
    "href": "project-draft.html#late-work-policy",
    "title": "Final project",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.\nBe sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "project-tips.html",
    "href": "project-tips.html",
    "title": "Final project tips + resources",
    "section": "",
    "text": "Data sources\n\nSome resources that may be helpful as you find data:\n\nFiveThirtyEight data\nTidyTuesday\nData Is Plural\nR Data Sources for Regression Analysis\n\n\n\nOther data repositories\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies\n\n\n\n\nTips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your Qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.\n\n\n\nFormatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\nAn alternative approach is to add the following code to the YAML:\n\nexecute:\n  echo: false\n  warning: false\n  message: false\n\n\n\n\nHeaders\n\nUse headers to clearly label each section. Make sure there is a space between the last # and the title, so the header renders correctly. For example, ###Section Title will not render as header, but ### Section Title will.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\n\nResize plots and figures, so you have more space for the narrative.\n\nResize individual figures: Use the code chunk header {r plot1, fig.height = 3, fig.width = 5}, replacing plot1 with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig_width and fig_height options in your YAML header as shown below:\n\n\n\n---\ntitle: \"Your title\"\nauthor: \"Your names\"\nformat:\n  pdf:\n    fig-width: 7\n    fig-height: 5\n---\nReplace the height and width values with values appropriate for your write up.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\n\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\nIf you’re using base R function, i.e. when using the emplogit functions, put the code par(mfrow = c(rows,columns)) before the code to make the plots. For example, par(mfrow = c(2,3)) will arrange plots in a grid with 2 rows and 3 columns.\n\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\nUse coord_flip() to flip the x and y axes on the plot. This is useful if you a bar plot with an x-axis that is difficult to read due to overlapping text.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg |&gt;\n  count(manufacturer) |&gt;\n  mutate(manufacturer = str_to_title(manufacturer)) |&gt;\n  ggplot(aes(x = fct_reorder(manufacturer,n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  coord_flip() +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_bw() \n\n\n\n\n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel &lt;- lm(mpg ~ hp, data = mtcars)\ntidy(model) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document.\n\n\n\n\nAdditional resources\n\nExploring RStudio’s Visual Markdown Editor\nR for Data Science\nQuarto documentation:\n\nQuarto PDF Basics\nPresentations in Quarto\n\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Duke University Department of Statistical Science, go to the Duke Container Manager website, cmgr.oit.duke.edu/containers.\nIf this is your first time accessing the containers, click on reserve STA210 on the Reservations available menu on the right. You only need to do this once, and when you do, you’ll see this container moved to the My reservations menu on the left.\nNext, click on STA210 under My reservations to access the RStudio instance you’ll use for the course.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "support.html",
    "href": "support.html",
    "title": "Course support",
    "section": "",
    "text": "We expect everyone will have questions at some point in the semester, so we want to make sure you can identify when that is and feel comfortable seeking help.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#lectures-and-labs",
    "href": "support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#office-hours",
    "href": "support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on Canvas to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage you to take advantage of them!\nMake a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours on the course Canvas site.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#ed-discussion",
    "href": "support.html#ed-discussion",
    "title": "Course support",
    "section": "Ed Discussion",
    "text": "Ed Discussion\nOutside of class and office hours, any general questions about course content or assignments should be posted on Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts on Ed Discussion before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#email",
    "href": "support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nIf you have questions about personal matters that are not appropriate for the class discussion forum (e.g. illness, accommodations, etc.), you may me at maria.tackett@duke.edu. If you email me, please include “STA 210” in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#academic-support",
    "href": "support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThe Academic Resource Center (the ARC) offers services to support students academically during their undergraduate careers at Duke. The ARC can provide support with time management, academic skills and strategies, course-specific tutoring, presentation skills, public speaking, and more. ARC services are available free to all Duke undergraduate students studying any discipline. Learn more:\n\nLearning Consultations – time management, study strategies, learning preferences, and more\nVOICE Lab – strengthen public speaking, practice presentations, and more\n\nYou can contact the Academic Resource Center by phone at (919) 684-5917, by email at theARC@duke.edu, or by visiting http://arc.duke.edu/.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#mental-health-and-wellbeing-resources",
    "href": "support.html#mental-health-and-wellbeing-resources",
    "title": "Course support",
    "section": "Mental health and wellbeing resources",
    "text": "Mental health and wellbeing resources\n\nDukeReach provides comprehensive outreach services to support students in managing all aspects of wellbeing, including referrals and follow-up services for students who are experiencing significant challenges related to mental health, physical health, social adjustment, and/or a variety of other stressors. You can contact the DukeReach team at dukereach@duke.edu and/or submit a referral at support.students.duke.edu. \nCounseling and Psychological Services (CAPS) offers counseling services to Duke students including virtual appointments, and referrals in the community. You do not need an appointment for an initial assessment. You may walk in or call 919-660-1000 to get started. Hours: Monday-Friday 9:00am - 4:00pm. After hours counseling services are available at no additional cost to students, you can call: 919-660-1000 Option 2.\nTimelyCare (formerly known as Blue Devils Care) is an online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling.\nDuke Student Health offers a wide range of healthcare services for all Duke students, many of which are covered by the student health fee. To make an appointment call (919) 681-9355. Hours: Monday - Friday, 8am - 4:30pm, Thursday 9am - 4:30pm. Closed from 12-12:30 each day.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#technology-accommodations",
    "href": "support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nHighly aided students who have limited access to computers may request loaner laptops through the DukeLIFE Technology Assistance Program. Please note that supplies are limited.\nNote that we will be using Duke’s computational resources in this course. These resources are freely available to you. As long as your computer can connect to the internet and open a browser window, you can perform the necessary computing for this course. All software we use is open-source and/or freely available.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#course-materials-costs",
    "href": "support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.).",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#assistance-with-zoom-or-canvas",
    "href": "support.html#assistance-with-zoom-or-canvas",
    "title": "Course support",
    "section": "Assistance with Zoom or Canvas",
    "text": "Assistance with Zoom or Canvas\nFor technical help with Canvas or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Canvas here.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "ae/ae-09-prob-odds.html",
    "href": "ae/ae-09-prob-odds.html",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-09 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-1",
    "href": "ae/ae-09-prob-odds.html#exercise-1",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nWhat is the probability a randomly selected respondent has heard a lot about AI?\nWhat are the odds a randomly selected respondent has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-2",
    "href": "ae/ae-09-prob-odds.html#exercise-2",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWhat is the probability a randomly selected respondent who is concerned about increased use of AI in daily life has heard a lot about AI?\nWhat are the odds a randomly selected respondent who is concerned about increased use of AI in daily life has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-3",
    "href": "ae/ae-09-prob-odds.html#exercise-3",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 3",
    "text": "Exercise 3\nMake a plot to visualize the relationship between how much a respondent has heard about AI and being concerned with increased use of AI in daily life. Use the plot to describe the relationship between the two variables."
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-4",
    "href": "ae/ae-09-prob-odds.html#exercise-4",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nHow do the odds of being concerned about increased use of AI in daily life for a randomly selected respondent who has heard nothing about AI compare to the odds for a randomly selected respondent who has heard a lot about AI?\nHow do the odds of being concerned about increased use of AI in daily life for a randomly selected respondent who has heard a little about AI compare to the odds for a randomly selected respondent who has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-5",
    "href": "ae/ae-09-prob-odds.html#exercise-5",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 5",
    "text": "Exercise 5\nWe can use a logistic regression model to understand the relationship between how much someone has heard about AI and whether they are concerned about increased use of AI in daily life. (We will discuss this in detail next class, but will get a preview for now.)\nLet \\(p\\) be the probability a randomly selected respondent is concerned about increased use of AI in daily life. The statistical model is\n\\[\n\\begin{aligned}\n\\log\\Big(\\frac{p_i}{1-p_i}\\Big) = \\beta_0 &+ \\beta_1\\boldsymbol{1}(ai\\_heard_i = \\text{A little}) \\\\ &+ \\beta_2\\mathbf{1}(ai\\_heard_i = \\text{Nothing}) \\\\  &+ \\beta_3\\mathbf{1}(ai\\_heard_i = \\text{Refused})\n\\end{aligned}\n\\]\nThe code and output to fit this model is shown below:\n\nai_concern_fit &lt;- glm(ai_concern ~ ai_heard, data = pew_data,\n                      family = \"binomial\")\ntidy(ai_concern_fit) |&gt; \n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.065\n0.031\n-2.082\n0.037\n\n\nai_heardA little\n0.383\n0.040\n9.504\n0.000\n\n\nai_heardNothing at all\n-0.276\n0.079\n-3.505\n0.000\n\n\nai_heardRefused\n-0.697\n0.459\n-1.520\n0.129\n\n\n\n\n\n\nInterpret the intercept in the context of the data in terms of the log-odds of being concerned about increased use of AI in daily life.\nInterpret the coefficient of ai_heardA little in the context of the data in terms of the log-odds of being concerned about increased use of AI in daily life.\nInterpret the coefficient of ai_heardNothing at all in the context of the data in terms of the odds of being concerned about the increased use of AI in daily life. How does this compare to your response to Exercise 4?\n\n\n\n\n\n\n\nImportantSubmission\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "ae/ae-03-slr.html",
    "href": "ae/ae-03-slr.html",
    "title": "AE 03: Simple linear regression",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-03 repo to get started. If you do not see an ae-03 repo, use the link below to create one:\nhttps://classroom.github.com/a/jxxCTVVo\nThis AE does not count towards the participation grade.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-1",
    "href": "ae/ae-03-slr.html#exercise-1",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nVisualizations for the univariate and bivariate exploratory data analysis of daily bike rentals and temperature are below.\n\np1 &lt;- ggplot(bikeshare, aes(x = count)) +\n  geom_histogram(binwidth = 250) + \n  labs(x = \"Daily bike rentals\")\n\np2 &lt;- ggplot(bikeshare, aes(x = temp_orig)) +\n  geom_histogram() + \n  labs(x = \"Temperature (Celsius)\")\n\np3 &lt;- ggplot(bikeshare, aes(y = count, x = temp_orig)) +\n  geom_point() + \n  labs(x = \"Temperature (Celsius)\", \n       y = \"Daily bike rentals\")\n\n(p1 | p2) / p3\n\n\n\n\n\n\n\n\nThere appears to be one day with a very small number of bike rentals. What was the day? Why were the number of bike rentals so low on that day? Hint: You can Google the date to figure out what was going on that day."
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-2",
    "href": "ae/ae-03-slr.html#exercise-2",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nIn the raw data, seasons are coded as 1, 2, 3, 4, numeric values that correspond to winter, spring, summer, and fall respectively. Complete the code below to make season a categorical variable with levels corresponding to season names stored in the original order.\n\nbikeshare &lt;- bikeshare |&gt;\n  mutate(season = case_when(\n    season == 1 ~ \"Winter\", \n    season == 2 ~ \"Spring\", \n    season == 3 ~ \"Summer\", \n    season == 4 ~ \"Fall\"\n  ))"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-3",
    "href": "ae/ae-03-slr.html#exercise-3",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe want to evaluate whether the relationship between temperature and daily bike rentals is the same for each season. To answer this question, begin by creating a scatter plot of daily bike rentals vs. temperature faceted by season.\n\n# add code developed during livecoding here"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-4",
    "href": "ae/ae-03-slr.html#exercise-4",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nWhich season appears to have the strongest relationship between temperature and daily bike rentals? Why do you think the relationship is strongest in this season?\nWhich season appears to have the weakest relationship between temperature and daily bike rentals? Why do you think the relationship is weakest in this season?"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-5",
    "href": "ae/ae-03-slr.html#exercise-5",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nFilter your data for the season with the strongest apparent relationship between temperature and daily bike rentals.\n\n# add code developed during livecoding here"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-6",
    "href": "ae/ae-03-slr.html#exercise-6",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nUsing the data from Exercise 5, fit a linear model to predict daily bike rentals using temperature for this season.\n\n# add code developed during livecoding here"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-7",
    "href": "ae/ae-03-slr.html#exercise-7",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nUse the output to write out the estimated regression equation."
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-8",
    "href": "ae/ae-03-slr.html#exercise-8",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nInterpret the slope in the context of the data.\nDoes it make sense to interpret the intercept? If so, interpret the intercept in the context of the data. Otherwise, explain why not."
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-9",
    "href": "ae/ae-03-slr.html#exercise-9",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nSuppose you work for a bike share company in Durham, NC, and they want to predict daily bike rentals in 2024. What is one reason you might recommend they use your analysis for this task? What is one reason you would recommend they not use your analysis for this task?"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html",
    "href": "ae/ae-05-sim-testing.html",
    "title": "AE 05: Permutation test for the slope",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-05 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#data",
    "href": "ae/ae-05-sim-testing.html#data",
    "title": "AE 05: Permutation test for the slope",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\nGoal: Use statistical inference to evaluate whether there is a relationship between the age of the house at time of sale and its price."
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#exploratory-data-analysis",
    "href": "ae/ae-05-sim-testing.html#exploratory-data-analysis",
    "title": "AE 05: Permutation test for the slope",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\nLet’s begin by creating a new variable that is the age of the house in 2020.\n\nduke_forest &lt;- duke_forest |&gt;\n  mutate(age_2020 = 2020 - year_built)\n\nNow let’s visualize the relationship between the age of the house in 2020 and the sales price.\n\nggplot(duke_forest, aes(x = age_2020, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Age in 2020 (years)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and age of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#model",
    "href": "ae/ae-05-sim-testing.html#model",
    "title": "AE 05: Permutation test for the slope",
    "section": "Model",
    "text": "Model\n\ndf_fit &lt;- lm(price ~ age_2020, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n690891.015\n68637.793\n10.066\n0.000\n\n\nage_2020\n-2473.935\n1225.191\n-2.019\n0.046"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#hypothesis-test",
    "href": "ae/ae-05-sim-testing.html#hypothesis-test",
    "title": "AE 05: Permutation test for the slope",
    "section": "Hypothesis test",
    "text": "Hypothesis test\n\n\n\n\n\n\nTip\n\n\n\nFor code chunks with fill-in-the-blank code, change code chunk option to #| eval: true once you’ve filled in the code.\n\n\n\nState the null and alternative hypotheses\nWrite the null and alternative hypotheses in words and mathematical notation.\n\n\nGenerate null distribution using permutation\nFill in the code, then set eval: true .\n\nn = 100\nset.seed(01232025)\n\nnull_dist &lt;- _____ |&gt;\n  specify(______) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = _____, type = \"permute\") |&gt;\n  fit()\n\n\n\nVisualize distribution\n\n# Code for histogram of null distribution\n\n\n\nCalculate the p-value.\n\n# get observed fit \nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ age_2020) |&gt;\n  fit()\n\n# calculate p-value\nget_p_value(\n  ____,\n  obs_stat = ____,\n  direction = \"two-sided\"\n)\n\n\n\nState conclusion\nWrite your conclusion in the context of the data. You can use 0.05 as the decision-making threshold."
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#bootstrap-ci-time-permitting",
    "href": "ae/ae-05-sim-testing.html#bootstrap-ci-time-permitting",
    "title": "AE 05: Permutation test for the slope",
    "section": "Bootstrap CI (time permitting)",
    "text": "Bootstrap CI (time permitting)\n\nConstruct the bootstrap CI\nConstruct a 95% bootstrap confidence interval.\n\n\nDraw conclusion\n\nInterpret the interval in the context of the data.\nIs the interval consistent with the conclusion from your hypothesis test? Briefly explain why or why not.\n\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-05 repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html",
    "href": "ae/ae-12-exam-02-review.html",
    "title": "AE 12: Exam 02 Review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-12 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE."
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#packages",
    "href": "ae/ae-12-exam-02-review.html#packages",
    "title": "AE 12: Exam 02 Review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(pROC)"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-1",
    "href": "ae/ae-12-exam-02-review.html#exercise-1",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 1",
    "text": "Exercise 1\nSuppose you fit a simple linear regression model.\n\nDraw or describe a scatterplot that contains an observation with large leverage but low Cook’s distance.\nDraw or describe a scatterplot that contains an observation with large leverage and high Cook’s distance.\nDraw or describe a scatterplot that contains an observation with a large studentized residual."
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#data-credit-cards",
    "href": "ae/ae-12-exam-02-review.html#data-credit-cards",
    "title": "AE 12: Exam 02 Review",
    "section": "Data: Credit cards",
    "text": "Data: Credit cards\nThe data for this analysis is about credit card customers. It can be found in the file credit.csv. The following variables are in the data set:\n\nincome: Income in $1,000’s\nlimit: Credit limit\nrating: Credit rating\ncards: Number of credit cards\nage: Age in years\neducation: Number of years of education\nown: A factor with levels No and Yes indicating whether the individual owns their home\nstudent: A factor with levels No and Yes indicating whether the individual was a student\nmarried: A factor with levels No and Yes indicating whether the individual was married\nregion: A factor with levels South, East, and West indicating the region of the US the individual is from\nbalance: Average credit card balance in $.\n\nThe objective of this analysis is to predict whether a person has maxed out their credit card, i.e., had $0 average card balance.\n\ncredit &lt;- read_csv(\"data/credit.csv\") |&gt;\n  mutate(maxed = factor(if_else(balance == 0, 1, 0)))"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-2",
    "href": "ae/ae-12-exam-02-review.html#exercise-2",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWhy is logistic regression the best modeling approach for this analysis?\nDescribe where each of the following show up in the analysis:\n\nlog-odds …\nodds\nprobabilities"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-3",
    "href": "ae/ae-12-exam-02-review.html#exercise-3",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe’ll start by splitting the model into training and testing data. Then we’ll using the training data to fit a model for predicting the odds of maxed = 1 using income, rating, and region.\n\n# make training and test sets\nset.seed(210)\ncredit_split &lt;- initial_split(credit, prop = 0.8)\ncredit_train &lt;- training(credit_split)\ncredit_test &lt;- testing(credit_split)\n\ncredit_fit &lt;- glm(maxed ~ income + rating + region, data = credit_train, \n                  family = \"binomial\")\n\ntidy(credit_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n10.097\n1.687\n5.987\n0.000\n\n\nincome\n0.115\n0.026\n4.444\n0.000\n\n\nrating\n-0.058\n0.009\n-6.428\n0.000\n\n\nregionSouth\n-0.632\n0.715\n-0.884\n0.377\n\n\nregionWest\n-0.332\n0.724\n-0.458\n0.647\n\n\n\n\n\nThe logistic regression model takes the following form:\n\\[\n\\log(\\frac{\\pi_i}{1 - \\pi_i}) = \\beta_0 + \\beta_1 ~ income + \\beta_2 ~ rating + \\beta_3 ~ regionSouth + \\beta_4 ~ regionWest\n\\]\n\nWrite the interpretation of income in terms of the odds of maxing out a credit card.\nUse the equation above to show the expected change in the odds of maxing out a credit card when the credit rating increases by 10 points. Assume income and region are constant. Write your answer in terms of \\(\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4\\).\nSuppose there are two individuals. Individual 1 has an income of $64,000, a credit rating of 590, and is from the South region. Individual 2 has an income of $135,000, a credit rating of 695, and is from the East region. Use the equation above to show how the odds of maxing out a credit card differ between Individual 1 and Individual 2. Write your answer in terms of \\(\\beta_0, \\beta_1, \\beta_2\\), etc."
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-4",
    "href": "ae/ae-12-exam-02-review.html#exercise-4",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 4",
    "text": "Exercise 4\nWe consider adding the interaction between region and income to the current model. We’ll use a drop-in-deviance test to determine whether or not to add the interaction term.\n\nState the null and alternative hypotheses in words and using mathematical notation.\nDescribe what the test statistic \\(G\\) means in the context of the data.\nShow why the degrees of freedom for the test statistic are equal to 2.\nConduct the drop-in-deviance test and state your conclusion in the context of the data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-5",
    "href": "ae/ae-12-exam-02-review.html#exercise-5",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 5",
    "text": "Exercise 5\nNow let’s evaluate the performance of the selected model using the testing data.\nCreate a confusion matrix using a cutoff probability of 0.3.\n\n# add code here\n\n\nWhat is the sensitivity? What does it mean in the context of the data ?\nWhat is the specificity? What does it mean in the context of the data?\nWhat is the false positive rate? What does it mean in the context of the data?\nWhat is the false negative rate? What does it mean in the context of the data?"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-6",
    "href": "ae/ae-12-exam-02-review.html#exercise-6",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 6",
    "text": "Exercise 6\nProduce the ROC curve.\n\n# add code here\n\n\nDescribe how you can use this curve to select a cutoff probability (rather than just going with 0.5)."
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-7",
    "href": "ae/ae-12-exam-02-review.html#exercise-7",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 7",
    "text": "Exercise 7\nQuestions about checking conditions for logistic regression:\n\nDo we assess conditions on the training or testing set?\nWhy do we not consider categorical predictors when checking linearity?\nWhy do we not need to check constant variance for logistic regression?"
  },
  {
    "objectID": "ae/ae-02-life-expectancy.html",
    "href": "ae/ae-02-life-expectancy.html",
    "title": "AE 02: Life expectancy and healthcare expenditure",
    "section": "",
    "text": "Important\n\n\n\nFor this AE, you will discuss the questions in groups. This AE does not count towards the Application Exercise grade.\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-02-life-expectancy.html#introduction",
    "href": "ae/ae-02-life-expectancy.html#introduction",
    "title": "AE 02: Life expectancy and healthcare expenditure",
    "section": "Introduction",
    "text": "Introduction\nThe data set comes from Zarulli et al. (2021), who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThis AE will focus on the following variables:\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic area. ( from the World Health Organization)\nhealth_pct_gdp: Spending on healthcare goods and services, expressed as a percentage of GDP. It excludes capital health expenditures such as buildings, machinery, information technology and stocks of vaccines for emergency or outbreaks.\n\nClick here for the original research paper and a full list of variables in the original data set.\n\nlife_exp &lt;- read_excel(\"data/life-expectancy-data.xlsx\") |&gt; \n  rename(life_exp = `Life_expectancy_at_birth`, \n         health_pct_gdp = `Domestic_general_government_health_expenditure_pct_of_GDP`)\n\n\nlife_exp |&gt;\n  select(life_exp, health_pct_gdp) |&gt;\n  glimpse()\n\nRows: 140\nColumns: 2\n$ life_exp       &lt;dbl&gt; 63.8, 78.2, 59.9, 76.2, 74.6, 83.0, 81.3, 72.5, 71.8, 7…\n$ health_pct_gdp &lt;dbl&gt; 5, 41, 44, 74, 16, 68, 73, 20, 18, 61, 84, 66, 21, 74, …"
  },
  {
    "objectID": "ae/ae-02-life-expectancy.html#exercises",
    "href": "ae/ae-02-life-expectancy.html#exercises",
    "title": "AE 02: Life expectancy and healthcare expenditure",
    "section": "Exercises",
    "text": "Exercises\nWe begin by visualizing the distributions of life expectancy, health expenditure percentage, and the relationship between these two variables.\n\np1 &lt;- ggplot(life_exp, aes(x = life_exp)) +\n  geom_histogram() + \n  labs(x = \"Life expectancy\")\n\np2 &lt;- ggplot(life_exp, aes(x = health_pct_gdp)) +\n  geom_histogram() + \n  labs(x = \"% Health expenditure\")\n\np3 &lt;- ggplot(life_exp, aes(x = health_pct_gdp, y = life_exp)) +\n  geom_point() + \n  labs(x = \"% Health expenditure\", \n       y = \"Life expectancy\")\n\n(p1 | p2) / p3\n\n\n\n\n\n\n\n\n\nExercise 1\nDescribe the relationship between life expectancy and healthcare expenditure as a percentage of the GDP. Comment on how we expect the life expectancy to change as the percentage on healthcare expenditure changes.\n\n\nExercise 2\nSuppose you want to fit a model so you can use the healthcare expenditure as a percentage of GDP to predict life expectancy. Would a model of the form\n\\[\\text{life_exp} = \\beta_0 + \\beta_1 ~ \\text{health_pct_gdp} + \\epsilon\\]\nbe a useful model for the data? Why or why not?"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html",
    "href": "ae/ae-07-exam-01-review.html",
    "title": "AE 07: Exam 01 review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-07- to get started.\nRender, commit, and push your responses to GitHub by the end of class."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#packages",
    "href": "ae/ae-07-exam-01-review.html#packages",
    "title": "AE 07: Exam 01 review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#trail-users",
    "href": "ae/ae-07-exam-01-review.html#trail-users",
    "title": "AE 07: Exam 01 review",
    "section": "Trail users",
    "text": "Trail users\nThe Pioneer Valley Planning Commission (PVPC) collected data for ninety days from April 5, 2005 to November 15, 2005. Data collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\nWe will use regression analysis to predict the number of trail users based on weather and other features describing the day.\nThe variables we’ll focus on for this analysis are\n\nvolume estimated number of trail users that day (number of breaks recorded)\nhightemp daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\ndaytype one of “weekday” or “weekend”\n\nView the data set1 to see the remaining variables.\n\nrail_trail &lt;- read_csv(\"data/rail-trail.csv\")"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#exploratory-analysis",
    "href": "ae/ae-07-exam-01-review.html#exploratory-analysis",
    "title": "AE 07: Exam 01 review",
    "section": "Exploratory analysis",
    "text": "Exploratory analysis\n\nExercise 1\nVisualize, summarize, and describe the distribution of volume.\n\n\nExercise 2\n\nVisualize and describe the relationship between hightemp and volume.\nModify the plot to consider if the relationship between these variables differs by daytype."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#modeling",
    "href": "ae/ae-07-exam-01-review.html#modeling",
    "title": "AE 07: Exam 01 review",
    "section": "Modeling",
    "text": "Modeling\nFit a model using hightemp and daytype to predict the volume for this trail.\n\nExercise 3\n\nWrite the statistical model.\nFit the model and write the estimated regression equation. Neatly display the results using 3 digits and the 90% confidence interval for the coefficients.\n\n\n\nExercise 4\nInterpret the slope of hightemp in the context of the data.\n\n\nExercise 5\n\nDoes it make sense to interpret the intercept? Explain your reasoning.\nIf not, what can we do to make the interpretation meaningful?"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#inference-for-coefficients",
    "href": "ae/ae-07-exam-01-review.html#inference-for-coefficients",
    "title": "AE 07: Exam 01 review",
    "section": "Inference for coefficients",
    "text": "Inference for coefficients\n\nExercise 6\nThe following code can be used to create a bootstrap distribution for the model coefficients. Describe what each line of code does, supplemented by any visualizations that might help with your description.\n\nset.seed(1234)\n\n1boot_dist &lt;- rail_trail |&gt;\n2  specify(volume ~ hightemp + daytype) |&gt;\n3  generate(reps = 100, type = \"bootstrap\") |&gt;\n4  fit()\n\n\n1\n\n___\n\n2\n\n___\n\n3\n\n___\n\n4\n\n___\n\n\n\n\n\n\nExercise 7\nUse the bootstrap distribution created in Exercise 6, boot_dist, to construct a 90% confidence interval for the coefficient of hightemp using bootstrapping and the percentile method and interpret it in context of the data.\n\n\nExercise 8\nConduct a hypothesis test for the coefficient of hightemp significance level using permutation with 100 reps. State the hypotheses in words and mathematical notation. Also include a visualization of the null distribution of the slope with the observed slope marked as a vertical line.\n\n\nExercise 9\nNow repeat Exercises 7 and 8 using approaches based on mathematical models. You can reference output from previous exercises and/or write new code as needed."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#inference-for-prediction",
    "href": "ae/ae-07-exam-01-review.html#inference-for-prediction",
    "title": "AE 07: Exam 01 review",
    "section": "Inference for prediction",
    "text": "Inference for prediction\n\nExercise 10\nBased on your model, predict the volume for a weekday with high temperature of degrees.\n\n\nExercise 11\nSuppose you’re asked to construct a confidence and a prediction interval for your finding in the previous exercise. Which one would you expect to be wider and why? In your answer clearly state the difference between these intervals.\n\n\nExercise 12\nNow construct the intervals and comment on whether your guess is confirmed."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#interaction-terms",
    "href": "ae/ae-07-exam-01-review.html#interaction-terms",
    "title": "AE 07: Exam 01 review",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nExercise 13\nNow fit the model using hightemp and daytype to predict volume such that the effect of hightemp can differ by daytype.\n\n\nExercise 14\n\nWrite the estimated regression equation for weekends.\nWrite the estimated regression equation for weekdays.\n\n\n\nExercise 15\nAccording to this model, does the effect of hightemp differ for weekends vs. weekdays? Explain."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#model-comparison",
    "href": "ae/ae-07-exam-01-review.html#model-comparison",
    "title": "AE 07: Exam 01 review",
    "section": "Model comparison",
    "text": "Model comparison\n\nExercise 16\nWhich model is a better fit for the data - the model with or without the interaction? Show any work to support your choice.\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-07- repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#footnotes",
    "href": "ae/ae-07-exam-01-review.html#footnotes",
    "title": "AE 07: Exam 01 review",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package.↩︎"
  },
  {
    "objectID": "prepare/prepare-lec02.html",
    "href": "prepare/prepare-lec02.html",
    "title": "Prepare for Lecture 02: The big picture",
    "section": "",
    "text": "📖 Read R for Data Science, Introduction: What you will learn\n📖 Read GitHub for supporting, reusing, contributing, and failing safely\n🎥 Watch Meet the Toolkit: R + RStudio\n🎥 Watch Meet the Toolkit: Quarto"
  },
  {
    "objectID": "prepare/prepare-lec07.html",
    "href": "prepare/prepare-lec07.html",
    "title": "Prepare for Lecture 06: Multiple linear regression",
    "section": "",
    "text": "📖 Read Multiple linear regression, Section 7.1 - 7.4\n📖 Read Multiple linear regression, Section 7.6.1"
  },
  {
    "objectID": "prepare/prepare-lec04.html",
    "href": "prepare/prepare-lec04.html",
    "title": "Prepare for Lecture 04: Inference - bootstrap confidence intervals",
    "section": "",
    "text": "📖 Read Inference for simple linear regression, Section 5. 1- 5.3\n📖 Read Bootstrap confidence intervals, Section 5.5"
  },
  {
    "objectID": "prepare/prepare-lec22.html",
    "href": "prepare/prepare-lec22.html",
    "title": "Prepare for Lecture 22: Multinomial Logistic Regression pt2",
    "section": "",
    "text": "📖 juliasilge.com/blog/multinomial-volcano-eruptions\n📖 juliasilge.com/blog/nber-papers"
  },
  {
    "objectID": "hw/stats-experience.html",
    "href": "hw/stats-experience.html",
    "title": "Statistics Experience",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/hw-03.html",
    "href": "hw/hw-03.html",
    "title": "HW 03",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-04.html",
    "href": "hw/hw-04.html",
    "title": "HW 04",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "labs/lab-08.html",
    "href": "labs/lab-08.html",
    "title": "Lab 08",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 08"
    ]
  },
  {
    "objectID": "labs/lab-07.html",
    "href": "labs/lab-07.html",
    "title": "Lab 07",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 07"
    ]
  },
  {
    "objectID": "labs/lab-04.html",
    "href": "labs/lab-04.html",
    "title": "Lab 04",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-01.html",
    "href": "labs/lab-01.html",
    "title": "Lab 01",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-02.html",
    "href": "labs/lab-02.html",
    "title": "Lab 02",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-03.html",
    "href": "labs/lab-03.html",
    "title": "Lab 03",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-00.html",
    "href": "labs/lab-00.html",
    "title": "Lab 00",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-05.html",
    "href": "labs/lab-05.html",
    "title": "Lab 05",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-06.html",
    "href": "labs/lab-06.html",
    "title": "Lab 06",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "STA 210 - Regression Analysis",
    "section": "",
    "text": "In STA 210, students will learn how linear and logistic regression models are used to explore multivariable relationships and apply these methods to answer relevant and engaging questions using a data-driven approach. Students will develop computing skills to implement a reproducible data analysis workflow and gain experience communicating statistical results. Throughout the semester, students will work on a team project where they will develop a research question, answer it using methods learned in the course, and share results through a written report and presentation.\nTopics include applications of linear and logistic regression, interpretation, diagnostics, model selection, and model assessment. Students will gain experience using the computing tools R and GitHub to analyze real-world data from a variety of fields. This class emphasizes data analysis over mathematical theory.\n\n\n100-level Statistical Science course or Statistical Science 230, 231, or 240L",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#pre-requisites",
    "href": "overview.html#pre-requisites",
    "title": "STA 210 - Regression Analysis",
    "section": "",
    "text": "100-level Statistical Science course or Statistical Science 230, 231, or 240L",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#teaching-assistants",
    "href": "overview.html#teaching-assistants",
    "title": "STA 210 - Regression Analysis",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\nName\nRole\n\n\nAdeli Hutton\nLab leader\n\n\nShane Rybacki\nLab leader\n\n\n\nSee Canvas for office hours times and locations.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "hw/hw-01.html",
    "href": "hw/hw-01.html",
    "title": "HW 01",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-02.html",
    "href": "hw/hw-02.html",
    "title": "HW 02",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "prepare/prepare-lec18.html",
    "href": "prepare/prepare-lec18.html",
    "title": "Prepare for Lecture 18: Logistic regression - Prediction",
    "section": "",
    "text": "📖 Classification module in Google Machine Learning Crash Course"
  },
  {
    "objectID": "prepare/prepare-lec10.html",
    "href": "prepare/prepare-lec10.html",
    "title": "Prepare for Lecture 10: Inference + Model conditions",
    "section": "",
    "text": "📖 Read Model conditions"
  },
  {
    "objectID": "prepare/prepare-lec05.html",
    "href": "prepare/prepare-lec05.html",
    "title": "Prepare for Lecture 05: Inference - permutation tests",
    "section": "",
    "text": "📖 Read Inference for simple linear regression, Section 5. 1- 5.3\n📖 Read Inference for simple linear regression, Section 5.6 - 5.8"
  },
  {
    "objectID": "prepare/prepare-lec06.html",
    "href": "prepare/prepare-lec06.html",
    "title": "Prepare for Lecture 06: Inference - Mathematical models",
    "section": "",
    "text": "📖 Read Inference for simple linear regression, Section 5.9"
  },
  {
    "objectID": "prepare/prepare-lec03.html",
    "href": "prepare/prepare-lec03.html",
    "title": "Prepare for Lecture 03: Simple linear regression",
    "section": "",
    "text": "📖 Read Simple linear regression, Section 4.1 - 4.6\n📖 Read Simple linear regression, Section 4.8"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html",
    "href": "ae/ae-04-bootstrap.html",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-04 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#data",
    "href": "ae/ae-04-bootstrap.html#data",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\n\nglimpse(duke_forest)\n\nRows: 98\nColumns: 13\n$ address    &lt;chr&gt; \"1 Learned Pl, Durham, NC 27705\", \"1616 Pinecrest Rd, Durha…\n$ price      &lt;dbl&gt; 1520000, 1030000, 420000, 680000, 428500, 456000, 1270000, …\n$ bed        &lt;dbl&gt; 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4, 5, 3, 4, 4, 3,…\n$ bath       &lt;dbl&gt; 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0, 2.0, 3.0, 3.0,…\n$ area       &lt;dbl&gt; 6040, 4475, 1745, 2091, 1772, 1950, 3909, 2841, 3924, 2173,…\n$ type       &lt;chr&gt; \"Single Family\", \"Single Family\", \"Single Family\", \"Single …\n$ year_built &lt;dbl&gt; 1972, 1969, 1959, 1961, 2020, 2014, 1968, 1973, 1972, 1964,…\n$ heating    &lt;chr&gt; \"Other, Gas\", \"Forced air, Gas\", \"Forced air, Gas\", \"Heat p…\n$ cooling    &lt;fct&gt; central, central, central, central, central, central, centr…\n$ parking    &lt;chr&gt; \"0 spaces\", \"Carport, Covered\", \"Garage - Attached, Covered…\n$ lot        &lt;dbl&gt; 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.79, 0.53, 0.73,…\n$ hoa        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ url        &lt;chr&gt; \"https://www.zillow.com/homedetails/1-Learned-Pl-Durham-NC-…"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#exploratory-data-analysis",
    "href": "ae/ae-04-bootstrap.html#exploratory-data-analysis",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#model",
    "href": "ae/ae-04-bootstrap.html#model",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Model",
    "text": "Model\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#bootstrap-confidence-interval",
    "href": "ae/ae-04-bootstrap.html#bootstrap-confidence-interval",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Bootstrap confidence interval",
    "text": "Bootstrap confidence interval\n\n1. Calculate the observed fit (slope)\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159.\n\n\n\n\n2. Take n_iter bootstrap samples and fit models to each one.\nFill in the code, then set eval: true .\n\nn_iter = 100\nset.seed(091222)\n\nboot_fits &lt;- ______ |&gt;\n  specify(______) |&gt;\n  generate(reps = ____, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n\nWhy do we set a seed before taking the bootstrap samples?\nMake a histogram of the bootstrap samples to visualize the bootstrap distribution.\n\n# Code for histogram\n\n\n\n\n3. Compute the 95% confidence interval as the middle 95% of the bootstrap distribution\nFill in the code, then set eval: true .\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = _____, \n  level = ____,\n  type = \"percentile\"\n)"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#changing-confidence-level",
    "href": "ae/ae-04-bootstrap.html#changing-confidence-level",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nModify the code from Step 3 to create a 90% confidence interval.\n\n# Code for the 90% confidence interval\n\n\n\nModify the code from Step 3 to create a 99% confidence interval.\n\n# Code for the 99% confidence interval\n\n\nWhich confidence level produces the most accurate confidence interval (90%, 95%, 99%)? Explain\nWhich confidence level produces the most precise confidence interval (90%, 95%, 99%)? Explain\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-04 repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html",
    "href": "ae/ae-08-multicollinearity.html",
    "title": "AE 08: Multicollinearity",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-08 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)\nlibrary(rms) #calculate VIF"
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-1",
    "href": "ae/ae-08-multicollinearity.html#exercise-1",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nFit the regression model using high temperature, average temperature, season, and precipitation to predict volume.\nAre there any coefficients that may be not what you expected?"
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-2",
    "href": "ae/ae-08-multicollinearity.html#exercise-2",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 2",
    "text": "Exercise 2\nUse the formula\n\\[\nVIF_j = \\frac{1}{1 - R^2_j}\n\\]\nto calculate the VIF for avgtemp."
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-3",
    "href": "ae/ae-08-multicollinearity.html#exercise-3",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 3",
    "text": "Exercise 3\nBased on the VIF from the previous exercise, does avgtemp have a linear dependency with one or more other predictors? Explain."
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-4",
    "href": "ae/ae-08-multicollinearity.html#exercise-4",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nUse the vif function to compute VIF for all the predictors in Exercise 1.\nAre there predictors with near-linear dependencies? If so, which ones?"
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-5",
    "href": "ae/ae-08-multicollinearity.html#exercise-5",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 5",
    "text": "Exercise 5\nLet’s address the issue of multicollinearity. Choose a strategy to address the multicollinearity. Apply it, then use relevant statistics to select a final model."
  },
  {
    "objectID": "ae/ae-11-multinomial.html",
    "href": "ae/ae-11-multinomial.html",
    "title": "AE 11: Multinomial logistic regression",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-10 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE."
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-1",
    "href": "ae/ae-11-multinomial.html#exercise-1",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nCreate a plot to visualize the relationship between the response, viewcat and the primary variable of interest in this analysis, viewenc. What do you observe from the plot?"
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-2",
    "href": "ae/ae-11-multinomial.html#exercise-2",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nCreate a plot to visualize the relationship between the response, viewcat and age. What do you observe from the plot?"
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-3",
    "href": "ae/ae-11-multinomial.html#exercise-3",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nFit a model using the ageCent and viewenc to understand the odds a child is in a given category of viewcat. Display the model including 95% confidence intervals for the coefficients."
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-4",
    "href": "ae/ae-11-multinomial.html#exercise-4",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nWhat is the baseline category for viewcat? What is the baseline category for viewenc?\nInterpret the intercept associated with the odds of a child being in the category viewcat == 2 versus the baseline.\nInterpret the effect of age in terms of the odds of a child being in the category viewcat == 2 versus the baseline. Based on the confidence interval for the coefficient, is the numeric predictor a statistically significant predictor of viewership?"
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-5",
    "href": "ae/ae-11-multinomial.html#exercise-5",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nShould the interaction between ageCent and viewenc be included in the model? Show any analysis used to make your conclusion."
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-6",
    "href": "ae/ae-11-multinomial.html#exercise-6",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nThe primary objective of the experiment was to understand the effect of encouragement on viewership. Does encouragement have a significant effect on viewership after adjusting for age? If so, describe the effect. Otherwise, explain why not."
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-7",
    "href": "ae/ae-11-multinomial.html#exercise-7",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nUse the model selected in Exercise 5 to compute the predicted probabilities and predicted classes for viewcat.\nMake a confusion matrix.\nWhat percentage of observations were correctly classified?"
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-8",
    "href": "ae/ae-11-multinomial.html#exercise-8",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nAssess the overall model performance.\nWere there particular categories in which the model has a harder time differentiating?"
  },
  {
    "objectID": "ae/ae-06-model-compare.html",
    "href": "ae/ae-06-model-compare.html",
    "title": "AE 06: Model comparison",
    "section": "",
    "text": "Important\n\n\n\nRender, commit, and push your responses to GitHub by the end of class.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#data",
    "href": "ae/ae-06-model-compare.html#data",
    "title": "AE 06: Model comparison",
    "section": "Data",
    "text": "Data\nWhich variables help us predict the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.\nThe variables we’ll focus on for this analysis are\n\nTip: amount of the tip\nParty: number of people in the party\nMeal: Time of day (Lunch, Dinner, Late Night)\nAge: Age category of person paying the bill (Yadult, Middle, SenCit)\nDay: Day of the week (includes every day but Monday)\n\nView the data set to see the remaining variables.\n\ntips &lt;- read_csv(\"data/tip-data.csv\")"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-1",
    "href": "ae/ae-06-model-compare.html#exercise-1",
    "title": "AE 06: Model comparison",
    "section": "Exercise 1",
    "text": "Exercise 1\nSplit the data into training (80%) and testing (20%) sets. Use seed 2025."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-2",
    "href": "ae/ae-06-model-compare.html#exercise-2",
    "title": "AE 06: Model comparison",
    "section": "Exercise 2",
    "text": "Exercise 2\nUse the training data to fit a model using Party, Age, and Meal to predict tips. Compute the \\(R^2\\) and \\(Adj. R^2\\) for this model."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-3",
    "href": "ae/ae-06-model-compare.html#exercise-3",
    "title": "AE 06: Model comparison",
    "section": "Exercise 3",
    "text": "Exercise 3\nNow fit a model predicting tips using Party, Age, and Meal, such that the effect of party can differ by Meal. Compute \\(R^2\\) and \\(Adj. R^2\\) for this model."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-4",
    "href": "ae/ae-06-model-compare.html#exercise-4",
    "title": "AE 06: Model comparison",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nWhich model do you choose - the model from Exercise 2 or Exercise 3? Why?\nCompute RMSE for the selected model."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-5",
    "href": "ae/ae-06-model-compare.html#exercise-5",
    "title": "AE 06: Model comparison",
    "section": "Exercise 5",
    "text": "Exercise 5\nNow let’s use the testing data to assess the performance of the model selected in Exercise 4.\n\nCompute the predicted tips for the testing data. Add the predictions to the testing data set.\nCompute RMSE and \\(R^2\\) for the testing data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-6",
    "href": "ae/ae-06-model-compare.html#exercise-6",
    "title": "AE 06: Model comparison",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nHow do RMSE compare between the training and testing data?\nHow does \\(R^2\\) compare between the training and testing data?\nIs this what you expect? Why?"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-7",
    "href": "ae/ae-06-model-compare.html#exercise-7",
    "title": "AE 06: Model comparison",
    "section": "Exercise 7",
    "text": "Exercise 7\nWhy can we use \\(R^2\\) as an assessment of performance on the testing data even if we can’t use it to compare models?"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#to-submit-the-ae",
    "href": "ae/ae-06-model-compare.html#to-submit-the-ae",
    "title": "AE 06: Model comparison",
    "section": "To submit the AE:",
    "text": "To submit the AE:\n\n\n\n\n\n\nImportant\n\n\n\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html",
    "href": "ae/ae-10-logistic-compare.html",
    "title": "AE 10: Comparing logistic regression models",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-10 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE."
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#packages",
    "href": "ae/ae-10-logistic-compare.html#packages",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#response-to-leukemia-treatment",
    "href": "ae/ae-10-logistic-compare.html#response-to-leukemia-treatment",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Response to Leukemia treatment",
    "text": "Response to Leukemia treatment\nToday’s data is from a study where 51 untreated adult patients with Acute Myeloid Leukemia who were given a course of treatment, and they were assessed as to their response to the treatment.1\nThe goal of today’s analysis is to use pre-treatment factors to predict how likely it is a patient will respond to the treatment.\nWe will use the following variables:\n\nAge: Age at diagnosis (in years)\nSmear: Differential percentage of blasts\nInfil: Percentage of absolute marrow leukemia infiltrate\nIndex: Percentage labeling index of the bone marrow leukemia cells\nBlasts: Absolute number of blasts, in thousands\nTemp: Highest temperature of the patient prior to treatment, in degrees Fahrenheit\nResp: 1 = responded to treatment or 0 = failed to respond\n\n\nleukemia &lt;- read_csv(\"data/leukemia.csv\") |&gt;\n  mutate(Resp = factor(Resp))"
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#comparing-models",
    "href": "ae/ae-10-logistic-compare.html#comparing-models",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Comparing models",
    "text": "Comparing models\n\nConsider a model with all the pre-treatment variables: Age, Smear, Infil, Index, Blasts and Temp. Fit a model using these six variables to predict whether a patient responded to the treatment. Call the model full_model. Display the model.\n\n\n# add code\n\n\nBased on the model, which pre-treatment variables are statistically significant using a threshold of \\(\\alpha = 0.05\\)? (We will talk more about inference for logistic regression coefficients in an upcoming lecture.)\nFit a model that only includes the statistically significant predictors. Call the model reduced_model.\n\n\n# add code\n\n\nUse a drop-in-deviance test to compare a model that includes only the significant predictors to the full model. Which model do you choose based on the results of this test?\n\n\n# add code\n\n\nIs your choice based on AIC consistent with your choice from the previous exercise? What about a choice based on BIC?\n\n\n# add code"
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#submission",
    "href": "ae/ae-10-logistic-compare.html#submission",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#footnotes",
    "href": "ae/ae-10-logistic-compare.html#footnotes",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe data set is from the Stat2Data R package. This AE is adapted from exercises in Stat 2.↩︎"
  },
  {
    "objectID": "ae/ae-01-movies.html",
    "href": "ae/ae-01-movies.html",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "",
    "text": "Important\n\n\n\nFor this AE, you will discuss the questions in groups and submit answers on Ed Discussion. This AE does not count towards the Application Exercise grade.\nWe will look at the relationship between budget and revenue for movies made in the United States in 1986 to 2020. The dataset is created based on data from the Internet Movie Database (IMDB).\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(viridis)\nlibrary(DT)"
  },
  {
    "objectID": "ae/ae-01-movies.html#data",
    "href": "ae/ae-01-movies.html#data",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Data",
    "text": "Data\nThe movies data set includes basic information about each movie including budget, genre, movie studio, director, etc. A full list of the variables may be found here.\n\nmovies &lt;- read_csv(\"https://raw.githubusercontent.com/danielgrijalva/movie-stats/master/movies.csv\")\n\nView the first 10 rows of data.\n\nmovies |&gt;\n  slice(1:10)\n\n# A tibble: 10 × 15\n   name   rating genre  year released score  votes director writer star  country\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;  \n 1 The S… R      Drama  1980 June 13…   8.4 9.27e5 Stanley… Steph… Jack… United…\n 2 The B… R      Adve…  1980 July 2,…   5.8 6.5 e4 Randal … Henry… Broo… United…\n 3 Star … PG     Acti…  1980 June 20…   8.7 1.20e6 Irvin K… Leigh… Mark… United…\n 4 Airpl… PG     Come…  1980 July 2,…   7.7 2.21e5 Jim Abr… Jim A… Robe… United…\n 5 Caddy… R      Come…  1980 July 25…   7.3 1.08e5 Harold … Brian… Chev… United…\n 6 Frida… R      Horr…  1980 May 9, …   6.4 1.23e5 Sean S.… Victo… Bets… United…\n 7 The B… R      Acti…  1980 June 20…   7.9 1.88e5 John La… Dan A… John… United…\n 8 Ragin… R      Biog…  1980 Decembe…   8.2 3.30e5 Martin … Jake … Robe… United…\n 9 Super… PG     Acti…  1980 June 19…   6.8 1.01e5 Richard… Jerry… Gene… United…\n10 The L… R      Biog…  1980 May 16,…   7   1   e4 Walter … Bill … Davi… United…\n# ℹ 4 more variables: budget &lt;dbl&gt;, gross &lt;dbl&gt;, company &lt;chr&gt;, runtime &lt;dbl&gt;"
  },
  {
    "objectID": "ae/ae-01-movies.html#analysis",
    "href": "ae/ae-01-movies.html#analysis",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Analysis",
    "text": "Analysis\nWe begin by looking at how the average gross revenue (gross) has changed over time. Since we want to visualize the results, we will choose a few genres of interest for the analysis.\n\ngenre_list &lt;- c(\"Comedy\", \"Action\", \"Animation\", \"Horror\")\n\n\nmovies |&gt;\n  filter(genre %in% genre_list) |&gt; \n  group_by(genre,year) |&gt;\n  summarise(avg_gross = mean(gross)) |&gt;\n  ggplot(mapping = aes(x = year, y = avg_gross, color=genre)) +\n    geom_point() + \n    geom_line() +\n    ylab(\"Average Gross Revenue (in US Dollars)\") +\n    ggtitle(\"Gross Revenue Over Time\") +\n    scale_color_viridis_d()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat do you observe from the plot?\n\n\n\nNext, let’s see the relationship between a movie’s budget and its gross revenue.\n\nmovies |&gt;\n  filter(genre %in% genre_list, budget &gt; 0) |&gt; \n  ggplot(mapping = aes(x=log(budget), y = log(gross), color=genre)) +\n  geom_point() +\n  geom_smooth(method=\"lm\",se=FALSE) + \n  xlab(\"Log-transformed Budget\")+\n  ylab(\"Log-transformed Gross Revenue\") +\n  facet_wrap(~ genre) + \n  scale_color_viridis_d()"
  },
  {
    "objectID": "ae/ae-01-movies.html#exercises",
    "href": "ae/ae-01-movies.html#exercises",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Exercises",
    "text": "Exercises\n\nSuppose we fit a regression model for each genre that uses budget to predict gross revenue. What are the signs of the correlation between budget and gross and the slope in each regression equation?\nSuppose we fit the regression model from the previous question. Which genre would you expect to have the smallest residuals, on average (residual = observed revenue - predicted revenue)?\nPost your response on ED Discussion.\nhttps://edstem.org/us/courses/70992/discussion/5951333\n[Time permitting] Discuss the following: Notice in the graph above that budget and gross are log-transformed. Why are the log-transformed values of the variables displayed rather than the original values (in U.S. dollars)? Post your group’s response in the AE 01 Movie Budgets comments on Ed Discussion."
  },
  {
    "objectID": "ae/ae-01-movies.html#references",
    "href": "ae/ae-01-movies.html#references",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "References",
    "text": "References\n\ngithub.com/danielgrijalva/movie-stats\nInternet Movie Database"
  },
  {
    "objectID": "ae/ae-01-movies.html#appendix",
    "href": "ae/ae-01-movies.html#appendix",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of genres in the data set:\n\nmovies |&gt; \n  arrange(genre) |&gt; \n  select(genre) |&gt;\n  distinct() |&gt;\n  datatable()"
  },
  {
    "objectID": "computing-r-resources.html",
    "href": "computing-r-resources.html",
    "title": "Resources for learning R",
    "section": "",
    "text": "Below are freely available resources to learn or review the following in R: data wrangling, data visualization, Quarto basics.",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#in-depth-introduction",
    "href": "computing-r-resources.html#in-depth-introduction",
    "title": "Resources for learning R",
    "section": "In-depth introduction",
    "text": "In-depth introduction\nCoursera: Data Visualization and Transformation with R by Mine Çetinkaya-Rundel and Elijah Meyer\n\nIncludes videos, readings, practice exercise, quizzes, and other resources\nYou can select content within the modules you want to complete.\nFocus on Modules 2 and 3. Review the content in Module 1 as needed.s\nClick here for instructions to register for Coursera for free as a Duke student",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#in-depth-review",
    "href": "computing-r-resources.html#in-depth-review",
    "title": "Resources for learning R",
    "section": "In-depth review",
    "text": "In-depth review\nData Science with R videos by Mine Çetinkaya-Rundel and Elijah Meyer\n\nVideos from the data science Coursera course\nFocus on videos on visualizing and summarizing data\nYou need to join the Coursera course to access the files from the code along videos.\n\nLearn R: An interactive introduction to data analysis with R\n\nHands-on tutorial that can be completed within the site (no RStudio required)\nFocus on Chapters 4 - 6",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#shorter-review",
    "href": "computing-r-resources.html#shorter-review",
    "title": "Resources for learning R",
    "section": "Shorter review",
    "text": "Shorter review\nR for Data Science (2nd ed) by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund\n\nFocus on Chapters 1 - 3, 10",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#additional-resources",
    "href": "computing-r-resources.html#additional-resources",
    "title": "Resources for learning R",
    "section": "Additional resources",
    "text": "Additional resources\n\nTidy Modeling with R by Max Kuhn & Julia Silge\nPosit Cheatsheets\nR workshops by Duke Center for Data and Visualization Sciences",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 210 - Regression Analysis",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\nweek\ndow\ndate\ntopic\nprepare\nslides\nnotes\nae\nhw\nlab\nproject\ndue\n\n\n\n\n1\nTh\nJan 8\nWelcome to STA 210!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\nM\nJan 12\nLab 00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nJan 13\nThe big picture\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nJan 15\nSimple linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\nM\nJan 19\nNo lab: Martin Luther King Jr. Day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nJan 20\nInference: Bootstrap confidence intervals\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nJan 22\nInference: Permutation tests\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\nM\nJan 26\nLab 01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nJan 27\nInference: Mathematical models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 01 due\n\n\n\nTh\nJan 29\nMultiple linear regression (MLR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 01 due\n\n\n5\nM\nFeb 2\nLab 02\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nFeb 3\nMLR: Types of predictors\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nFeb 5\nInference for MLR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 02 due\n\n\n6\nM\nFeb 9\nLab 03\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nFeb 10\nModel conditions + diagnostics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 02 due\n\n\n\nTh\nFeb 12\nExam 01 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 03 due\n\n\n7\nM\nFeb 16\nLab 04: Exam 01 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 04 due at end of lab\n\n\n\nTu\nFeb 17\nExam 01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nFeb 19\nVariable transformations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8\nM\nFeb 23\nLab: Project proposal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nFeb 24\nModel selection\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nFeb 26\nCross validation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9\nM\nMar 2\nLab 06\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nMar 3\nWrapping up MLR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 5\nEthics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 05 due\n\n\n10\nM\nMar 9\nNo Lab: Spring break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nMar 10\nNo Lecture: Spring Break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 12\nNo Lecture: Spring break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11\nM\nMar 16\nLab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nMar 17\nLogistic regression (LR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 03 due\n\n\n\nTh\nMar 19\nLR: Prediction + Assessment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12\nM\nMar 23\nLab 06\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nMar 24\nLR: Inference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 26\nLR: Model selection\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 06 due\n\n\n13\nM\nMar 30\nLab 07\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nMar 31\nSpecial topic/ Catch up\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 04 due\n\n\n\nTh\nApr 2\nExam 02 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 07 due\n\n\n14\nM\nApr 6\nLab 08: Exam 02 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 08 due at end of lab\n\n\n\nTu\nApr 7\nExam 02\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nApr 9\nSpecial topic\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15\nM\nApr 13\nProject work day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nApr 14\nProject presentations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nApr 16\nProject presentations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n16\nM\nApr 20\nLab: Draft peer review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nApr 21\nProject meetings\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistics experience due\n\n\nExam period",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio containers\n🔗 for Duke Container Manager\n\n\nCourse GitHub organization\n🔗 for GitHub\n\n\nCourse Canvas site\n🔗 for Canvas\n\n\nDiscussion forum\n🔗 to Ed Discussion\n\n\nAssignment submission\n🔗 to Gradescope\n\n\nLecture recording request\n🔗 to Lecture recording request form",
    "crumbs": [
      "Useful links"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "STA 210 Syllabus",
    "section": "",
    "text": "See Canvas for class meeting times and locations.\n\n\n\n\n\n\nName\nRole\n\n\n\n\nProf. Maria Tackett\nInstructor\n\n\nAdeli Hutton\nLab leader\n\n\nShane Rybacki\nLab leader\n\n\n\nSee Canvas for office hours.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-info",
    "href": "syllabus.html#course-info",
    "title": "STA 210 Syllabus",
    "section": "",
    "text": "See Canvas for class meeting times and locations.\n\n\n\n\n\n\nName\nRole\n\n\n\n\nProf. Maria Tackett\nInstructor\n\n\nAdeli Hutton\nLab leader\n\n\nShane Rybacki\nLab leader\n\n\n\nSee Canvas for office hours.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "STA 210 Syllabus",
    "section": "Course description",
    "text": "Course description\nIn STA 210, students will learn how linear and logistic regression models are used to explore multivariable relationships and apply these methods to answer relevant and engaging questions using a data-driven approach. Students will develop computing skills to implement a reproducible data analysis workflow and gain experience communicating statistical results. Throughout the semester, students will work on a team project where they will develop a research question, answer it using methods learned in the course, and share results through a written report and presentation.\nTopics include applications of linear and logistic regression, interpretation, diagnostics, model selection, and model assessment. Students will gain experience using the computing tools R and GitHub to analyze real-world data from a variety of fields. This class emphasizes data analysis over mathematical theory.\n\nPrerequisites\n100-level Statistical Science course or Statistical Science 230, 231, or 240L",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-learning-objectives",
    "href": "syllabus.html#course-learning-objectives",
    "title": "STA 210 Syllabus",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze real-world data to answer questions about multivariable relationships.\nuse R to fit and evaluate linear and logistic regression models.\nassess whether a proposed model is appropriate and describe its limitations.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "STA 210 Syllabus",
    "section": "Course materials",
    "text": "Course materials\nMost readings in this course will come from Introduction to Regression Analysis: A Data Science Approach. It is freely available online (introregression.netlify.app). Readings from this text and other sources will be posted under the “prepare” column on the course schedule. We will use the statistical software R. Students will be able to access R through Docker containers provided by Duke Office of Information Technology. See the computing page for more information.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-community",
    "href": "syllabus.html#course-community",
    "title": "STA 210 Syllabus",
    "section": "Course community",
    "text": "Course community\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nUsing pronouns can help foster a respectful campus environment where all community members can thrive. Sharing pronouns is always optional for members of the Duke community. If you would like to share yours, you can update them in DukeHub. You can learn more at the DukeHub & Zoom Tutorials.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website, https://sta210-sp26.netlify.app.\nLinks to Zoom meetings may be found in Canvas. Periodic announcements will be sent via email and will also be available through Ed Discussion and Canvas Announcements. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nEmail\nIf you have questions about assignment extensions, accommodations, or any other matter not appropriate for the class discussion forum, please email me directly at maria.tackett@duke.edu. If you email me, please include “STA 210” in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#five-tips-for-success",
    "href": "syllabus.html#five-tips-for-success",
    "title": "STA 210 Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nThe TAs and I will provide materials, answer questions, and provide guidance to help you learn the material in this course. Below are five things you can do to be successful in STA 210:\n\nComplete all “prepare” readings and tasks before class.\nActively participate and engage in lectures and labs.\nAsk questions frequently during lecture, in office hours, on Ed Discussion, and among your classmates.\nComplete all homework and labs, asking yourself “why” questions as you go through the steps to complete each exercise.\nStay current with the course material, as each new concept builds on previous ones.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#getting-help-in-the-course",
    "href": "syllabus.html#getting-help-in-the-course",
    "title": "STA 210 Syllabus",
    "section": "Getting help in the course",
    "text": "Getting help in the course\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours1 to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. You are encouraged to use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the class discussion forum Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts in Ed Discussion before adding a new question. If you know the answer to a question posted in the discussion forum, you are encouraged to respond!\n\nCheck out the Support page for more resources.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#what-to-expect-in-the-course",
    "href": "syllabus.html#what-to-expect-in-the-course",
    "title": "STA 210 Syllabus",
    "section": "What to expect in the course",
    "text": "What to expect in the course\n\nLectures and labs\nLectures and labs are designed to be interactive, so you gain experience applying new concepts and learning from each other. My role as instructor is to introduce you to new methods, tools, and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities during the lectures and labs. You are expected to prepare for class by completing assigned readings, attend all lecture and lab sessions, and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded based on completing what we do in class.\nYou are expected to bring a laptop, tablet, or any device with internet and a keyboard to each class so that you can participate in the in-class exercises. Please make sure your device is fully charged before you come to class, as the number of outlets in the classroom will not be sufficient to accommodate everyone.\n\n\nTeams\nYou will work on a team for most labs throughout the semester. Teams will be assigned, and you will work with the team for 1 - 2 lab assignments. All team members are expected to contribute equally to the completion of the lab. You will be asked to complete teamwork evaluations and self-reflections throughout the semester. Failure to adequately contribute to an assignment can result in a penalty to your score relative to the team’s overall mark.\nYou are expected to make use of the provided GitHub repository as the central collaborative platform. Commits to this repository will be used as one of several metrics of each team member’s relative contribution for each assignment.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#activities-assessment",
    "href": "syllabus.html#activities-assessment",
    "title": "STA 210 Syllabus",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nYou will be assessed based on five components: labs, homework, exams, final project, and participation.\n\nLabs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation and communication. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s Git repository in the course’s GitHub organization as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nLabs will be graded based on completion and workflow. The lowest lab grade will be dropped at the end of the semester. The lowest lab grade will be dropped at the end of the semester.\n\n\nHomework\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis exercises and explain concepts. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be two exams in this course. Each exam will include a closed-note in-class component and an open-note take-home component. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. The exams will focus on both conceptual understanding and application through analysis and computational tasks. The exams will be based on content in prepare assignments, lectures, in-class activities, homework, and lab assignments. More detail about the exams will be given during the semester.\nIf you miss Exam 01 due to a reason documented by a Dean’s Excuse, the Exam 02 score will replace the missed exam score. If you miss Exam 02 due to a reason documented by a Dean’s Excuse, you will make up the exam during the final exam period.\n\n\nProject\nThe purpose of the final project is to apply what you’ve learned to analyze an interesting data-driven research question. More information about the project will be provided during the semester. You can learn more on the Project page.\n\n\nParticipation\nAttending and actively engaging in lecture is important to help you be successful in the course. Attendance and participation will be tracked by turning in some deliverable during lecture (e.g., responding to an online poll question, minute paper, etc.). There are 26 lectures this semester (this does not include exam days). You must participate in at least 18 lectures to get full credit on the participation component of the final course grade. Otherwise, the component is calculated as the percentage of lectures you attended and participated.\nThere are no make ups for the participation activities.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "STA 210 Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\n\nCategory\nPercentage\n\n\n\n\nLabs\n10%\n\n\nHomework\n15%\n\n\nExam 01\n25%\n\n\nExam 02\n25%\n\n\nFinal project\n20%\n\n\nParticipation\n5%\n\n\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "STA 210 Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nDuke Community Standard\nAll students must adhere to the Duke Community Standard(DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard, students agree:\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;and\nI will act if the Standard is compromised.\n\n\n\n\n\n\nAcademic honesty\nTL;DR: Don’t cheat!\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nFor the projects and team labs, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project or team labs across teams.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of artificial intelligence (AI): You should treat AI tools, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:2 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning. (2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\nAI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\nNo AI tools for narrative: Unless instructed otherwise, AI is not permitted for writing narrative that is copy and pasted into the assignment. In general, you may use AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\n\nIf you are unsure if the use of a particular resource complies with the academic honesty policy, please ask a member of the teaching team.\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one’s own work, following proper citation of sources, adhering to guidance around group work projects,and more).Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback in a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nThere is no late work permitted on lab assignments. These are graded for completion, so a lab assignment will be graded as “Not complete” if it is submitted after the deadline.\nHomework and labs may be submitted up to 2 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThe late work policy for exams will be provided with the exam instructions.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a homework assignment by the stated due date, you may email me at maria.tackett@duke.edu before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let me know if you need help contacting your academic dean.\n\n\nRegrade Requests\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the last day of classes.\n\n\nAttendance policy\nEvery student is expected to attend and participate in lecture and labs. There may be times, however, when you cannot attend class. Lecture recordings are available upon request for students who have an excused absence. See the Lecture recording request policy for more detail. If you miss a lecture, make sure to review the material and complete the application exercise, if applicable, before the next lecture. Labs dedicated to completing the lab assignment and collaborating with your lab team. If you miss a lab session, make sure to communicate with your lab TA and teammates about how you can make up your contribution. If you know you’re going to miss a lab session and you’re feeling well enough to do so, notify your lab TA and teammates ahead of time.\nMore details on Trinity attendance policies are available here.\n\n\nLecture recording request\nLectures will be recorded on Panopto and will be made available to students with an excused absence upon request. Videos shared with such students will be available for a week after the lecture date. To request a particular lecture’s video, please fill out the form at the link below. Please submit the form within 24 hours of missing lecture to ensure you have sufficient time to watch the recording. Please also make sure that any official documentation, such as incapacitation forms, Dean’s excuses, NOVAPs, and quarantine/removal from class notices from student health are also uploaded to the form.\n🔗 https://forms.office.com/r/TwGidRkmb0\nAbout one week before each exam, the class recordings will be available to all students. These recordings will be available until the start of the exam.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#accommodations",
    "href": "syllabus.html#accommodations",
    "title": "STA 210 Syllabus",
    "section": "Accommodations",
    "text": "Accommodations\n\nAcademic accommodations\nIf you need accommodations for this class, you will need to register with the Student Disability Access Office (SDAO) and provide them with documentation related to your needs. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.\n\n\nReligious accommodations\nStudents are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: trinity.duke.edu/undergraduate/academic-policies/religious-holidays",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#academic-support",
    "href": "syllabus.html#academic-support",
    "title": "STA 210 Syllabus",
    "section": "Academic support",
    "text": "Academic support\n\nAcademic Resource Center\nThe Academic Resource Center (the ARC) offers services to support students academically during their undergraduate careers at Duke. The ARC can provide support with time management, academic skills and strategies, course-specific tutoring, presentation skills, public speaking, and more. ARC services are available free to all Duke undergraduate students studying any discipline. Learn more:\n\nLearning Consultations – time management, study strategies, learning preferences, and more\nVOICE Lab – strengthen public speaking, practice presentations, and more\n\nYou can contact the Academic Resource Center by phone at (919) 684-5917, by email at theARC@duke.edu, or by visiting http://arc.duke.edu/.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#important-dates",
    "href": "syllabus.html#important-dates",
    "title": "STA 210 Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nJanuary 7: Classes begin\nJanuary 19: Martin Luther King Jr. Day holiday.\nJanuary 21: Drop/Add ends\nMarch 9 - 13: Spring break\nMarch 25: Last day to withdraw with “W”\nApril 22: Classes end\nApril 23-26: Reading period\nApril 27 - May 2: Final exam period\n\nClick here for the full Duke academic calendar.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "STA 210 Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOffice hours are times the teaching team set aside each week to meet with students.↩︎\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D.↩︎↩︎",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "website-files/index.html",
    "href": "website-files/index.html",
    "title": "website-files",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Sunday, February 16\nProject proposal due Thursday, February 27\nExploratory data analysis due Thursday, March 20\nPresentation + Presentation comments due Monday, March 31 (in lab)\nAnalysis draft + peer review due Monday, 21 (peer review in lab)\nWritten report due Wednesday, April 30\nProject highlights due Friday, May 2\nReproducibility + organization due Friday, May 2\nFinal project survey due Saturday, May 3",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-milestones",
    "href": "project.html#project-milestones",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Sunday, February 16\nProject proposal due Thursday, February 27\nExploratory data analysis due Thursday, March 20\nPresentation + Presentation comments due Monday, March 31 (in lab)\nAnalysis draft + peer review due Monday, 21 (peer review in lab)\nWritten report due Wednesday, April 30\nProject highlights due Friday, May 2\nReproducibility + organization due Friday, May 2\nFinal project survey due Saturday, May 3",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#introduction",
    "href": "project.html#introduction",
    "title": "Final project",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio using Quarto and GitHub, and your analysis and written report must be reproducible.\n\nLogistics\nYou will work on the project with your lab groups. The primary deliverables for the project are\n\nan in-person presentation about the exploratory data analysis and initial modeling\na written, reproducible final report detailing your analysis\na summary of your project highlights to share with the class\na GitHub repository containing all work from the project\n\nThere are intermediate milestones and peer review assignments throughout the semester to help you work towards the primary deliverables.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#research-topics",
    "href": "project.html#research-topics",
    "title": "Final project",
    "section": "Research topics",
    "text": "Research topics\nThe goal of this milestone is to discuss topics and develop potential research questions your team is interested in investigating for the project. You are only developing ideas at this point; you do not need to have a data set identified right now.\nDevelop three potential research topics. Include the following for each topic:\n\nA brief description of the topic\nA statement about your motivation for investigating this topic\nThe potential audience(s), i.e., who might be most interested in this research?\nTwo or three potential research questions you could analyze about this topic. (Note: These are draft questions at this point. You will finalize the questions in the next stage of the project.)\nIdeas about the type of data you might use to answer this question or potential data sets you’re interested in using. (Note: The goal is to generate ideas at this point, so it is fine if you have not identified any particular data sets at this point.)\n\n\nSubmission\nWrite your responses in research-topics.qmd in your team’s project GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Sunday, February 16 at 11:59pm. There is no Gradescope submission.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-proposal",
    "href": "project.html#project-proposal",
    "title": "Final project",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is for your team to identify the data set you’re interested in analyzing to investigate one of your potential research topics. You will also do some preliminary exploration of the response variable and begin thinking about the modeling strategy. If you’re unsure where to find data, you can use the list of potential data sources on the Tips + resources page as a starting point.\n\n\n\n\n\n\nImportant\n\n\n\nYou must use the data set(s) in the proposal for the final project, unless instructed otherwise when given feedback.\n\n\nThe data set must meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.\n\ne.g., identifier variables such as “name”, “ID number”, etc. are not useful predictor variables.\ne.g., if you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nMay not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n\n\n\n\n\n\nWarningTypes of data sets to avoid\n\n\n\n\nData that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nData sets in which there is no information about how the data were originally collected\nData sets in which there are missing or unclear definitions about the observations and/or variables\n\n\n\nAsk a member of the teaching team if you’re unsure whether your data set meets the criteria.\nThe proposal will include the following sections:\n\nSection 1: Introduction\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the Research Topics milestone.\n\n\n\nAn introduction to the subject matter you’re investigating (citing any relevant literature)\nStatement of a well-developed research question.\nThe motivation for your research question and why it is important\nYour team’s hypotheses regarding the research question\n\nThis is a narrative about what you think regarding the research question, not formal statistical hypotheses.\n\n\n\n\nSection 2: Data description\n\nThe source of the data set\nA description of when and how the data were originally collected (by the original data curator, not necessarily how you found the data)\nA description of the observations and general characteristics being measured\n\n\n\nSection 3: Data processing\n\nDescription of data processing you need to do to prepare for analysis, such as joining multiple data sets, handling missing data, etc.\nVisualizations, summary statistics, and narrative to describe the distribution of the response variable.\n\n\n\nSection 4: Analysis approach\n\na description of the potential predictor variables of interest\nregression model technique (multiple linear regression for quantitative response variable or logistic regression for a categorical response variable)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of the data folder. You do not need to include the data dictionary in the PDF document.\n\n\nSubmission\nWrite your narrative and analysis for Sections 1 - 4 in the proposal.qmd file in your team’s GitHub repo. Put the data set and the data dictionary in the data folder in the repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Thursday, February 27 at 11:59pm.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages.\nThe proposal is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.\n\nExcellent (5 points) : All required elements are completed and are accurate. The data set meets the requirements (or the team has otherwise discussed the data with Professor Tackett) and the data do not pose obvious violations to the modeling assumptions. There is a thoughtful and comprehensive description of the data, any data processing, and exploration of the response variable as described above. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong (3 - 4 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.\nSatisfactory (2 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (1 point): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#eda",
    "href": "project.html#eda",
    "title": "Final project",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the previous milestones.\n\n\nThe purpose of this milestone is begin exploring the data and get early feedback on your data and analysis. You will submit a draft of the beginning of your report that includes the introduction and exploratory data analysis, with an emphasis on the EDA. It will also help you prepare for the presentation of the exploratory data analysis results.\nBelow is a brief description of the sections to include in this step:\n\nIntroduction\nThis section includes an introduction to the project motivation, background, data, and research question.\n\n\nExploratory data analysis\nThis section includes the following:\n\nDescription of the data set and key variables.\nExploratory data analysis of the response variable and key predictor variables.\n\nUnivariate EDA of the response and key predictor variables.\nBivariate EDA of the response and key predictor variables\nPotential interaction effects.\n\n\n\n\nSubmission\nWrite your draft introduction and exploratory data analysis in the written-report.qmd file in your team’s GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc. with code, warnings, and messages suppressed is about 4 - 6 pages (It is OK to be over this page limit at this stage in the project.)\n\n\n\n\n\n\nTip\n\n\n\nYou can save space by suppressing code, warnings, and messages by including the following in the YAML:\nexecute:\n  echo: false\n  message: false\n  warning: false\n\n\nThe exploratory data analysis is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above, along with incorporating the feedback from the proposal. Points will be assigned based on a holistic review of the exploratory data analysis.\n\nExcellent (9 - 10 points) : All required elements are completed and are accurate. There is a thorough exploration of the data as described above, and the team has demonstrated a careful and thoughtful approach exploring the data and preparing it for analysis. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong: (7 - 8 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some revision of the work required before team is ready for modeling.\nSatisfactory (5 - 6 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (4 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#presentation",
    "href": "project.html#presentation",
    "title": "Final project",
    "section": "Presentation",
    "text": "Presentation\n\n\n\n\n\n\nImportant\n\n\n\nPresentations will take place in class during labs. Presentation order will be announced in advance.\n\n\nYour team will do an in-person presentation that summarizes and showcases the work you’ve done on the project thus far. Because the presentations will take place while you’re still working on the project, it will also be an opportunity to receive feedback and suggestions as well as provide feedback to other teams. The presentation will focus on introducing the subject matter and research question, showcase key results from the exploratory data analysis, and discuss primary modeling strategies and/or results. The presentation should be supported by slides that serve as a brief visual addition to the presentation. The presentation and slides will be graded for content and clarity.\nYou can create your slides with any software you like (e.g., Keynote, PowerPoint, Google Slides, etc.). You can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\nThe presentation is expected to be between 5 to 8 minutes. It may not exceed 8 minutes, due to the limited time during lab.\nEvery team member is expected to speak in the presentation. Part of the grade will be whether every team member had a meaningful speaking role in the presentation.\n\nSlides\nThe slide deck should have no more than 6 content slides + 1 title slide to ensure you have enough time to discuss each slide. s Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the subject, motivation, and research question\nSlide 2: Introduce the data set\nSlide 3 - 4: Highlights from the EDA (be sure to include EDA for the response variable!)\nSlide 5: Initial modeling strategies / results (if applicable)\nSlide 6: Next steps and any questions you’d like to get feedback on\n\n\n\nSubmission\nYou can submit the presentation slides in two ways:\n\nPut a PDF of the slides or Quarto slides in the presentation folder in your team’s GitHub repo.\nPut the URL to your slides in the README of the presentation folder. If you share the URL, please make sure permissions are set so Prof. Tackett can view the slides.\n\n\n\n\n\n\n\nImportant\n\n\n\nSlides must be submitted by the start of your lab on the day of presentations. We will use a classroom computer for the presentations.\n\n\n\n\nGrading\nThe presentation is worth points. It will be graded based on the following:\n\nContent: The team told a unified story that clearly introduced the subject matter, research question, and exploration of the data.\nSlides: The presentation slides were organized, included clear and informative visualizations, and were easily readable.\nPresentation: The team’s communication style was clear and professional. The team divided the time well and stayed within the 8 minute time limit, with each team member making a meaningful contribution to the presentation.\n\n80% of the presentation grade will be the average of the teaching team scores and 20% will be the average of the peer scores.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#presentation-comments",
    "href": "project.html#presentation-comments",
    "title": "Final project",
    "section": "Presentation comments",
    "text": "Presentation comments\n\n\n\n\n\n\nImportant\n\n\n\nClick here to see the teams you’re scoring and a link to the feedback form.\nThis portion of the project is worth 2 points and will be assessed individually.\n\n\nYou will provide feedback on two teams’ presentations. The assigned teams and link to the feedback form will be available in advance of the presentations. Please provide all scores and comments by the end of the lab session. There will be a few minutes between each presentation to submit scores and comments.\nThe grade will be based on submitting the scores and comments for both of your assigned teams by the end of the presentation day.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#draft-report-peer-review",
    "href": "project.html#draft-report-peer-review",
    "title": "Final project",
    "section": "Analysis + peer review",
    "text": "Analysis + peer review\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\n\nDraft report\nWrite the draft in the written-report.qmd file in your project repo.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the body of the report, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model.\n\n\nGrading\nThe draft will be graded based on whether there is demonstration of a reasonable attempt at each of the sections described below in the written report file in the GitHub repo by the deadline.\n\n\n\nPeer review\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 210 is no exception. Each lab team will be assigned two other teams’ projects to review. Each team should push their draft to their GitHub repo by 10 am on the day their lab’s draft is due. The lab that week will be dedicated to the peer review, so your team will have time to review and provide quality feedback to two other teams.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided in the repo.\n\nSteps for peer review\n\n\n\n\n\n\nImportantPeer review assignments\n\n\n\nClick here to see the teams you’re peer reviewing.You’ll spend about 30 minutes reviewing each project.\n\n\n\nWhen you get to lab, you should have access to the GitHub repos for the teams you’re reviewing. In GitHub, search the repositories for project, and you should see the repos for the projects you’re reviewing. You will be able to read the files in the repo and post issues, but you cannot push changes to the repo. You will have access to the repo until the deadline for the peer review.\nYou may choose to all work on both peer reviews or have some team members focus on a single peer review. Either way there will be one peer review grade assigned per team.\nFor each team you’re reviewing:\n\nOpen that team’s repo, read the project draft, and browse the rest of the repo.\nGo to the Issues tab in that repo, click on New issue, and click on Get started for the Peer Review issue. Write your responses to the prompts in the issue. You will answer the following questions:\n\nDescribe the goal of the project.\nDescribe the data set used in the project. What are the observations in the data? What is the source of the data? How were the data originally collected?\nConsider the exploratory data analysis (EDA). Describe one aspect of the EDA that is effective in helping you understand the data. Provide constructive feedback on how the team might improve the EDA.\nDescribe the statistical methods, analysis approach, and discussion of model assumptions, diagnostics, model fit.\nProvide constructive feedback on how the team might improve their analysis. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but also feel free to comment on aspects beyond the modeling.\nProvide constructive feedback on the interpretations and initial conclusion. What is most effective in the presentation of the results? What additional detail can the team provide to make the results and conclusions easier for the reader to understand?\nWhat aspect of this project are you most interested in and think would be interesting to highlight in the written report?\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?\n\n\n\n\n\nGrading\nThe peer review will be graded on the extent to which each comprehensively and constructively addresses the components on the peer review form. There will be one peer review grade per team.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#written-report",
    "href": "project.html#written-report",
    "title": "Final project",
    "section": "Written report",
    "text": "Written report\n\n\n\n\n\n\nImportant\n\n\n\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the code chunks are not visible and all messages and warnings are suppressed.\n\n\n\nYou will submit the PDF of your final report on GitHub.\nThe PDF you submit must match the .qmd in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including tables and visualizations, must be no more than 10 pages long. There is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will overwhelmingly be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the variables in the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.\n\n\n\nResults\nThis is where you will output and discuss the final model.\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe model fit is clearly assessed, and interesting findings from the model are clearly described. The model conditions and diagnostics are thoroughly and accurately assessed for the final model, if not previously discussed in the methodology. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model’s predictive power is thoroughly assessed.\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted and labeled. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#project-highlights",
    "href": "project.html#project-highlights",
    "title": "Final project",
    "section": "Project highlights",
    "text": "Project highlights\n\n\n\n\n\n\nImportant\n\n\n\nYour project highlights will be posted as a reply to the “Final project highlights” thread under the Discussions tab on Canvas.\nYou are welcome to but not required to put the highlights in your project repo.\n\n\nThe project highlights are an opportunity to share an overview of your project and final results with your peers! Choose one of the following formats to share your highlights:\n\nOption 1: Structured Abstract\nA structured abstract extends on a traditional abstract by separating the content into separate sections. The abstract will be about 200 - 400 words and will be split into the following sections:\n\nProject title\nBackground (also called Objectives in some journals)\nMethods\nResults\nConclusions\n\nBelow are some examples of structured abstracts. These examples are here to give you an idea of what a structured abstract looks like; you are not required (or expected) to exactly replicate any one of these abstracts.\n\n\nStructured abstract example 1\nStructured abstract example 2\nTips for writing abstracts (see Example Abstract 4: A Structured Abstract)\n\n\n\nOption 2: Summary slides\nThis is a good option if you would like to include some visualizations and output along with a short narrative describing the project highlights. These slides can be organized similarly as the structured abstract (option 1) with a slide for each section:\n\nTitle slide\nBackground\nMethods\nResults\nConclusions\n\n\n\nOption 3: Summary video\nThis is a good option if you would like to record a short presentation sharing your project highlights. You may use slides following a similar structure as Option 2 or find another creative way to present your results! The video should be no longer that 3 minutes.\n\n\nGrading criteria\nThe project highlights will be graded based on how clarity of the summary and neatly done abstracts, slides, or video.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#reproducibility-organization",
    "href": "project.html#reproducibility-organization",
    "title": "Final project",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Project title and team name\n\nOptional: Short project summary\n\nwritten-report.qmd & written-report.pdf: Final written report\nproposal.qmd & proposal.pdf: Project proposal\nresearch-topics.qmd & research-topics.pdf: Proposed research questions\n/data: Folder that contains the data set for the final project.\n\n/data/README.md: Data dictionary and source for data set\n\nproject.Rproj: File specifying the RStudio project\n/presentation: Folder with the presentation slides or link to slides.\n.gitignore: File that lists all files that are in the local RStudio project but not the GitHub repo\n/.github: Folder for peer review issue template\nAny other files should be neatly organized into clearly labeled folders.\n\nUpdate the README of the project repo with your project title and team members’ names.\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#final-project-survey",
    "href": "project.html#final-project-survey",
    "title": "Final project",
    "section": "Final project survey",
    "text": "Final project survey\nYou will complete a short survey about the project. You will receive the survey via email.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#peer-teamwork-evaluation",
    "href": "project.html#peer-teamwork-evaluation",
    "title": "Final project",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nThere will be an opportunity to provide feedback to Professor Tackett about each team member’s contribution to the project. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#overall-grading",
    "href": "project.html#overall-grading",
    "title": "Final project",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nResearch topics\n3 pts\n\n\nProject proposal\n5 pts\n\n\nExploratory data analysis\n10 pts\n\n\nPresentation\n10 pts\n\n\nPresentation comments\n2 pts\n\n\nDraft report + peer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nProject highlights\n15 pts\n\n\nReproducibility + organization\n3 pts\n\n\nProject survey\n2 pts\n\n\n\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Team understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Team understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Team has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Team is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%*: Team is not making a sufficient effort.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "project.html#late-work-policy",
    "href": "project.html#late-work-policy",
    "title": "Final project",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.\nBe sure to turn in your work early to avoid any technological mishaps.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  }
]