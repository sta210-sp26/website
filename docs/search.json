[
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you’re having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you’ll find an entry called Container Manager (CMGR Coursework Containers).",
    "crumbs": [
      "Computing",
      "Troubleshooting"
    ]
  },
  {
    "objectID": "computing-troubleshooting.html#footnotes",
    "href": "computing-troubleshooting.html#footnotes",
    "title": "Computing troubleshooting",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThese troubleshooting steps are from https://sta199-f25.github.io/computing-troubleshooting.html↩︎",
    "crumbs": [
      "Computing",
      "Troubleshooting"
    ]
  },
  {
    "objectID": "project-draft.html",
    "href": "project-draft.html",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Thursday, February 13\nProject proposal \nExploratory data analysis \nPresentation + Presentation comments \nAnalysis draft + peer review \nWritten report \nProject highlights \nReproducibility + organization \nFinal project survey"
  },
  {
    "objectID": "project-draft.html#project-milestones",
    "href": "project-draft.html#project-milestones",
    "title": "Final project",
    "section": "",
    "text": "Research topics due Thursday, February 13\nProject proposal \nExploratory data analysis \nPresentation + Presentation comments \nAnalysis draft + peer review \nWritten report \nProject highlights \nReproducibility + organization \nFinal project survey"
  },
  {
    "objectID": "project-draft.html#introduction",
    "href": "project-draft.html#introduction",
    "title": "Final project",
    "section": "Introduction",
    "text": "Introduction\nTL;DR: Pick a data set and do a regression analysis. That is your final project.\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\nChoose the data based on your group’s interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\nAll analyses must be done in RStudio using Quarto and GitHub, and your analysis and written report must be reproducible.\n\nLogistics\nYou will work on the project with your lab groups. The primary deliverables for the project are\n\nan in-person presentation about the exploratory data analysis and initial modeling\na written, reproducible final report detailing your analysis\na summary of your project highlights to share with the class\na GitHub repository containing all work from the project\n\nThere are intermediate milestones and peer review assignments throughout the semester to help you work towards the final deliverables."
  },
  {
    "objectID": "project-draft.html#research-topics",
    "href": "project-draft.html#research-topics",
    "title": "Final project",
    "section": "Research topics",
    "text": "Research topics\nThe goal of this milestone is to discuss topics and develop potential research questions your team is interested in investigating for the project. You are only developing ideas at this point; you do not need to have a data set identified at this point.\nDevelop three potential research topics. Include the following for each topic:\n\nA brief description of the topic\nA statement about your motivation for investigating this topic.\nThe potential audience(s), i.e., who might be most interested in this research?\nTwo or three potential research questions you could analyze about this topic.\nIdeas about the type of data you might use to answer this question or potential data sets you’re interested in using. [Note: The goal is to generate ideas at this point, so it is fine if you have not identified any particular data sets at this point.]\n\n\nSubmission\nWrite your responses in research-topics.qmd in your team’s project GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline, Thursday, February 13 at 11:59pm."
  },
  {
    "objectID": "project-draft.html#project-proposal",
    "href": "project-draft.html#project-proposal",
    "title": "Final project",
    "section": "Project proposal",
    "text": "Project proposal\nThe purpose of the project proposal is for your team to identify the data set you’re interested in analyzing to investigate one of your potential research questions. You will also do some preliminary exploration of the response variable and begin thinking about the modeling strategy. If you’re unsure where to find data, you can use the list of potential data sources on the Tips + resources page as a starting point.\n\n\n\n\n\n\nImportant\n\n\n\nYou must the data set(s) in the proposal for the final project, unless instructed otherwise when given feedback.\n\n\nThe data set must meet the following criteria:\n\nAt least 500 observations\nAt least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.\n\ne.g., identifier variables such as “name”, “ID number”, etc. are not useful predictor variables.\ne.g., if you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique predictors.\n\nAt least one variable that can be identified as a reasonable response variable.\n\nThe response variable can be quantitative or categorical.\n\nA mix of quantitative and categorical variables that can be used as predictors.\nMay not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n\n\n\n\n\n\nWarningTypes of data sets to avoid\n\n\n\n\nData that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\nData sets in which there is no information about how the data were originally collected\nData sets in which there are missing or unclear definitions about the observations and/or variables\n\n\n\nAsk a member of the teaching team if you’re unsure whether your data set meets the criteria.\nThe proposal will include the following sections:\n\nSection 1: Introduction\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the Research Questions milestone.\n\n\n\nAn introduction to the subject matter you’re investigating (citing any relevant literature)\nStatement of a well-developed research question.\nThe motivation for your research question and why it is important\nYour team’s hypotheses regarding the research question\n\nThis is a narrative about what you think regarding the research question, not formal statistical hypotheses.\n\n\n\n\nSection 2: Data description\n\nThe source of the data set\nA description of when and how the data were originally collected (by the original data curator, not necessarily how you found the data)\nA description of the observations and general characteristics being measured\n\n\n\nSection 3: Initial exploratory data analysis\n\nDescription of data cleaning you need to do to prepare for analysis (can focus on the response variable for now), such as joining data sets, imputing missing values, variable transformation, creating a new variable, etc.\nVisualizations, summary statistics, and narrative to describe the distribution of the response variable.\n\n\n\nSection 4: Analysis approach\n\na description of the potential predictor variables of interest\nregression model technique (multiple linear regression for quantitative response variable or logistic regression for a categorical response variable)\n\n\n\nData dictionary (aka code book)\nSubmit a data dictionary for all the variables in your data set in the README of the data folder. You do not need to include the data dictionary in the PDF document.\n\n\nSubmission\nWrite your narrative and analysis for Sections 1 - 4 in the proposal.qmd file in your team’s GitHub repo. Put the data set and the data dictionary in the data folder in the repo. Push the qmd and rendered pdf documents to GitHub by the deadline.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages.\nThe proposal is worth 10 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.\n\nExcellent (9 - 10 points) : All required elements are completed and are accurate. The data set meets the requirements (or the team has otherwise discussed the data with Professor Tackett) and the data do not pose obvious violations to the modeling assumptions. There is a thoughtful and comprehensive description of the data and exploration of the response variable as described above. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong (7 - 8 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.\nSatisfactory (5 - 6 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (4 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling."
  },
  {
    "objectID": "project-draft.html#eda",
    "href": "project-draft.html#eda",
    "title": "Final project",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\n\n\n\n\nTip\n\n\n\nReuse and iterate on the work from the previous milestones.\n\n\nThe purpose of this milestone is begin exploring the data and get early feedback on your data and analysis. You will submit a draft of the beginning of your report that includes the introduction and exploratory data analysis, with an emphasis on the EDA. It will also help you prepare for the presentation of the exploratory data analysis results.\nBelow is a brief description of the sections to include in this step:\n\nIntroduction\nThis section includes an introduction to the project motivation, background, data, and research question.\n\n\nExploratory data analysis\nThis section includes the following:\n\nDescription of the data set and key variables.\nExploratory data analysis of the response variable and key predictor variables.\n\nUnivariate EDA of the response and key predictor variables.\nBivariate EDA of the response and key predictor variables\nPotential interaction effects.\n\n\n\n\nSubmission\nWrite your draft introduction and exploratory data analysis in the written-report.qmd file in your team’s GitHub repo. Push the qmd and rendered pdf documents to GitHub by the deadline.\n\n\nGrading\nThe anticipated length, including all graphs, tables, narrative, etc. with code, warnings, and messages suppressed is about about 4 - 6 pages.\n\n\n\n\n\n\nTip\n\n\n\nYou can suppress code, warnings, and messages by including the following in the YAML:\nexecute: \n  echo: false\n  message: false\n  warning: false\n\n\nThe exploratory data analysis is worth 15 points and will be graded based on accurately and comprehensively addressing the criteria stated above, along with incorporating the feedback from the proposal. Points will be assigned based on a holistic review of the exploratory data analysis.\n\nExcellent (14 - 15 points) : All required elements are completed and are accurate. There is a thorough exploration of the data as described above, and the team has demonstrated a careful and thoughtful approach exploring the data and preparing it for analysis. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nStrong: (11 - 13 points): Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some revision of the work required before team is ready for modeling.\nSatisfactory (8 - 10 points): Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\nNeeds Improvement (7 or fewer points points): Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling."
  },
  {
    "objectID": "project-draft.html#presentation",
    "href": "project-draft.html#presentation",
    "title": "Final project",
    "section": "Presentation",
    "text": "Presentation\n\n\n\n\n\n\nImportant\n\n\n\nPresentations will take place in class during labs. Presentation order will be announced in advance.\n\n\nYour team will do an in-person presentation that summarizes and showcases the work you’ve done on the project thus far. Because the presentations will take place while you’re still working on the project, it will also be an opportunity to receive feedback and suggestions as well as provide feedback to other teams. The presentation will focus on introducing the subject matter and research question, showcase key results from the exploratory data analysis, and discuss primary modeling strategies and/or results. The presentation should be supported by slides that serve as a brief visual addition to the presentation. The presentation and slides will be graded for content and clarity.\nYou can create your slides with any software you like (e.g., Keynote, PowerPoint, Google Slides, etc.). You can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\nThe presentation is expected to be between 5 to 8 minutes. It may not exceed 8 minutes, due to the limited time during lab.\nEvery team member is expected to speak in the presentation. Part of the grade will be whether every team member had a meaningful speaking role in the presentation.\n\nSlides\nThe slide deck should have no more than 6 content slides + 1 title slide to ensure you have enough time to discuss each slide. s Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the subject, motivation, and research question\nSlide 2: Introduce the data set\nSlide 3 - 4: Highlights from the EDA (be sure to include EDA for the response variable!)\nSlide 5: Initial modeling strategies / results\nSlide 6: Next steps and any questions you’d like to get feedback on\n\n\n\nSubmission\nYou can submit the presentation slides in two ways:\n\nPut a PDF of the slides or Quarto slides in the presentation folder in your team’s GitHub repo.\nPut the URL to your slides in the README of the presentation folder. If you share the URL, please make sure permissions are set so Prof. Tackett can view the slides.\n\n\n\n\n\n\n\nImportant\n\n\n\nSlides must be submitted by the start of your lab on the day of presentations. We will use a classroom computer for the presentations.\n\n\n\n\nGrading\nThe presentation is worth points. It will be graded based on the following:\n\nContent: The team told a unified story that clearly introduced the subject matter, research question, and exploration of the data.\nSlides: The presentation slides were organized, included clear and informative visualizations, and were easily readable.\nPresentation: The team’s communication style was clear and professional. The team divided the time well and stayed within the 8 minute time limit, with each team member making a meaningful contribution to the presentation.\n\n80% of the presentation grade will be the average of the teaching team scores and 20% will be the average of the peer scores."
  },
  {
    "objectID": "project-draft.html#presentation-comments",
    "href": "project-draft.html#presentation-comments",
    "title": "Final project",
    "section": "Presentation comments",
    "text": "Presentation comments\n\n\n\n\n\n\nImportant\n\n\n\nClick here to see the teams you’re scoring and a link to the feedback form.\nThis portion of the project is worth 2 points and will be assessed individually.\n\n\nYou will provide feedback on two teams’ presentations. The assigned teams and link to the feedback form will be available in advance of the presentations. Please provide all scores and comments by the end of the lab session. There will be a few minutes between each presentation to submit scores and comments.\nThe grade will be based on submitting the scores and comments for both of your assigned teams by the end of the presentation day, November 11."
  },
  {
    "objectID": "project-draft.html#draft-report-peer-review",
    "href": "project-draft.html#draft-report-peer-review",
    "title": "Final project",
    "section": "Analysis + peer review",
    "text": "Analysis + peer review\nThe purpose of the draft and peer review is to give you an opportunity to get early feedback on your analysis. Therefore, the draft and peer review will focus primarily on the exploratory data analysis, modeling, and initial interpretations.\n\nDraft report\nWrite the draft in the written-report.qmd file in your project repo.\nBelow is a brief description of the sections to focus on in the draft:\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the body of the report, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, any variable transformations (if needed), and any other relevant considerations that were part of the model fitting process.\n\n\nResults\nIn this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.\nThis section also includes initial interpretations and conclusions drawn from the model.\n\n\nGrading\nThe draft will be graded based on whether there is demonstration of a reasonable attempt at each of the sections described below in the written report file in the GitHub repo by the deadline.\n\n\n\nPeer review\nCritically reviewing others’ work is a crucial part of the scientific process, and STA 221 is no exception. Each lab team will be assigned two other teams’ projects to review. Each team should push their draft to their GitHub repo by 10 am on the day their lab’s draft is due. The lab that week will be dedicated to the peer review, so your team will have time to review and provide quality feedback to two other teams.\nDuring the peer review process, you will be provided read-only access to your partner teams’ GitHub repos. Provide your review in the form of GitHub issues to your partner team’s GitHub repo using the issue template provided in the repo.\n\nSteps for peer review\n\n\n\n\n\n\nImportantPeer review assignments\n\n\n\nClick here to see the teams you’re peer reviewing.You’ll spend about 30 minutes reviewing each project.\n\n\n\nWhen you get to lab, you should have access to the GitHub repos for the teams you’re reviewing. In GitHub, search the repositories for project, and you should see the repos for the projects you’re reviewing. You will be able to read the files in the repo and post issues, but you cannot push changes to the repo. You will have access to the repo until the deadline for the peer review.\nYou may choose to all work on both peer reviews or have some team members focus on a single peer review. Either way there will be one peer review grade assigned per team.\nFor each team you’re reviewing:\n\nOpen that team’s repo, read the project draft, and browse the rest of the repo.\nGo to the Issues tab in that repo, click on New issue, and click on Get started for the Peer Review issue. Write your responses to the prompts in the issue. You will answer the the following questions:\n\nDescribe the goal of the project.\nDescribe the data set used in the project. What are the observations in the data? What is the source of the data? How were the data originally collected?\nConsider the exploratory data analysis (EDA). Describe one aspect of the EDA that is effective in helping you understand the data. Provide constructive feedback on how the team might improve the EDA.\nDescribe the statistical methods, analysis approach, and discussion of model assumptions, diagnostics, model fit.\nProvide constructive feedback on how the team might improve their analysis. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but also feel free to comment on aspects beyond the modeling.\nProvide constructive feedback on the interpretations and initial conclusion. What is most effective in the presentation of the results? What additional detail can the team provide to make the results and conclusions easier for the reader to understand?\nWhat aspect of this project are you most interested in and think would be interesting to highlight in the written report?\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?\n\n\n\n\n\nGrading\nThe peer review will be graded on the extent to which each comprehensively and constructively addresses the components on the peer review form. There will be one peer review grade per team."
  },
  {
    "objectID": "project-draft.html#written-report",
    "href": "project-draft.html#written-report",
    "title": "Final project",
    "section": "Written report",
    "text": "Written report\n\n\n\n\n\n\nImportant\n\n\n\nYour written report must be completed in the written-report.qmd file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits.\nBefore you finalize your write up, make sure the code chunks are not visible and all messages and warnings are suppressed.\n\n\n\nYou will submit the PDF of your final report on GitHub.\nThe PDF you submit must match the .qmd in your GitHub repository exactly. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including tables and visualizations, must be no more than 10 pages long. There is no minimum page requirement; however, you should comprehensively address all of the analysis and report.\nBe selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis.\nYou are welcome to include an appendix with additional work at the end of the written report document; however, grading will overwhelmingly be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit.\n\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\n\n\n\nResults\n\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\n\n\n\nDiscussion + Conclusion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report."
  },
  {
    "objectID": "project-draft.html#project-highlights",
    "href": "project-draft.html#project-highlights",
    "title": "Final project",
    "section": "Project highlights",
    "text": "Project highlights"
  },
  {
    "objectID": "project-draft.html#reproducibility-organization",
    "href": "project-draft.html#reproducibility-organization",
    "title": "Final project",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nThe GitHub repo should have the following structure:\n\nREADME: Short project description and data dictionary\nwritten-report.qmd & written-report.pdf: Final written report\nproposal.qmd & proposal.pdf: Project proposal\nresearch-questions.qmd & research-questions.pdf: Proposed research questions\n/data: Folder that contains the data set for the final project.\nproject.Rproj: File specifying the RStudio project\n/presentation: Folder with the presentation slides or link to slides.\n.gitignore: File that lists all files that are in the local RStudio project but not the GitHub repo\n/.github: Folder for peer review issue template\nAny other files should be neatly organized into clearly labeled folders.\n\nUpdate the README of the project repo with your project title and a few sentences (~ 2 -5) describing your final project.\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-draft.html#final-project-survey",
    "href": "project-draft.html#final-project-survey",
    "title": "Final project",
    "section": "Final project survey",
    "text": "Final project survey"
  },
  {
    "objectID": "project-draft.html#peer-teamwork-evaluation",
    "href": "project-draft.html#peer-teamwork-evaluation",
    "title": "Final project",
    "section": "Peer teamwork evaluation",
    "text": "Peer teamwork evaluation\nThere will be an opportunity to provide feedback to Professor Tackett about each team member’s contribution to the project. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly."
  },
  {
    "objectID": "project-draft.html#overall-grading",
    "href": "project-draft.html#overall-grading",
    "title": "Final project",
    "section": "Overall grading",
    "text": "Overall grading\nThe grade breakdown is as follows:\n\n\n\nTotal\n100 pts\n\n\n\n\nResearch topics\n3 pts\n\n\nProject proposal\n5 pts\n\n\nExploratory data analysis\n10 pts\n\n\nPresentation\n10 pts\n\n\nPresentation comments\n2 pts\n\n\nDraft report + peer review\n10 pts\n\n\nWritten report\n40 pts\n\n\nProject highlights\n15 pts\n\n\nReproducibility + organization\n3 pts\n\n\nProject survey\n2 pts\n\n\n\n\nGrading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort."
  },
  {
    "objectID": "project-draft.html#late-work-policy",
    "href": "project-draft.html#late-work-policy",
    "title": "Final project",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.\nBe sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "project-tips.html",
    "href": "project-tips.html",
    "title": "Final project tips + resources",
    "section": "",
    "text": "Data sources\n\nSome resources that may be helpful as you find data:\n\nFiveThirtyEight data\nTidyTuesday\nData Is Plural\nR Data Sources for Regression Analysis\n\n\n\nOther data repositories\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies\n\n\n\n\nTips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your Qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.\n\n\n\nFormatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\nAn alternative approach is to add the following code to the YAML:\n\nexecute:\n  echo: false\n  warning: false\n  message: false\n\n\n\n\nHeaders\n\nUse headers to clearly label each section. Make sure there is a space between the last # and the title, so the header renders correctly. For example, ###Section Title will not render as header, but ### Section Title will.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\n\nResize plots and figures, so you have more space for the narrative.\n\nResize individual figures: Use the code chunk header {r plot1, fig.height = 3, fig.width = 5}, replacing plot1 with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig_width and fig_height options in your YAML header as shown below:\n\n\n\n---\ntitle: \"Your title\"\nauthor: \"Your names\"\nformat:\n  pdf:\n    fig-width: 7\n    fig-height: 5\n---\nReplace the height and width values with values appropriate for your write up.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\n\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\nIf you’re using base R function, i.e. when using the emplogit functions, put the code par(mfrow = c(rows,columns)) before the code to make the plots. For example, par(mfrow = c(2,3)) will arrange plots in a grid with 2 rows and 3 columns.\n\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\nUse coord_flip() to flip the x and y axes on the plot. This is useful if you a bar plot with an x-axis that is difficult to read due to overlapping text.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg |&gt;\n  count(manufacturer) |&gt;\n  mutate(manufacturer = str_to_title(manufacturer)) |&gt;\n  ggplot(aes(x = fct_reorder(manufacturer,n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  coord_flip() +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_bw() \n\n\n\n\n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel &lt;- lm(mpg ~ hp, data = mtcars)\ntidy(model) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document.\n\n\n\n\nAdditional resources\n\nExploring RStudio’s Visual Markdown Editor\nR for Data Science\nQuarto documentation:\n\nQuarto PDF Basics\nPresentations in Quarto\n\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package",
    "crumbs": [
      "Project",
      "Tips + resources"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "slides/02-big-picture.html#announcements",
    "href": "slides/02-big-picture.html#announcements",
    "title": "The big picture",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours start this week\n\nSee office hours schedule on Canvas\n\nComplete Lab 00 tasks\nIntroduction to R workshops at Duke library\n\nSee Monday’s Canvas announcement\n\nTriangle"
  },
  {
    "objectID": "slides/02-big-picture.html#topics",
    "href": "slides/02-big-picture.html#topics",
    "title": "The big picture",
    "section": "Topics",
    "text": "Topics\n\nData science workflow\nReproducible data analysis\nAnalyzing multivariable relationships"
  },
  {
    "objectID": "slides/02-big-picture.html#data-science-workflow",
    "href": "slides/02-big-picture.html#data-science-workflow",
    "title": "The big picture",
    "section": "Data science workflow",
    "text": "Data science workflow\n\nSource: Introduction to Regression Analysis: A Data Science Approach"
  },
  {
    "objectID": "slides/02-big-picture.html#reproducibility-checklist",
    "href": "slides/02-big-picture.html#reproducibility-checklist",
    "title": "The big picture",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for an analysis to be reproducible?\n\n\nNear term goals:\n✔️ Can the tables and figures be exactly reproduced from the code and data?\n✔️ Does the code actually do what you think it does?\n✔️ In addition to what was done, is it clear why it was done?\n\n\nLong term goals:\n✔️ Can the code be used for other data?\n✔️ Can you extend the code to do other things?"
  },
  {
    "objectID": "slides/02-big-picture.html#why-is-reproducibility-important",
    "href": "slides/02-big-picture.html#why-is-reproducibility-important",
    "title": "The big picture",
    "section": "Why is reproducibility important?",
    "text": "Why is reproducibility important?\n\nResults produced are more reliable and trustworthy (Ostblom and Timbers 2022)\nFacilitates more effective collaboration (Ostblom and Timbers 2022)\nContributing to science, which builds and organizes knowledge in terms of testable hypotheses (Alexander 2023)\nPossible to identify and correct errors or biases in the analysis process (Alexander 2023)"
  },
  {
    "objectID": "slides/02-big-picture.html#toolkit",
    "href": "slides/02-big-picture.html#toolkit",
    "title": "The big picture",
    "section": "Toolkit",
    "text": "Toolkit\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/02-big-picture.html#r-and-rstudio",
    "href": "slides/02-big-picture.html#r-and-rstudio",
    "title": "The big picture",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nR is a statistical programming language\nRStudio is a convenient interface for R (an integrated development environment, IDE)\n\n\nSource: Statistical Inference via Data Science"
  },
  {
    "objectID": "slides/02-big-picture.html#rstudio-ide",
    "href": "slides/02-big-picture.html#rstudio-ide",
    "title": "The big picture",
    "section": "RStudio IDE",
    "text": "RStudio IDE"
  },
  {
    "objectID": "slides/02-big-picture.html#quarto",
    "href": "slides/02-big-picture.html#quarto",
    "title": "The big picture",
    "section": "Quarto",
    "text": "Quarto\n\nFully reproducible reports – the analysis is run from the beginning each time you render\nCode goes in chunks and narrative goes outside of chunks\nVisual editor to make document editing experience similar to a word processor (Google docs, Word, Pages, etc.)"
  },
  {
    "objectID": "slides/02-big-picture.html#quarto-1",
    "href": "slides/02-big-picture.html#quarto-1",
    "title": "The big picture",
    "section": "Quarto",
    "text": "Quarto"
  },
  {
    "objectID": "slides/02-big-picture.html#how-will-we-use-quarto",
    "href": "slides/02-big-picture.html#how-will-we-use-quarto",
    "title": "The big picture",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise and assignment is written in a Quarto document\nYou’ll have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/02-big-picture.html#what-is-versioning",
    "href": "slides/02-big-picture.html#what-is-versioning",
    "title": "The big picture",
    "section": "What is versioning?",
    "text": "What is versioning?"
  },
  {
    "objectID": "slides/02-big-picture.html#what-is-versioning-1",
    "href": "slides/02-big-picture.html#what-is-versioning-1",
    "title": "The big picture",
    "section": "What is versioning?",
    "text": "What is versioning?\nwith human readable messages"
  },
  {
    "objectID": "slides/02-big-picture.html#why-do-we-need-version-control",
    "href": "slides/02-big-picture.html#why-do-we-need-version-control",
    "title": "The big picture",
    "section": "Why do we need version control?",
    "text": "Why do we need version control?\n\n\n\n\n\n\n\n\nProvides a clear record of how the analysis methods evolved. This makes analysis auditable and thus more trustworthy and reliable. (Ostblom and Timbers 2022)"
  },
  {
    "objectID": "slides/02-big-picture.html#git-and-github",
    "href": "slides/02-big-picture.html#git-and-github",
    "title": "The big picture",
    "section": "git and GitHub",
    "text": "git and GitHub\n\n\ngit is a version control system – like “Track Changes” features from Microsoft Word.\nGitHub is the home for your git-based projects on the internet (like DropBox but much better).\nThere are a lot of git commands and very few people know them all. 99% of the time you will use git to add, commit, push, and pull."
  },
  {
    "objectID": "slides/02-big-picture.html#factors-associated-with-life-expectancy",
    "href": "slides/02-big-picture.html#factors-associated-with-life-expectancy",
    "title": "The big picture",
    "section": "Factors associated with life expectancy",
    "text": "Factors associated with life expectancy\nThe data set comes from Zarulli et al. (2021) who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThe data are available in life-expectancy-data.csv. There are 140 countries (observations) in the data set.\n\n\nClick here for the original research paper."
  },
  {
    "objectID": "slides/02-big-picture.html#variable-definitions",
    "href": "slides/02-big-picture.html#variable-definitions",
    "title": "The big picture",
    "section": "Variable definitions",
    "text": "Variable definitions\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic area. ( from the World Health Organization)\nincome_inequality: Measure of the deviation of the distribution of income among individuals or households within a country from a perfectly equal distribution. A value of 0 represents absolute equality, a value of 100 absolute inequality (Gini coefficient)."
  },
  {
    "objectID": "slides/02-big-picture.html#variable-definitions-1",
    "href": "slides/02-big-picture.html#variable-definitions-1",
    "title": "The big picture",
    "section": "Variable definitions",
    "text": "Variable definitions\n\neducation: Indicator of whether a country’s education index is above (High) or below (Low) the median index for the 140 countries in the data set.\n\nEducation index: Average of mean years of schooling (of adults) and expected years of school (of children), both expressed as an index obtained by scaling wit the corresponding maxima."
  },
  {
    "objectID": "slides/02-big-picture.html#terminology",
    "href": "slides/02-big-picture.html#terminology",
    "title": "The big picture",
    "section": "Terminology",
    "text": "Terminology\n\nlife_exp is the response variable\n\nvariable whose variation we want to understand / variable we wish to predict\nalso known as outcome or dependent variable\n\n\n\n\nincome_inequality, education are the predictor variables\n\nvariables used to account for variation in the response\nalso known as explanatory, independent, or input variables"
  },
  {
    "objectID": "slides/02-big-picture.html#univariate-exploratory-data-analysis",
    "href": "slides/02-big-picture.html#univariate-exploratory-data-analysis",
    "title": "The big picture",
    "section": "Univariate exploratory data analysis",
    "text": "Univariate exploratory data analysis"
  },
  {
    "objectID": "slides/02-big-picture.html#bivariate-exploratory-data-analysis",
    "href": "slides/02-big-picture.html#bivariate-exploratory-data-analysis",
    "title": "The big picture",
    "section": "Bivariate exploratory data analysis",
    "text": "Bivariate exploratory data analysis"
  },
  {
    "objectID": "slides/02-big-picture.html#function-between-response-and-predictors",
    "href": "slides/02-big-picture.html#function-between-response-and-predictors",
    "title": "The big picture",
    "section": "Function between response and predictors",
    "text": "Function between response and predictors\n\n\\[\\text{life_exp} = f(\\text{income_inequality}, \\text{education}) + \\epsilon\\]\n\n\nGoal: Determine \\(f\\)\nHow do we determine \\(f\\)?\n\nMake an assumption about the functional form \\(f\\) (parametric model)\nUse the data to fit a model based on that form"
  },
  {
    "objectID": "slides/02-big-picture.html#determine-f",
    "href": "slides/02-big-picture.html#determine-f",
    "title": "The big picture",
    "section": "Determine \\(f\\)",
    "text": "Determine \\(f\\)\n\nChoose the functional form of \\(f\\), i.e., choose the appropriate model given the response variable\n\n\nSuppose \\(f\\) takes the form of a linear model\n\\[Y = f(\\mathbf{X}) = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p + \\epsilon\\]\n\n\n\nUse the data to fit (or train) the model, i.e, compute estimates of the model parameters, denoted \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_p\\)"
  },
  {
    "objectID": "slides/02-big-picture.html#life_exp-vs.-income_inequality",
    "href": "slides/02-big-picture.html#life_exp-vs.-income_inequality",
    "title": "The big picture",
    "section": "life_exp vs. income_inequality",
    "text": "life_exp vs. income_inequality\n\n\\[\\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality}\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#life_exp-vs.-income_inequality-education",
    "href": "slides/02-big-picture.html#life_exp-vs.-income_inequality-education",
    "title": "The big picture",
    "section": "life_exp vs. income_inequality + education",
    "text": "life_exp vs. income_inequality + education\n\n\\[\\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality} + \\hat{\\beta}_2 ~\\text{education}\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#statistical-model-vs.-regression-equation",
    "href": "slides/02-big-picture.html#statistical-model-vs.-regression-equation",
    "title": "The big picture",
    "section": "Statistical model vs. regression equation",
    "text": "Statistical model vs. regression equation\nStatistical model (also known as the data-generating model)\n\n\\[{\\small \\text{life_exp} = \\beta_0 + \\beta_1 ~\\text{income_inequality} + \\beta_2 ~\\text{education} + \\epsilon}\\]\n\nModels the process for generating values of the response in the population (function + error), i.e., the population-level model.\n\n\nRegression equation (also known as the fitted model)\nEstimate of the function using the sample data\n\n\\[{\\small \\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality} + \\hat{\\beta}_2 ~\\text{education}}\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#life_exp-vs.-income_inequality-education-with-interaction",
    "href": "slides/02-big-picture.html#life_exp-vs.-income_inequality-education-with-interaction",
    "title": "The big picture",
    "section": "life_exp vs. income_inequality + education (with interaction)",
    "text": "life_exp vs. income_inequality + education (with interaction)\n\n\\[{\\small \\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality} + \\hat{\\beta}_2 ~\\text{education} + \\hat{\\beta}_3 ~ \\text{income_inequality} \\times \\text{education}}\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#why-fit-a-model",
    "href": "slides/02-big-picture.html#why-fit-a-model",
    "title": "The big picture",
    "section": "Why fit a model?",
    "text": "Why fit a model?\n\nPrediction: Expected value of the response variable for given values of the predictor variables\nInference: Conclusion about the relationship between the response and predictor variables\n\n\n\n\nWhat is an example of a prediction question that can be answered using the model of life_exp vs. income_inequality and education?\nWhat is an example of an inference question that can be answered using the model of life_exp vs.income_inequality and education?"
  },
  {
    "objectID": "slides/02-big-picture.html#recap",
    "href": "slides/02-big-picture.html#recap",
    "title": "The big picture",
    "section": "Recap",
    "text": "Recap\n\nReproducibility\n\nIt is best practice conduct all data analysis in a reproducible way\nWe will implement a reproducible workflow using R, Quarto, and git/GitHub\n\nMultivariable relationships\n\nWe can use exploratory data analysis to describe the relationship between two variables\nWe make an assumption about the relationship between variables when doing linear regression\nThe two main objectives for fitting a linear regression model are (1) prediction and (2) inference"
  },
  {
    "objectID": "slides/02-big-picture.html#for-next-time",
    "href": "slides/02-big-picture.html#for-next-time",
    "title": "The big picture",
    "section": "For next time",
    "text": "For next time\n\nComplete Lecture 03 prepare\nBring fully-charged laptop or device to access RStudio for in-class exercise"
  },
  {
    "objectID": "slides/02-big-picture.html#references",
    "href": "slides/02-big-picture.html#references",
    "title": "The big picture",
    "section": "References",
    "text": "References\n\n\n\n\nAlexander, Rohan. 2023. “Telling Stories with Data,” June. https://doi.org/10.1201/9781003229407.\n\n\nOstblom, Joel, and Tiffany Timbers. 2022. “Opinionated Practices for Teaching Reproducibility: Motivation, Guided Instruction and Practice.” Journal of Statistics and Data Science Education 30 (3): 241–50. https://doi.org/10.1080/26939169.2022.2074922.\n\n\nZarulli, Virginia, Elizaveta Sopina, Veronica Toffolutti, and Adam Lenart. 2021. “Health Care System Efficiency and Life Expectancy: A 140-Country Study.” Edited by Srinivas Goli. PLOS ONE 16 (7): e0253450. https://doi.org/10.1371/journal.pone.0253450."
  },
  {
    "objectID": "slides/02-big-picture-notes.html",
    "href": "slides/02-big-picture-notes.html",
    "title": "The big picture",
    "section": "",
    "text": "Office hours start this week\n\nSee office hours schedule on Canvas\n\nComplete Lab 00 tasks\nIntroduction to R workshops at Duke library\n\nSee Monday’s Canvas announcement\n\nTriangle"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#announcements",
    "href": "slides/02-big-picture-notes.html#announcements",
    "title": "The big picture",
    "section": "",
    "text": "Office hours start this week\n\nSee office hours schedule on Canvas\n\nComplete Lab 00 tasks\nIntroduction to R workshops at Duke library\n\nSee Monday’s Canvas announcement\n\nTriangle"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#topics",
    "href": "slides/02-big-picture-notes.html#topics",
    "title": "The big picture",
    "section": "Topics",
    "text": "Topics\n\nData science workflow\nReproducible data analysis\nAnalyzing multivariable relationships"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#data-science-workflow",
    "href": "slides/02-big-picture-notes.html#data-science-workflow",
    "title": "The big picture",
    "section": "Data science workflow",
    "text": "Data science workflow\n\n\n\nSource: Introduction to Regression Analysis: A Data Science Approach"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#reproducibility-checklist",
    "href": "slides/02-big-picture-notes.html#reproducibility-checklist",
    "title": "The big picture",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for an analysis to be reproducible?\n\n. . .\nNear term goals:\n✔️ Can the tables and figures be exactly reproduced from the code and data?\n✔️ Does the code actually do what you think it does?\n✔️ In addition to what was done, is it clear why it was done?\n. . .\nLong term goals:\n✔️ Can the code be used for other data?\n✔️ Can you extend the code to do other things?"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#why-is-reproducibility-important",
    "href": "slides/02-big-picture-notes.html#why-is-reproducibility-important",
    "title": "The big picture",
    "section": "Why is reproducibility important?",
    "text": "Why is reproducibility important?\n\nResults produced are more reliable and trustworthy (Ostblom and Timbers 2022)\nFacilitates more effective collaboration (Ostblom and Timbers 2022)\nContributing to science, which builds and organizes knowledge in terms of testable hypotheses (Alexander 2023)\nPossible to identify and correct errors or biases in the analysis process (Alexander 2023)"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#toolkit",
    "href": "slides/02-big-picture-notes.html#toolkit",
    "title": "The big picture",
    "section": "Toolkit",
    "text": "Toolkit\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#r-and-rstudio",
    "href": "slides/02-big-picture-notes.html#r-and-rstudio",
    "title": "The big picture",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nR is a statistical programming language\nRStudio is a convenient interface for R (an integrated development environment, IDE)\n\n\n\n\nSource: Statistical Inference via Data Science"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#rstudio-ide",
    "href": "slides/02-big-picture-notes.html#rstudio-ide",
    "title": "The big picture",
    "section": "RStudio IDE",
    "text": "RStudio IDE"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#quarto",
    "href": "slides/02-big-picture-notes.html#quarto",
    "title": "The big picture",
    "section": "Quarto",
    "text": "Quarto\n\nFully reproducible reports – the analysis is run from the beginning each time you render\nCode goes in chunks and narrative goes outside of chunks\nVisual editor to make document editing experience similar to a word processor (Google docs, Word, Pages, etc.)"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#quarto-1",
    "href": "slides/02-big-picture-notes.html#quarto-1",
    "title": "The big picture",
    "section": "Quarto",
    "text": "Quarto"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#how-will-we-use-quarto",
    "href": "slides/02-big-picture-notes.html#how-will-we-use-quarto",
    "title": "The big picture",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise and assignment is written in a Quarto document\nYou’ll have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#what-is-versioning",
    "href": "slides/02-big-picture-notes.html#what-is-versioning",
    "title": "The big picture",
    "section": "What is versioning?",
    "text": "What is versioning?"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#what-is-versioning-1",
    "href": "slides/02-big-picture-notes.html#what-is-versioning-1",
    "title": "The big picture",
    "section": "What is versioning?",
    "text": "What is versioning?\nwith human readable messages"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#why-do-we-need-version-control",
    "href": "slides/02-big-picture-notes.html#why-do-we-need-version-control",
    "title": "The big picture",
    "section": "Why do we need version control?",
    "text": "Why do we need version control?\n\n\n\n\n\n\n\n\nProvides a clear record of how the analysis methods evolved. This makes analysis auditable and thus more trustworthy and reliable. (Ostblom and Timbers 2022)"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#git-and-github",
    "href": "slides/02-big-picture-notes.html#git-and-github",
    "title": "The big picture",
    "section": "git and GitHub",
    "text": "git and GitHub\n\n\n\n\n\n\ngit is a version control system – like “Track Changes” features from Microsoft Word.\nGitHub is the home for your git-based projects on the internet (like DropBox but much better).\nThere are a lot of git commands and very few people know them all. 99% of the time you will use git to add, commit, push, and pull."
  },
  {
    "objectID": "slides/02-big-picture-notes.html#factors-associated-with-life-expectancy",
    "href": "slides/02-big-picture-notes.html#factors-associated-with-life-expectancy",
    "title": "The big picture",
    "section": "Factors associated with life expectancy",
    "text": "Factors associated with life expectancy\nThe data set comes from Zarulli et al. (2021) who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThe data are available in life-expectancy-data.csv. There are 140 countries (observations) in the data set.\n\n\nClick here for the original research paper."
  },
  {
    "objectID": "slides/02-big-picture-notes.html#variable-definitions",
    "href": "slides/02-big-picture-notes.html#variable-definitions",
    "title": "The big picture",
    "section": "Variable definitions",
    "text": "Variable definitions\n\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic area. ( from the World Health Organization)\nincome_inequality: Measure of the deviation of the distribution of income among individuals or households within a country from a perfectly equal distribution. A value of 0 represents absolute equality, a value of 100 absolute inequality (Gini coefficient)."
  },
  {
    "objectID": "slides/02-big-picture-notes.html#variable-definitions-1",
    "href": "slides/02-big-picture-notes.html#variable-definitions-1",
    "title": "The big picture",
    "section": "Variable definitions",
    "text": "Variable definitions\n\neducation: Indicator of whether a country’s education index is above (High) or below (Low) the median index for the 140 countries in the data set.\n\nEducation index: Average of mean years of schooling (of adults) and expected years of school (of children), both expressed as an index obtained by scaling wit the corresponding maxima."
  },
  {
    "objectID": "slides/02-big-picture-notes.html#terminology",
    "href": "slides/02-big-picture-notes.html#terminology",
    "title": "The big picture",
    "section": "Terminology",
    "text": "Terminology\n\nlife_exp is the response variable\n\nvariable whose variation we want to understand / variable we wish to predict\nalso known as outcome or dependent variable\n\n\n. . .\n\nincome_inequality, education are the predictor variables\n\nvariables used to account for variation in the response\nalso known as explanatory, independent, or input variables"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#univariate-exploratory-data-analysis",
    "href": "slides/02-big-picture-notes.html#univariate-exploratory-data-analysis",
    "title": "The big picture",
    "section": "Univariate exploratory data analysis",
    "text": "Univariate exploratory data analysis"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#bivariate-exploratory-data-analysis",
    "href": "slides/02-big-picture-notes.html#bivariate-exploratory-data-analysis",
    "title": "The big picture",
    "section": "Bivariate exploratory data analysis",
    "text": "Bivariate exploratory data analysis"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#function-between-response-and-predictors",
    "href": "slides/02-big-picture-notes.html#function-between-response-and-predictors",
    "title": "The big picture",
    "section": "Function between response and predictors",
    "text": "Function between response and predictors\n\n\\[\\text{life_exp} = f(\\text{income_inequality}, \\text{education}) + \\epsilon\\]\n\n\nGoal: Determine \\(f\\)\nHow do we determine \\(f\\)?\n\nMake an assumption about the functional form \\(f\\) (parametric model)\nUse the data to fit a model based on that form"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#determine-f",
    "href": "slides/02-big-picture-notes.html#determine-f",
    "title": "The big picture",
    "section": "Determine \\(f\\)",
    "text": "Determine \\(f\\)\n\nChoose the functional form of \\(f\\), i.e., choose the appropriate model given the response variable\n\n\nSuppose \\(f\\) takes the form of a linear model\n\\[Y = f(\\mathbf{X}) = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_p X_p + \\epsilon\\]\n\n. . .\n\nUse the data to fit (or train) the model, i.e, compute estimates of the model parameters, denoted \\(\\hat{\\beta}_0, \\hat{\\beta}_1, \\ldots, \\hat{\\beta}_p\\)"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#life_exp-vs.-income_inequality",
    "href": "slides/02-big-picture-notes.html#life_exp-vs.-income_inequality",
    "title": "The big picture",
    "section": "life_exp vs. income_inequality",
    "text": "life_exp vs. income_inequality\n\n\n\n\n\n\n\n\n\n\\[\\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality}\\]"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#life_exp-vs.-income_inequality-education",
    "href": "slides/02-big-picture-notes.html#life_exp-vs.-income_inequality-education",
    "title": "The big picture",
    "section": "life_exp vs. income_inequality + education",
    "text": "life_exp vs. income_inequality + education\n\n\n\n\n\n\n\n\n\n\\[\\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality} + \\hat{\\beta}_2 ~\\text{education}\\]"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#statistical-model-vs.-regression-equation",
    "href": "slides/02-big-picture-notes.html#statistical-model-vs.-regression-equation",
    "title": "The big picture",
    "section": "Statistical model vs. regression equation",
    "text": "Statistical model vs. regression equation\nStatistical model (also known as the data-generating model)\n\n\\[{\\small \\text{life_exp} = \\beta_0 + \\beta_1 ~\\text{income_inequality} + \\beta_2 ~\\text{education} + \\epsilon}\\]\n\nModels the process for generating values of the response in the population (function + error), i.e., the population-level model.\n\n. . .\nRegression equation (also known as the fitted model)\nEstimate of the function using the sample data\n\n\\[{\\small \\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality} + \\hat{\\beta}_2 ~\\text{education}}\\]"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#life_exp-vs.-income_inequality-education-with-interaction",
    "href": "slides/02-big-picture-notes.html#life_exp-vs.-income_inequality-education-with-interaction",
    "title": "The big picture",
    "section": "life_exp vs. income_inequality + education (with interaction)",
    "text": "life_exp vs. income_inequality + education (with interaction)\n\n\n\n\n\n\n\n\n\n\\[{\\small \\widehat{\\text{life_exp}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{income_inequality} + \\hat{\\beta}_2 ~\\text{education} + \\hat{\\beta}_3 ~ \\text{income_inequality} \\times \\text{education}}\\]"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#why-fit-a-model",
    "href": "slides/02-big-picture-notes.html#why-fit-a-model",
    "title": "The big picture",
    "section": "Why fit a model?",
    "text": "Why fit a model?\n\nPrediction: Expected value of the response variable for given values of the predictor variables\nInference: Conclusion about the relationship between the response and predictor variables\n\n. . .\n\n\nWhat is an example of a prediction question that can be answered using the model of life_exp vs. income_inequality and education?\nWhat is an example of an inference question that can be answered using the model of life_exp vs.income_inequality and education?"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#recap",
    "href": "slides/02-big-picture-notes.html#recap",
    "title": "The big picture",
    "section": "Recap",
    "text": "Recap\n\nReproducibility\n\nIt is best practice conduct all data analysis in a reproducible way\nWe will implement a reproducible workflow using R, Quarto, and git/GitHub\n\nMultivariable relationships\n\nWe can use exploratory data analysis to describe the relationship between two variables\nWe make an assumption about the relationship between variables when doing linear regression\nThe two main objectives for fitting a linear regression model are (1) prediction and (2) inference"
  },
  {
    "objectID": "slides/02-big-picture-notes.html#for-next-time",
    "href": "slides/02-big-picture-notes.html#for-next-time",
    "title": "The big picture",
    "section": "For next time",
    "text": "For next time\n\nComplete Lecture 03 prepare\nBring fully-charged laptop or device to access RStudio for in-class exercise"
  },
  {
    "objectID": "slides/03-slr-intro.html#announcements",
    "href": "slides/03-slr-intro.html#announcements",
    "title": "Simple Linear Regression",
    "section": "Announcements",
    "text": "Announcements\n\nNo lab Monday, January 20 - Martin Luther King Jr. Holiday\nNo final exam in this class\n\nNo in-person activities after LDOC"
  },
  {
    "objectID": "slides/03-slr-intro.html#topics",
    "href": "slides/03-slr-intro.html#topics",
    "title": "Simple Linear Regression",
    "section": "Topics",
    "text": "Topics\n\n\nUse simple linear regression to describe the relationship between a quantitative predictor and quantitative response variable.\nEstimate the slope and intercept of the regression line using the least squares method.\nInterpret the slope and intercept of the regression line.\nPredict the response given a value of the predictor variable.\nFit linear regression models in R"
  },
  {
    "objectID": "slides/03-slr-intro.html#computation-set-up",
    "href": "slides/03-slr-intro.html#computation-set-up",
    "title": "Simple Linear Regression",
    "section": "Computation set up",
    "text": "Computation set up\n\n# load packages\nlibrary(tidyverse)       # for data wrangling\nlibrary(tidymodels)      # for modeling\nlibrary(knitr)          # for formatting tables\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/03-slr-intro.html#movie-scores",
    "href": "slides/03-slr-intro.html#movie-scores",
    "title": "Simple Linear Regression",
    "section": "Movie scores",
    "text": "Movie scores\n\n\n\nData behind the FiveThirtyEight story Be Suspicious Of Online Movie Ratings, Especially Fandango’s\nData originally from the fandango data frame in fivethirtyeight package. Available in movie-scores.csv\nContains every film released in 2014 and 2015 that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores"
  },
  {
    "objectID": "slides/03-slr-intro.html#data-overview",
    "href": "slides/03-slr-intro.html#data-overview",
    "title": "Simple Linear Regression",
    "section": "Data overview",
    "text": "Data overview\n\nmovie_scores &lt;- read_csv(\"https://intro-regression.github.io/data/movie-scores.csv\")\n\nglimpse(movie_scores)\n\nRows: 146\nColumns: 4\n$ film           &lt;chr&gt; \"Avengers: Age of Ultron\", \"Cinderella\", \"Ant-Man\", \"Do…\n$ year           &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2014, 2015, 2…\n$ critics_score  &lt;dbl&gt; 74, 85, 80, 18, 14, 63, 42, 86, 99, 89, 84, 82, 99, 51,…\n$ audience_score &lt;dbl&gt; 86, 80, 90, 84, 28, 62, 53, 64, 82, 87, 77, 60, 79, 70,…"
  },
  {
    "objectID": "slides/03-slr-intro.html#movie-scores-data",
    "href": "slides/03-slr-intro.html#movie-scores-data",
    "title": "Simple Linear Regression",
    "section": "Movie scores data",
    "text": "Movie scores data\nThe data set contains the “Tomatometer” score (critics_score) and audience score (audience_score) for 146 movies rated on rottentomatoes.com."
  },
  {
    "objectID": "slides/03-slr-intro.html#movie-ratings-data",
    "href": "slides/03-slr-intro.html#movie-ratings-data",
    "title": "Simple Linear Regression",
    "section": "Movie ratings data",
    "text": "Movie ratings data\nGoal: Fit a line to describe the relationship between the critics score and audience score."
  },
  {
    "objectID": "slides/03-slr-intro.html#why-fit-a-line",
    "href": "slides/03-slr-intro.html#why-fit-a-line",
    "title": "Simple Linear Regression",
    "section": "Why fit a line?",
    "text": "Why fit a line?\nWe fit a line to accomplish one or both of the following:\n\n\nPrediction\n\nWhat is the audience score expected to be for an upcoming movie that received 35% from the critics?\n\n\n\n\nInference\n\nIs the critics score a useful predictor of the audience score? By how much is the audience score expected to change for each additional point in the critics score?"
  },
  {
    "objectID": "slides/03-slr-intro.html#terminology",
    "href": "slides/03-slr-intro.html#terminology",
    "title": "Simple Linear Regression",
    "section": "Terminology",
    "text": "Terminology\n\n\n\nResponse, Y: variable describing the outcome of interest\nPredictor, X: variable we use to help understand the variability in the response"
  },
  {
    "objectID": "slides/03-slr-intro.html#regression-model",
    "href": "slides/03-slr-intro.html#regression-model",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the response, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\mathbf{E(Y|X)}} + \\epsilon\\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-slr-intro.html#regression-model-1",
    "href": "slides/03-slr-intro.html#regression-model-1",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\\begin{aligned} Y &= {\\color{purple} \\textbf{Model}} + \\textbf{Error} \\\\[8pt]\n&= {\\color{purple} \\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= {\\color{purple} \\mathbf{E(Y|X)}} + \\epsilon \\\\ \\end{aligned}\\]\n\n\n\n\n\n\n\n\n\n\n\n\\(E(Y|X) = \\mu_{Y|X}\\) is the mean value of \\(Y\\) given a particular value of \\(X\\)."
  },
  {
    "objectID": "slides/03-slr-intro.html#regression-model-2",
    "href": "slides/03-slr-intro.html#regression-model-2",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{blue}{\\textbf{Error}} \\\\[8pt]\n&= \\color{purple}{\\mathbf{f(X)}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[8pt]\n&= \\color{purple}{\\mathbf{E(Y|X)}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/03-slr-intro.html#slr-statistical-model-theoretical",
    "href": "slides/03-slr-intro.html#slr-statistical-model-theoretical",
    "title": "Simple Linear Regression",
    "section": "SLR: Statistical model (Theoretical)",
    "text": "SLR: Statistical model (Theoretical)\nWhen we have a quantitative response, \\(Y\\), and a single quantitative predictor, \\(X\\), we can use a simple linear regression model to describe the relationship between \\(Y\\) and \\(X\\).\n\n\\[y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\\]\n\n\n\n\\(\\beta_1\\): True slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): True intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon_i\\): Error for the \\(i^{th}\\) observation"
  },
  {
    "objectID": "slides/03-slr-intro.html#slr-regression-equation-fitted",
    "href": "slides/03-slr-intro.html#slr-regression-equation-fitted",
    "title": "Simple Linear Regression",
    "section": "SLR: Regression equation (Fitted)",
    "text": "SLR: Regression equation (Fitted)\n\n\\[\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i\n\\]\n\n\n\\(\\hat{\\beta}_1\\): Estimated slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\hat{\\beta}_0\\): Estimated intercept of the relationship between \\(X\\) and \\(Y\\)\nNo error term!\n\n\n\nWhy is there no error term in the estimated regression equation?"
  },
  {
    "objectID": "slides/03-slr-intro.html#computing-estimates-hatbeta_1-and-hatbeta_0",
    "href": "slides/03-slr-intro.html#computing-estimates-hatbeta_1-and-hatbeta_0",
    "title": "Simple Linear Regression",
    "section": "Computing estimates \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)",
    "text": "Computing estimates \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)"
  },
  {
    "objectID": "slides/03-slr-intro.html#residuals",
    "href": "slides/03-slr-intro.html#residuals",
    "title": "Simple Linear Regression",
    "section": "Residuals",
    "text": "Residuals\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]"
  },
  {
    "objectID": "slides/03-slr-intro.html#least-squares-line",
    "href": "slides/03-slr-intro.html#least-squares-line",
    "title": "Simple Linear Regression",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted}\n= y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe Ordinary Least Squares (OLS) line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/03-slr-intro.html#least-squares-estimator-of-hatbeta_0",
    "href": "slides/03-slr-intro.html#least-squares-estimator-of-hatbeta_0",
    "title": "Simple Linear Regression",
    "section": "Least-squares estimator of \\(\\hat{\\beta}_0\\)",
    "text": "Least-squares estimator of \\(\\hat{\\beta}_0\\)\n\n\n\nClick here for full details on finding \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) in simple linear regression."
  },
  {
    "objectID": "slides/03-slr-intro.html#properties-of-least-squares-regression",
    "href": "slides/03-slr-intro.html#properties-of-least-squares-regression",
    "title": "Simple Linear Regression",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\nThe regression line goes through the center of mass point, the coordinates corresponding to average \\(X\\) and average \\(Y\\): \\(\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1\\bar{x}\\)\nThe slope has the same sign as the correlation coefficient: \\(\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}\\)\nThe sum of the residuals is approximately zero: \\(\\sum_{i = 1}^n e_i \\approx 0\\)\nThe residuals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/03-slr-intro.html#estimating-the-slope",
    "href": "slides/03-slr-intro.html#estimating-the-slope",
    "title": "Simple Linear Regression",
    "section": "Estimating the slope",
    "text": "Estimating the slope\n\\[\\large{\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}}\\]\n\n\n\\[\\begin{aligned}\ns_X &= 30.1688 \\\\\ns_Y &=  20.0244 \\\\\nr &= 0.7814\n\\end{aligned}\\]\n\n\\[\\begin{aligned}\n\\hat{\\beta}_1 &= 0.7814 \\times \\frac{20.0244}{30.1688} \\\\\n&= 0.5187\\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-slr-intro.html#estimating-the-intercept",
    "href": "slides/03-slr-intro.html#estimating-the-intercept",
    "title": "Simple Linear Regression",
    "section": "Estimating the intercept",
    "text": "Estimating the intercept\n\\[\\large{\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1\\bar{x}}\\]\n\n\n\\[\\begin{aligned}\n&\\bar{x} = 60.8493 \\\\\n&\\bar{y} = 63.8767 \\\\\n&\\hat{\\beta}_1 = 0.5187\n\\end{aligned}\\]\n\n\\[\\begin{aligned}\\hat{\\beta}_0 &= 63.8767 - 0.5187 \\times 60.8493 \\\\\n&= 32.3142\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-slr-intro.html#interpretation",
    "href": "slides/03-slr-intro.html#interpretation",
    "title": "Simple Linear Regression",
    "section": "Interpretation",
    "text": "Interpretation\n\\[\n\\widehat{\\text{audience}} = 32.3142 + 0.5187 \\times \\text{critics}\n\\]\n\nQuestionSubmit\n\n\n\n\nSubmit your responses to the following:\n\nThe slope of the model for predicting audience score from critics score is 0.5187 . Which of the following is the best interpretation of this value?\n32.3142 is the predicted mean audience score for what type of movies?\n\n\n\n\n\n \n\n\n\n🔗 https://forms.office.com/r/NYMZZguyqP"
  },
  {
    "objectID": "slides/03-slr-intro.html#does-it-make-sense-to-interpret-the-intercept",
    "href": "slides/03-slr-intro.html#does-it-make-sense-to-interpret-the-intercept",
    "title": "Simple Linear Regression",
    "section": "Does it make sense to interpret the intercept?",
    "text": "Does it make sense to interpret the intercept?\n\n✅ The intercept is meaningful in the context of the data if\n\nthe predictor can feasibly take values equal to or near zero, or\nthere are values near zero in the observed data.\n\n\n\n🛑 Otherwise, the intercept may not be meaningful!"
  },
  {
    "objectID": "slides/03-slr-intro.html#making-a-prediction",
    "href": "slides/03-slr-intro.html#making-a-prediction",
    "title": "Simple Linear Regression",
    "section": "Making a prediction",
    "text": "Making a prediction\nSuppose that a movie has a critics score of 70. According to this model, what is the movie’s predicted audience score?\n\\[\\begin{aligned}\n\\widehat{\\text{audience_score}} &= 32.3142 + 0.5187 \\times \\text{critics_score} \\\\\n&= 32.3142 + 0.5187 \\times 70 \\\\\n&= 68.6232\n\\end{aligned}\\]\n\n\n\n\n\n\n\n\nCaution\n\n\nUsing the model to predict for values outside the range of the original data is extrapolation. Why do we want to avoid extrapolation?"
  },
  {
    "objectID": "slides/03-slr-intro.html#fit-the-model",
    "href": "slides/03-slr-intro.html#fit-the-model",
    "title": "Simple Linear Regression",
    "section": "Fit the model",
    "text": "Fit the model\nUse the lm() function to fit a linear regression model\n\n\nmovie_fit &lt;- lm(audience_score ~ critics_score, data = movie_scores)\nmovie_fit\n\n\nCall:\nlm(formula = audience_score ~ critics_score, data = movie_scores)\n\nCoefficients:\n  (Intercept)  critics_score  \n      32.3155         0.5187"
  },
  {
    "objectID": "slides/03-slr-intro.html#tidy-results",
    "href": "slides/03-slr-intro.html#tidy-results",
    "title": "Simple Linear Regression",
    "section": "Tidy results",
    "text": "Tidy results\nUse the tidy() function from the broom R package to “tidy” the model output\n\n\nmovie_fit &lt;- lm(audience_score ~ critics_score, data = movie_scores)\ntidy(movie_fit)\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     32.3      2.34        13.8 4.03e-28\n2 critics_score    0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/03-slr-intro.html#format-results",
    "href": "slides/03-slr-intro.html#format-results",
    "title": "Simple Linear Regression",
    "section": "Format results",
    "text": "Format results\nUse the kable() function from the knitr package to neatly format the results\n\n\n\nmovie_fit &lt;- lm(audience_score ~ critics_score, data = movie_scores)\ntidy(movie_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n32.316\n2.343\n13.795\n0\n\n\ncritics_score\n0.519\n0.035\n15.028\n0"
  },
  {
    "objectID": "slides/03-slr-intro.html#prediction-1",
    "href": "slides/03-slr-intro.html#prediction-1",
    "title": "Simple Linear Regression",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nSingle observation\n\nnew_movie &lt;- tibble(critics_score = 70)\npredict(movie_fit, new_movie)\n\n       1 \n68.62297"
  },
  {
    "objectID": "slides/03-slr-intro.html#prediction-2",
    "href": "slides/03-slr-intro.html#prediction-2",
    "title": "Simple Linear Regression",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nMultiple observations\n\nmore_new_movies &lt;- tibble(critics_score = c(24,70, 85))\npredict(movie_fit, more_new_movies)\n\n       1        2        3 \n44.76379 68.62297 76.40313"
  },
  {
    "objectID": "slides/03-slr-intro.html#recap",
    "href": "slides/03-slr-intro.html#recap",
    "title": "Simple Linear Regression",
    "section": "Recap",
    "text": "Recap\n\n\nUsed simple linear regression to describe the relationship between a quantitative predictor and quantitative response variable.\nUsed the least squares method to estimate the slope and intercept.\nInterpreted the slope and intercept.\nPredicted the response given a value of the predictor variable.\nUsed R to fit the regression line and calculate predictions"
  },
  {
    "objectID": "slides/03-slr-intro.html#next-class",
    "href": "slides/03-slr-intro.html#next-class",
    "title": "Simple Linear Regression",
    "section": "Next Class",
    "text": "Next Class\n\nInference: Bootstrap confidence intervals\n\n\n\nComplete Lecture 04 Prepare"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html",
    "href": "slides/03-slr-intro-notes.html",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "No lab Monday, January 20 - Martin Luther King Jr. Holiday\nNo final exam in this class\n\nNo in-person activities after LDOC"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#announcements",
    "href": "slides/03-slr-intro-notes.html#announcements",
    "title": "Simple Linear Regression",
    "section": "",
    "text": "No lab Monday, January 20 - Martin Luther King Jr. Holiday\nNo final exam in this class\n\nNo in-person activities after LDOC"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#topics",
    "href": "slides/03-slr-intro-notes.html#topics",
    "title": "Simple Linear Regression",
    "section": "Topics",
    "text": "Topics\n\n\nUse simple linear regression to describe the relationship between a quantitative predictor and quantitative response variable.\nEstimate the slope and intercept of the regression line using the least squares method.\nInterpret the slope and intercept of the regression line.\nPredict the response given a value of the predictor variable.\nFit linear regression models in R"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#computation-set-up",
    "href": "slides/03-slr-intro-notes.html#computation-set-up",
    "title": "Simple Linear Regression",
    "section": "Computation set up",
    "text": "Computation set up\n\n# load packages\nlibrary(tidyverse)       # for data wrangling\nlibrary(tidymodels)      # for modeling\nlibrary(knitr)          # for formatting tables\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#movie-scores",
    "href": "slides/03-slr-intro-notes.html#movie-scores",
    "title": "Simple Linear Regression",
    "section": "Movie scores",
    "text": "Movie scores\n\n\n\nData behind the FiveThirtyEight story Be Suspicious Of Online Movie Ratings, Especially Fandango’s\nData originally from the fandango data frame in fivethirtyeight package. Available in movie-scores.csv\nContains every film released in 2014 and 2015 that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#data-overview",
    "href": "slides/03-slr-intro-notes.html#data-overview",
    "title": "Simple Linear Regression",
    "section": "Data overview",
    "text": "Data overview\n\nmovie_scores &lt;- read_csv(\"https://intro-regression.github.io/data/movie-scores.csv\")\n\nglimpse(movie_scores)\n\nRows: 146\nColumns: 4\n$ film           &lt;chr&gt; \"Avengers: Age of Ultron\", \"Cinderella\", \"Ant-Man\", \"Do…\n$ year           &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2014, 2015, 2…\n$ critics_score  &lt;dbl&gt; 74, 85, 80, 18, 14, 63, 42, 86, 99, 89, 84, 82, 99, 51,…\n$ audience_score &lt;dbl&gt; 86, 80, 90, 84, 28, 62, 53, 64, 82, 87, 77, 60, 79, 70,…"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#movie-scores-data",
    "href": "slides/03-slr-intro-notes.html#movie-scores-data",
    "title": "Simple Linear Regression",
    "section": "Movie scores data",
    "text": "Movie scores data\nThe data set contains the “Tomatometer” score (critics_score) and audience score (audience_score) for 146 movies rated on rottentomatoes.com."
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#movie-ratings-data",
    "href": "slides/03-slr-intro-notes.html#movie-ratings-data",
    "title": "Simple Linear Regression",
    "section": "Movie ratings data",
    "text": "Movie ratings data\nGoal: Fit a line to describe the relationship between the critics score and audience score."
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#why-fit-a-line",
    "href": "slides/03-slr-intro-notes.html#why-fit-a-line",
    "title": "Simple Linear Regression",
    "section": "Why fit a line?",
    "text": "Why fit a line?\nWe fit a line to accomplish one or both of the following:\n. . .\n\nPrediction\n\nWhat is the audience score expected to be for an upcoming movie that received 35% from the critics?\n\n. . .\n\nInference\n\nIs the critics score a useful predictor of the audience score? By how much is the audience score expected to change for each additional point in the critics score?"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#terminology",
    "href": "slides/03-slr-intro-notes.html#terminology",
    "title": "Simple Linear Regression",
    "section": "Terminology",
    "text": "Terminology\n\n\n\nResponse, Y: variable describing the outcome of interest\nPredictor, X: variable we use to help understand the variability in the response"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#regression-model",
    "href": "slides/03-slr-intro-notes.html#regression-model",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the response, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\mathbf{E(Y|X)}} + \\epsilon\\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#regression-model-1",
    "href": "slides/03-slr-intro-notes.html#regression-model-1",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\\begin{aligned} Y &= {\\color{purple} \\textbf{Model}} + \\textbf{Error} \\\\[8pt]\n&= {\\color{purple} \\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= {\\color{purple} \\mathbf{E(Y|X)}} + \\epsilon \\\\ \\end{aligned}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\\(E(Y|X) = \\mu_{Y|X}\\) is the mean value of \\(Y\\) given a particular value of \\(X\\)."
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#regression-model-2",
    "href": "slides/03-slr-intro-notes.html#regression-model-2",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{blue}{\\textbf{Error}} \\\\[8pt]\n&= \\color{purple}{\\mathbf{f(X)}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[8pt]\n&= \\color{purple}{\\mathbf{E(Y|X)}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#slr-statistical-model-theoretical",
    "href": "slides/03-slr-intro-notes.html#slr-statistical-model-theoretical",
    "title": "Simple Linear Regression",
    "section": "SLR: Statistical model (Theoretical)",
    "text": "SLR: Statistical model (Theoretical)\nWhen we have a quantitative response, \\(Y\\), and a single quantitative predictor, \\(X\\), we can use a simple linear regression model to describe the relationship between \\(Y\\) and \\(X\\).\n\n\\[y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\\]\n\n. . .\n\n\\(\\beta_1\\): True slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): True intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon_i\\): Error for the \\(i^{th}\\) observation"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#slr-regression-equation-fitted",
    "href": "slides/03-slr-intro-notes.html#slr-regression-equation-fitted",
    "title": "Simple Linear Regression",
    "section": "SLR: Regression equation (Fitted)",
    "text": "SLR: Regression equation (Fitted)\n\n\\[\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i\n\\]\n\n\n\\(\\hat{\\beta}_1\\): Estimated slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\hat{\\beta}_0\\): Estimated intercept of the relationship between \\(X\\) and \\(Y\\)\nNo error term!\n\n. . .\n\nWhy is there no error term in the estimated regression equation?"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#computing-estimates-hatbeta_1-and-hatbeta_0",
    "href": "slides/03-slr-intro-notes.html#computing-estimates-hatbeta_1-and-hatbeta_0",
    "title": "Simple Linear Regression",
    "section": "Computing estimates \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)",
    "text": "Computing estimates \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#residuals",
    "href": "slides/03-slr-intro-notes.html#residuals",
    "title": "Simple Linear Regression",
    "section": "Residuals",
    "text": "Residuals\n\n\n\n\n\n\n\n\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#least-squares-line",
    "href": "slides/03-slr-intro-notes.html#least-squares-line",
    "title": "Simple Linear Regression",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted}\n= y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe Ordinary Least Squares (OLS) line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#least-squares-estimator-of-hatbeta_0",
    "href": "slides/03-slr-intro-notes.html#least-squares-estimator-of-hatbeta_0",
    "title": "Simple Linear Regression",
    "section": "Least-squares estimator of \\(\\hat{\\beta}_0\\)",
    "text": "Least-squares estimator of \\(\\hat{\\beta}_0\\)\n\n\n\nClick here for full details on finding \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) in simple linear regression."
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#properties-of-least-squares-regression",
    "href": "slides/03-slr-intro-notes.html#properties-of-least-squares-regression",
    "title": "Simple Linear Regression",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point, the coordinates corresponding to average \\(X\\) and average \\(Y\\): \\(\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1\\bar{x}\\)\nThe slope has the same sign as the correlation coefficient: \\(\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}\\)\nThe sum of the residuals is approximately zero: \\(\\sum_{i = 1}^n e_i \\approx 0\\)\nThe residuals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#estimating-the-slope",
    "href": "slides/03-slr-intro-notes.html#estimating-the-slope",
    "title": "Simple Linear Regression",
    "section": "Estimating the slope",
    "text": "Estimating the slope\n\\[\\large{\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}}\\]\n\n\n\\[\\begin{aligned}\ns_X &= 30.1688 \\\\\ns_Y &=  20.0244 \\\\\nr &= 0.7814\n\\end{aligned}\\]\n\n\\[\\begin{aligned}\n\\hat{\\beta}_1 &= 0.7814 \\times \\frac{20.0244}{30.1688} \\\\\n&= 0.5187\\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#estimating-the-intercept",
    "href": "slides/03-slr-intro-notes.html#estimating-the-intercept",
    "title": "Simple Linear Regression",
    "section": "Estimating the intercept",
    "text": "Estimating the intercept\n\\[\\large{\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1\\bar{x}}\\]\n\n\n\\[\\begin{aligned}\n&\\bar{x} = 60.8493 \\\\\n&\\bar{y} = 63.8767 \\\\\n&\\hat{\\beta}_1 = 0.5187\n\\end{aligned}\\]\n\n\\[\\begin{aligned}\\hat{\\beta}_0 &= 63.8767 - 0.5187 \\times 60.8493 \\\\\n&= 32.3142\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#interpretation",
    "href": "slides/03-slr-intro-notes.html#interpretation",
    "title": "Simple Linear Regression",
    "section": "Interpretation",
    "text": "Interpretation\n\\[\n\\widehat{\\text{audience}} = 32.3142 + 0.5187 \\times \\text{critics}\n\\]\n\nQuestionSubmit\n\n\n\n\nSubmit your responses to the following:\n\nThe slope of the model for predicting audience score from critics score is 0.5187 . Which of the following is the best interpretation of this value?\n32.3142 is the predicted mean audience score for what type of movies?\n\n\n\n\n\n \n\n\n\n🔗 https://forms.office.com/r/NYMZZguyqP"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#does-it-make-sense-to-interpret-the-intercept",
    "href": "slides/03-slr-intro-notes.html#does-it-make-sense-to-interpret-the-intercept",
    "title": "Simple Linear Regression",
    "section": "Does it make sense to interpret the intercept?",
    "text": "Does it make sense to interpret the intercept?\n. . .\n✅ The intercept is meaningful in the context of the data if\n\nthe predictor can feasibly take values equal to or near zero, or\nthere are values near zero in the observed data.\n\n. . .\n🛑 Otherwise, the intercept may not be meaningful!"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#making-a-prediction",
    "href": "slides/03-slr-intro-notes.html#making-a-prediction",
    "title": "Simple Linear Regression",
    "section": "Making a prediction",
    "text": "Making a prediction\nSuppose that a movie has a critics score of 70. According to this model, what is the movie’s predicted audience score?\n\\[\\begin{aligned}\n\\widehat{\\text{audience_score}} &= 32.3142 + 0.5187 \\times \\text{critics_score} \\\\\n&= 32.3142 + 0.5187 \\times 70 \\\\\n&= 68.6232\n\\end{aligned}\\]\n\n. . .\n\n\n\n\n\n\nCaution\n\n\n\nUsing the model to predict for values outside the range of the original data is extrapolation. Why do we want to avoid extrapolation?"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#fit-the-model",
    "href": "slides/03-slr-intro-notes.html#fit-the-model",
    "title": "Simple Linear Regression",
    "section": "Fit the model",
    "text": "Fit the model\nUse the lm() function to fit a linear regression model\n\n\nmovie_fit &lt;- lm(audience_score ~ critics_score, data = movie_scores)\nmovie_fit\n\n\nCall:\nlm(formula = audience_score ~ critics_score, data = movie_scores)\n\nCoefficients:\n  (Intercept)  critics_score  \n      32.3155         0.5187"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#tidy-results",
    "href": "slides/03-slr-intro-notes.html#tidy-results",
    "title": "Simple Linear Regression",
    "section": "Tidy results",
    "text": "Tidy results\nUse the tidy() function from the broom R package to “tidy” the model output\n\n\nmovie_fit &lt;- lm(audience_score ~ critics_score, data = movie_scores)\ntidy(movie_fit)\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     32.3      2.34        13.8 4.03e-28\n2 critics_score    0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#format-results",
    "href": "slides/03-slr-intro-notes.html#format-results",
    "title": "Simple Linear Regression",
    "section": "Format results",
    "text": "Format results\nUse the kable() function from the knitr package to neatly format the results\n\n\n\nmovie_fit &lt;- lm(audience_score ~ critics_score, data = movie_scores)\ntidy(movie_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n32.316\n2.343\n13.795\n0\n\n\ncritics_score\n0.519\n0.035\n15.028\n0"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#prediction-1",
    "href": "slides/03-slr-intro-notes.html#prediction-1",
    "title": "Simple Linear Regression",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nSingle observation\n\nnew_movie &lt;- tibble(critics_score = 70)\npredict(movie_fit, new_movie)\n\n       1 \n68.62297"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#prediction-2",
    "href": "slides/03-slr-intro-notes.html#prediction-2",
    "title": "Simple Linear Regression",
    "section": "Prediction",
    "text": "Prediction\nUse the predict() function to calculate predictions for new observations\n\nMultiple observations\n\nmore_new_movies &lt;- tibble(critics_score = c(24,70, 85))\npredict(movie_fit, more_new_movies)\n\n       1        2        3 \n44.76379 68.62297 76.40313"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#recap",
    "href": "slides/03-slr-intro-notes.html#recap",
    "title": "Simple Linear Regression",
    "section": "Recap",
    "text": "Recap\n\n\nUsed simple linear regression to describe the relationship between a quantitative predictor and quantitative response variable.\nUsed the least squares method to estimate the slope and intercept.\nInterpreted the slope and intercept.\nPredicted the response given a value of the predictor variable.\nUsed R to fit the regression line and calculate predictions"
  },
  {
    "objectID": "slides/03-slr-intro-notes.html#next-class",
    "href": "slides/03-slr-intro-notes.html#next-class",
    "title": "Simple Linear Regression",
    "section": "Next Class",
    "text": "Next Class\n\nInference: Bootstrap confidence intervals\n\n\n\nComplete Lecture 04 Prepare"
  },
  {
    "objectID": "slides/lab-01.html#tips-for-working-on-lab",
    "href": "slides/lab-01.html#tips-for-working-on-lab",
    "title": "Lab 01",
    "section": "Tips for working on lab",
    "text": "Tips for working on lab\n\nYou do not have to finish the lab in class, they will always be due Thursday. One work strategy is to get through portions that you think will be most challenging (which initially might be the coding component) during lab when a TA can help you on the spot and leave the narrative writing until later.\nDo not pressure each other to finish early (particularly once you start working on teams); use the time wisely to really learn the material and produce a quality report."
  },
  {
    "objectID": "slides/lab-01.html#tips-axis-labels-and-titles",
    "href": "slides/lab-01.html#tips-axis-labels-and-titles",
    "title": "Lab 01",
    "section": "Tips: Axis labels and titles",
    "text": "Tips: Axis labels and titles\n\nBelow is a graph of association between flipper length in millimeters and body mass in grams of three species of penguins in Palmer Station, Antarctica. What are informative title and axis labels for this graph?"
  },
  {
    "objectID": "slides/lab-01.html#tips-code-style",
    "href": "slides/lab-01.html#tips-code-style",
    "title": "Lab 01",
    "section": "Tips: Code style",
    "text": "Tips: Code style\nWhich code chunk would you rather read?\n\n# code chunk 1\npenguins|&gt;filter(!is.na(flipper_length_mm))|&gt;group_by(species)|&gt;summarise(min=min(flipper_length_mm),mean=mean(flipper_length_mm),sd=sd(flipper_length_mm),max=max(flipper_length_mm),n=n())\n\n\n\n\n# code chunk 2\npenguins |&gt; \n  filter(!is.na(flipper_length_mm)) |&gt; \n  group_by(species) |&gt; \n  summarise(min = min(flipper_length_mm), \n            mean = mean(flipper_length_mm), \n            max = max(flipper_length_mm),\n            n = n())"
  },
  {
    "objectID": "slides/lab-01.html#tips-code-style-contd",
    "href": "slides/lab-01.html#tips-code-style-contd",
    "title": "Lab 01",
    "section": "Tips: Code style cont’d",
    "text": "Tips: Code style cont’d\nMake code easier to read and debug by\n\nPutting each element on a different line (start a new line after + and |&gt;)\nPutting spaces before and after operators (+, -, *, =, |&gt; )\nIn general, avoiding long lines of code, i.e. lines longer than 80 characters.\n\nSee the R for Data Science - Workflow: code style for more tips on code styling."
  },
  {
    "objectID": "slides/lab-01.html#when-youre-done-with-lab",
    "href": "slides/lab-01.html#when-youre-done-with-lab",
    "title": "Lab 01",
    "section": "When you’re done with lab",
    "text": "When you’re done with lab\n\nMake sure all your final changes have been pushed to your GitHub repo\nSubmit the PDF of your responses to Gradescope"
  },
  {
    "objectID": "slides/lab-01.html#lab-01-linear-regression",
    "href": "slides/lab-01.html#lab-01-linear-regression",
    "title": "Lab 01",
    "section": "Lab 01: Linear regression",
    "text": "Lab 01: Linear regression\n\nToday’s lab focuses on using linear regression to explore the relationship between air temperature and ice duration for two lakes in Wisconsin, along with the change in ice duration over time.\nThere are markers throughout suggesting when to render, commit, and push changes to GitHub. These are to help you start using version control in your workflow.\nThere are points for having a neatly formatted document and implementing a reproducible workflow\n\n🔗 sta210-sp26.github.io/labs/lab-01.html"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 210 - Regression Analysis",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\nweek\ndow\ndate\ntopic\nprepare\nslides\nnotes\nae\nhw\nlab\nproject\ndue\n\n\n\n\n1\nTh\nJan 8\nWelcome to STA 210!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2\nM\nJan 12\nLab 00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nJan 13\nThe big picture\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nJan 15\nSimple linear regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\nM\nJan 19\nNo lab: Martin Luther King Jr. Day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nJan 20\nInference: Bootstrap confidence intervals\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nJan 22\nInference: Permutation tests\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\nM\nJan 26\nLab 01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nJan 27\nInference: Mathematical models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 01 due\n\n\n\nTh\nJan 29\nMultiple linear regression (MLR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 01 due\n\n\n5\nM\nFeb 2\nLab 02\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nFeb 3\nMLR: Types of predictors\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nFeb 5\nInference for MLR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 02 due\n\n\n6\nM\nFeb 9\nLab 03\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nFeb 10\nModel conditions + diagnostics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 02 due\n\n\n\nTh\nFeb 12\nExam 01 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 03 due\n\n\n7\nM\nFeb 16\nLab 04: Exam 01 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 04 due at end of lab\n\n\n\nTu\nFeb 17\nExam 01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nFeb 19\nVariable transformations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8\nM\nFeb 23\nLab: Project proposal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nFeb 24\nModel selection\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nFeb 26\nCross validation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9\nM\nMar 2\nLab 06\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nMar 3\nWrapping up MLR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 5\nEthics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 05 due\n\n\n10\nM\nMar 9\nNo Lab: Spring break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nMar 10\nNo Lecture: Spring Break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 12\nNo Lecture: Spring break\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11\nM\nMar 16\nLab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nMar 17\nLogistic regression (LR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 03 due\n\n\n\nTh\nMar 19\nLR: Prediction + Assessment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12\nM\nMar 23\nLab 06\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nMar 24\nLR: Inference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nMar 26\nLR: Model selection\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 06 due\n\n\n13\nM\nMar 30\nLab 07\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nMar 31\nSpecial topic/ Catch up\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 04 due\n\n\n\nTh\nApr 2\nExam 02 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 07 due\n\n\n14\nM\nApr 6\nLab 08: Exam 02 review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLab 08 due at end of lab\n\n\n\nTu\nApr 7\nExam 02\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nApr 9\nSpecial topic\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n15\nM\nApr 13\nProject work day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nApr 14\nProject presentations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\nApr 16\nProject presentations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n16\nM\nApr 20\nLab: Draft peer review\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTu\nApr 21\nProject meetings\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistics experience due\n\n\nExam period",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "computing-r-resources.html",
    "href": "computing-r-resources.html",
    "title": "Resources for learning R",
    "section": "",
    "text": "Below are freely available resources to learn or review the following in R: data wrangling, data visualization, Quarto basics.",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#in-depth-introduction",
    "href": "computing-r-resources.html#in-depth-introduction",
    "title": "Resources for learning R",
    "section": "In-depth introduction",
    "text": "In-depth introduction\nCoursera: Data Visualization and Transformation with R by Mine Çetinkaya-Rundel and Elijah Meyer\n\nIncludes videos, readings, practice exercise, quizzes, and other resources\nYou can select content within the modules you want to complete.\nFocus on Modules 2 and 3. Review the content in Module 1 as needed.s\nClick here for instructions to register for Coursera for free as a Duke student",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#in-depth-review",
    "href": "computing-r-resources.html#in-depth-review",
    "title": "Resources for learning R",
    "section": "In-depth review",
    "text": "In-depth review\nData Science with R videos by Mine Çetinkaya-Rundel and Elijah Meyer\n\nVideos from the data science Coursera course\nFocus on videos on visualizing and summarizing data\nYou need to join the Coursera course to access the files from the code along videos.\n\nLearn R: An interactive introduction to data analysis with R\n\nHands-on tutorial that can be completed within the site (no RStudio required)\nFocus on Chapters 4 - 6",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#shorter-review",
    "href": "computing-r-resources.html#shorter-review",
    "title": "Resources for learning R",
    "section": "Shorter review",
    "text": "Shorter review\nR for Data Science (2nd ed) by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund\n\nFocus on Chapters 1 - 3, 10",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "computing-r-resources.html#additional-resources",
    "href": "computing-r-resources.html#additional-resources",
    "title": "Resources for learning R",
    "section": "Additional resources",
    "text": "Additional resources\n\nTidy Modeling with R by Max Kuhn & Julia Silge\nPosit Cheatsheets\nR workshops by Duke Center for Data and Visualization Sciences",
    "crumbs": [
      "Computing",
      "R resources"
    ]
  },
  {
    "objectID": "ae/ae-01-movies.html",
    "href": "ae/ae-01-movies.html",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "",
    "text": "Important\n\n\n\nFor this AE, you will discuss the questions in groups and submit answers on Ed Discussion. This AE does not count towards the Application Exercise grade.\nWe will look at the relationship between budget and revenue for movies made in the United States in 1986 to 2020. The dataset is created based on data from the Internet Movie Database (IMDB).\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(viridis)\nlibrary(DT)"
  },
  {
    "objectID": "ae/ae-01-movies.html#data",
    "href": "ae/ae-01-movies.html#data",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Data",
    "text": "Data\nThe movies data set includes basic information about each movie including budget, genre, movie studio, director, etc. A full list of the variables may be found here.\n\nmovies &lt;- read_csv(\"https://raw.githubusercontent.com/danielgrijalva/movie-stats/master/movies.csv\")\n\nView the first 10 rows of data.\n\nmovies |&gt;\n  slice(1:10)\n\n# A tibble: 10 × 15\n   name   rating genre  year released score  votes director writer star  country\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;  \n 1 The S… R      Drama  1980 June 13…   8.4 9.27e5 Stanley… Steph… Jack… United…\n 2 The B… R      Adve…  1980 July 2,…   5.8 6.5 e4 Randal … Henry… Broo… United…\n 3 Star … PG     Acti…  1980 June 20…   8.7 1.20e6 Irvin K… Leigh… Mark… United…\n 4 Airpl… PG     Come…  1980 July 2,…   7.7 2.21e5 Jim Abr… Jim A… Robe… United…\n 5 Caddy… R      Come…  1980 July 25…   7.3 1.08e5 Harold … Brian… Chev… United…\n 6 Frida… R      Horr…  1980 May 9, …   6.4 1.23e5 Sean S.… Victo… Bets… United…\n 7 The B… R      Acti…  1980 June 20…   7.9 1.88e5 John La… Dan A… John… United…\n 8 Ragin… R      Biog…  1980 Decembe…   8.2 3.30e5 Martin … Jake … Robe… United…\n 9 Super… PG     Acti…  1980 June 19…   6.8 1.01e5 Richard… Jerry… Gene… United…\n10 The L… R      Biog…  1980 May 16,…   7   1   e4 Walter … Bill … Davi… United…\n# ℹ 4 more variables: budget &lt;dbl&gt;, gross &lt;dbl&gt;, company &lt;chr&gt;, runtime &lt;dbl&gt;"
  },
  {
    "objectID": "ae/ae-01-movies.html#analysis",
    "href": "ae/ae-01-movies.html#analysis",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Analysis",
    "text": "Analysis\nWe begin by looking at how the average gross revenue (gross) has changed over time. Since we want to visualize the results, we will choose a few genres of interest for the analysis.\n\ngenre_list &lt;- c(\"Comedy\", \"Action\", \"Animation\", \"Horror\")\n\n\nmovies |&gt;\n  filter(genre %in% genre_list) |&gt; \n  group_by(genre,year) |&gt;\n  summarise(avg_gross = mean(gross)) |&gt;\n  ggplot(mapping = aes(x = year, y = avg_gross, color=genre)) +\n    geom_point() + \n    geom_line() +\n    ylab(\"Average Gross Revenue (in US Dollars)\") +\n    ggtitle(\"Gross Revenue Over Time\") +\n    scale_color_viridis_d()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat do you observe from the plot?\n\n\n\nNext, let’s see the relationship between a movie’s budget and its gross revenue.\n\nmovies |&gt;\n  filter(genre %in% genre_list, budget &gt; 0) |&gt; \n  ggplot(mapping = aes(x=log(budget), y = log(gross), color=genre)) +\n  geom_point() +\n  geom_smooth(method=\"lm\",se=FALSE) + \n  xlab(\"Log-transformed Budget\")+\n  ylab(\"Log-transformed Gross Revenue\") +\n  facet_wrap(~ genre) + \n  scale_color_viridis_d()"
  },
  {
    "objectID": "ae/ae-01-movies.html#exercises",
    "href": "ae/ae-01-movies.html#exercises",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Exercises",
    "text": "Exercises\n\nSuppose we fit a regression model for each genre that uses budget to predict gross revenue. What are the signs of the correlation between budget and gross and the slope in each regression equation?\nSuppose we fit the regression model from the previous question. Which genre would you expect to have the smallest residuals, on average (residual = observed revenue - predicted revenue)?\nPost your response on ED Discussion.\nhttps://edstem.org/us/courses/70992/discussion/5951333\n[Time permitting] Discuss the following: Notice in the graph above that budget and gross are log-transformed. Why are the log-transformed values of the variables displayed rather than the original values (in U.S. dollars)? Post your group’s response in the AE 01 Movie Budgets comments on Ed Discussion."
  },
  {
    "objectID": "ae/ae-01-movies.html#references",
    "href": "ae/ae-01-movies.html#references",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "References",
    "text": "References\n\ngithub.com/danielgrijalva/movie-stats\nInternet Movie Database"
  },
  {
    "objectID": "ae/ae-01-movies.html#appendix",
    "href": "ae/ae-01-movies.html#appendix",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of genres in the data set:\n\nmovies |&gt; \n  arrange(genre) |&gt; \n  select(genre) |&gt;\n  distinct() |&gt;\n  datatable()"
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html",
    "href": "ae/ae-10-logistic-compare.html",
    "title": "AE 10: Comparing logistic regression models",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-10 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE."
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#packages",
    "href": "ae/ae-10-logistic-compare.html#packages",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#response-to-leukemia-treatment",
    "href": "ae/ae-10-logistic-compare.html#response-to-leukemia-treatment",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Response to Leukemia treatment",
    "text": "Response to Leukemia treatment\nToday’s data is from a study where 51 untreated adult patients with Acute Myeloid Leukemia who were given a course of treatment, and they were assessed as to their response to the treatment.1\nThe goal of today’s analysis is to use pre-treatment factors to predict how likely it is a patient will respond to the treatment.\nWe will use the following variables:\n\nAge: Age at diagnosis (in years)\nSmear: Differential percentage of blasts\nInfil: Percentage of absolute marrow leukemia infiltrate\nIndex: Percentage labeling index of the bone marrow leukemia cells\nBlasts: Absolute number of blasts, in thousands\nTemp: Highest temperature of the patient prior to treatment, in degrees Fahrenheit\nResp: 1 = responded to treatment or 0 = failed to respond\n\n\nleukemia &lt;- read_csv(\"data/leukemia.csv\") |&gt;\n  mutate(Resp = factor(Resp))"
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#comparing-models",
    "href": "ae/ae-10-logistic-compare.html#comparing-models",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Comparing models",
    "text": "Comparing models\n\nConsider a model with all the pre-treatment variables: Age, Smear, Infil, Index, Blasts and Temp. Fit a model using these six variables to predict whether a patient responded to the treatment. Call the model full_model. Display the model.\n\n\n# add code\n\n\nBased on the model, which pre-treatment variables are statistically significant using a threshold of \\(\\alpha = 0.05\\)? (We will talk more about inference for logistic regression coefficients in an upcoming lecture.)\nFit a model that only includes the statistically significant predictors. Call the model reduced_model.\n\n\n# add code\n\n\nUse a drop-in-deviance test to compare a model that includes only the significant predictors to the full model. Which model do you choose based on the results of this test?\n\n\n# add code\n\n\nIs your choice based on AIC consistent with your choice from the previous exercise? What about a choice based on BIC?\n\n\n# add code"
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#submission",
    "href": "ae/ae-10-logistic-compare.html#submission",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "ae/ae-10-logistic-compare.html#footnotes",
    "href": "ae/ae-10-logistic-compare.html#footnotes",
    "title": "AE 10: Comparing logistic regression models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe data set is from the Stat2Data R package. This AE is adapted from exercises in Stat 2.↩︎"
  },
  {
    "objectID": "ae/ae-06-model-compare.html",
    "href": "ae/ae-06-model-compare.html",
    "title": "AE 06: Model comparison",
    "section": "",
    "text": "Important\n\n\n\nRender, commit, and push your responses to GitHub by the end of class.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#data",
    "href": "ae/ae-06-model-compare.html#data",
    "title": "AE 06: Model comparison",
    "section": "Data",
    "text": "Data\nWhich variables help us predict the amount customers tip at a restaurant? To answer this question, we will use data collected in 2011 by a student at St. Olaf who worked at a local restaurant.\nThe variables we’ll focus on for this analysis are\n\nTip: amount of the tip\nParty: number of people in the party\nMeal: Time of day (Lunch, Dinner, Late Night)\nAge: Age category of person paying the bill (Yadult, Middle, SenCit)\nDay: Day of the week (includes every day but Monday)\n\nView the data set to see the remaining variables.\n\ntips &lt;- read_csv(\"data/tip-data.csv\")"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-1",
    "href": "ae/ae-06-model-compare.html#exercise-1",
    "title": "AE 06: Model comparison",
    "section": "Exercise 1",
    "text": "Exercise 1\nSplit the data into training (80%) and testing (20%) sets. Use seed 2025."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-2",
    "href": "ae/ae-06-model-compare.html#exercise-2",
    "title": "AE 06: Model comparison",
    "section": "Exercise 2",
    "text": "Exercise 2\nUse the training data to fit a model using Party, Age, and Meal to predict tips. Compute the \\(R^2\\) and \\(Adj. R^2\\) for this model."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-3",
    "href": "ae/ae-06-model-compare.html#exercise-3",
    "title": "AE 06: Model comparison",
    "section": "Exercise 3",
    "text": "Exercise 3\nNow fit a model predicting tips using Party, Age, and Meal, such that the effect of party can differ by Meal. Compute \\(R^2\\) and \\(Adj. R^2\\) for this model."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-4",
    "href": "ae/ae-06-model-compare.html#exercise-4",
    "title": "AE 06: Model comparison",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nWhich model do you choose - the model from Exercise 2 or Exercise 3? Why?\nCompute RMSE for the selected model."
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-5",
    "href": "ae/ae-06-model-compare.html#exercise-5",
    "title": "AE 06: Model comparison",
    "section": "Exercise 5",
    "text": "Exercise 5\nNow let’s use the testing data to assess the performance of the model selected in Exercise 4.\n\nCompute the predicted tips for the testing data. Add the predictions to the testing data set.\nCompute RMSE and \\(R^2\\) for the testing data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-6",
    "href": "ae/ae-06-model-compare.html#exercise-6",
    "title": "AE 06: Model comparison",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nHow do RMSE compare between the training and testing data?\nHow does \\(R^2\\) compare between the training and testing data?\nIs this what you expect? Why?"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#exercise-7",
    "href": "ae/ae-06-model-compare.html#exercise-7",
    "title": "AE 06: Model comparison",
    "section": "Exercise 7",
    "text": "Exercise 7\nWhy can we use \\(R^2\\) as an assessment of performance on the testing data even if we can’t use it to compare models?"
  },
  {
    "objectID": "ae/ae-06-model-compare.html#to-submit-the-ae",
    "href": "ae/ae-06-model-compare.html#to-submit-the-ae",
    "title": "AE 06: Model comparison",
    "section": "To submit the AE:",
    "text": "To submit the AE:\n\n\n\n\n\n\nImportant\n\n\n\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-11-multinomial.html",
    "href": "ae/ae-11-multinomial.html",
    "title": "AE 11: Multinomial logistic regression",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-10 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE."
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-1",
    "href": "ae/ae-11-multinomial.html#exercise-1",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nCreate a plot to visualize the relationship between the response, viewcat and the primary variable of interest in this analysis, viewenc. What do you observe from the plot?"
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-2",
    "href": "ae/ae-11-multinomial.html#exercise-2",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nCreate a plot to visualize the relationship between the response, viewcat and age. What do you observe from the plot?"
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-3",
    "href": "ae/ae-11-multinomial.html#exercise-3",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nFit a model using the ageCent and viewenc to understand the odds a child is in a given category of viewcat. Display the model including 95% confidence intervals for the coefficients."
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-4",
    "href": "ae/ae-11-multinomial.html#exercise-4",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nWhat is the baseline category for viewcat? What is the baseline category for viewenc?\nInterpret the intercept associated with the odds of a child being in the category viewcat == 2 versus the baseline.\nInterpret the effect of age in terms of the odds of a child being in the category viewcat == 2 versus the baseline. Based on the confidence interval for the coefficient, is the numeric predictor a statistically significant predictor of viewership?"
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-5",
    "href": "ae/ae-11-multinomial.html#exercise-5",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nShould the interaction between ageCent and viewenc be included in the model? Show any analysis used to make your conclusion."
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-6",
    "href": "ae/ae-11-multinomial.html#exercise-6",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nThe primary objective of the experiment was to understand the effect of encouragement on viewership. Does encouragement have a significant effect on viewership after adjusting for age? If so, describe the effect. Otherwise, explain why not."
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-7",
    "href": "ae/ae-11-multinomial.html#exercise-7",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nUse the model selected in Exercise 5 to compute the predicted probabilities and predicted classes for viewcat.\nMake a confusion matrix.\nWhat percentage of observations were correctly classified?"
  },
  {
    "objectID": "ae/ae-11-multinomial.html#exercise-8",
    "href": "ae/ae-11-multinomial.html#exercise-8",
    "title": "AE 11: Multinomial logistic regression",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nAssess the overall model performance.\nWere there particular categories in which the model has a harder time differentiating?"
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html",
    "href": "ae/ae-08-multicollinearity.html",
    "title": "AE 08: Multicollinearity",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-08 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)\nlibrary(rms) #calculate VIF"
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-1",
    "href": "ae/ae-08-multicollinearity.html#exercise-1",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nFit the regression model using high temperature, average temperature, season, and precipitation to predict volume.\nAre there any coefficients that may be not what you expected?"
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-2",
    "href": "ae/ae-08-multicollinearity.html#exercise-2",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 2",
    "text": "Exercise 2\nUse the formula\n\\[\nVIF_j = \\frac{1}{1 - R^2_j}\n\\]\nto calculate the VIF for avgtemp."
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-3",
    "href": "ae/ae-08-multicollinearity.html#exercise-3",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 3",
    "text": "Exercise 3\nBased on the VIF from the previous exercise, does avgtemp have a linear dependency with one or more other predictors? Explain."
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-4",
    "href": "ae/ae-08-multicollinearity.html#exercise-4",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nUse the vif function to compute VIF for all the predictors in Exercise 1.\nAre there predictors with near-linear dependencies? If so, which ones?"
  },
  {
    "objectID": "ae/ae-08-multicollinearity.html#exercise-5",
    "href": "ae/ae-08-multicollinearity.html#exercise-5",
    "title": "AE 08: Multicollinearity",
    "section": "Exercise 5",
    "text": "Exercise 5\nLet’s address the issue of multicollinearity. Choose a strategy to address the multicollinearity. Apply it, then use relevant statistics to select a final model."
  },
  {
    "objectID": "ae/ae-04-bootstrap.html",
    "href": "ae/ae-04-bootstrap.html",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-04 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#data",
    "href": "ae/ae-04-bootstrap.html#data",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\n\nglimpse(duke_forest)\n\nRows: 98\nColumns: 13\n$ address    &lt;chr&gt; \"1 Learned Pl, Durham, NC 27705\", \"1616 Pinecrest Rd, Durha…\n$ price      &lt;dbl&gt; 1520000, 1030000, 420000, 680000, 428500, 456000, 1270000, …\n$ bed        &lt;dbl&gt; 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4, 5, 3, 4, 4, 3,…\n$ bath       &lt;dbl&gt; 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0, 2.0, 3.0, 3.0,…\n$ area       &lt;dbl&gt; 6040, 4475, 1745, 2091, 1772, 1950, 3909, 2841, 3924, 2173,…\n$ type       &lt;chr&gt; \"Single Family\", \"Single Family\", \"Single Family\", \"Single …\n$ year_built &lt;dbl&gt; 1972, 1969, 1959, 1961, 2020, 2014, 1968, 1973, 1972, 1964,…\n$ heating    &lt;chr&gt; \"Other, Gas\", \"Forced air, Gas\", \"Forced air, Gas\", \"Heat p…\n$ cooling    &lt;fct&gt; central, central, central, central, central, central, centr…\n$ parking    &lt;chr&gt; \"0 spaces\", \"Carport, Covered\", \"Garage - Attached, Covered…\n$ lot        &lt;dbl&gt; 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.79, 0.53, 0.73,…\n$ hoa        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ url        &lt;chr&gt; \"https://www.zillow.com/homedetails/1-Learned-Pl-Durham-NC-…"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#exploratory-data-analysis",
    "href": "ae/ae-04-bootstrap.html#exploratory-data-analysis",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#model",
    "href": "ae/ae-04-bootstrap.html#model",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Model",
    "text": "Model\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#bootstrap-confidence-interval",
    "href": "ae/ae-04-bootstrap.html#bootstrap-confidence-interval",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Bootstrap confidence interval",
    "text": "Bootstrap confidence interval\n\n1. Calculate the observed fit (slope)\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159.\n\n\n\n\n2. Take n_iter bootstrap samples and fit models to each one.\nFill in the code, then set eval: true .\n\nn_iter = 100\nset.seed(091222)\n\nboot_fits &lt;- ______ |&gt;\n  specify(______) |&gt;\n  generate(reps = ____, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n\nWhy do we set a seed before taking the bootstrap samples?\nMake a histogram of the bootstrap samples to visualize the bootstrap distribution.\n\n# Code for histogram\n\n\n\n\n3. Compute the 95% confidence interval as the middle 95% of the bootstrap distribution\nFill in the code, then set eval: true .\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = _____, \n  level = ____,\n  type = \"percentile\"\n)"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#changing-confidence-level",
    "href": "ae/ae-04-bootstrap.html#changing-confidence-level",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nModify the code from Step 3 to create a 90% confidence interval.\n\n# Code for the 90% confidence interval\n\n\n\nModify the code from Step 3 to create a 99% confidence interval.\n\n# Code for the 99% confidence interval\n\n\nWhich confidence level produces the most accurate confidence interval (90%, 95%, 99%)? Explain\nWhich confidence level produces the most precise confidence interval (90%, 95%, 99%)? Explain\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-04 repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "prepare/prepare-lec01.html",
    "href": "prepare/prepare-lec01.html",
    "title": "Prepare for Lecture 01",
    "section": "",
    "text": "📖 Read the syllabus"
  },
  {
    "objectID": "prepare/prepare-lec02.html",
    "href": "prepare/prepare-lec02.html",
    "title": "Prepare for Lecture 02",
    "section": "",
    "text": "Required\n📖 Read Chapter 1\n\nOptional computing introduction/ review\n📖 Read GitHub for supporting, reusing, contributing, and failing safely\n🎥 Watch Meet the Toolkit: R + RStudio\n🎥 Watch Meet the Toolkit: Quarto"
  },
  {
    "objectID": "prepare/prepare-lec07.html",
    "href": "prepare/prepare-lec07.html",
    "title": "Prepare for Lecture 07: Multiple linear regression",
    "section": "",
    "text": "📖 Read Sections 7.1 - 7.4.1\n📖 Read Section 7.5"
  },
  {
    "objectID": "prepare/prepare-lec04.html",
    "href": "prepare/prepare-lec04.html",
    "title": "Prepare for Lecture 04: Inference - bootstrap confidence intervals",
    "section": "",
    "text": "📖 Read Sections 5.1 - 5.4\n💻 Reference Section 5.9.1 for R code"
  },
  {
    "objectID": "prepare/prepare-lec22.html",
    "href": "prepare/prepare-lec22.html",
    "title": "Prepare for Lecture 22: Multinomial Logistic Regression pt2",
    "section": "",
    "text": "📖 juliasilge.com/blog/multinomial-volcano-eruptions\n📖 juliasilge.com/blog/nber-papers"
  },
  {
    "objectID": "hw/stats-experience.html",
    "href": "hw/stats-experience.html",
    "title": "Statistics Experience",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "Statistics experience"
    ]
  },
  {
    "objectID": "hw/hw-03.html",
    "href": "hw/hw-03.html",
    "title": "HW 03",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 03"
    ]
  },
  {
    "objectID": "hw/hw-04.html",
    "href": "hw/hw-04.html",
    "title": "HW 04",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 04"
    ]
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "STA 210 - Regression Analysis",
    "section": "",
    "text": "In STA 210, students will learn how linear and logistic regression models are used to explore multivariable relationships and apply these methods to answer relevant and engaging questions using a data-driven approach. Students will develop computing skills to implement a reproducible data analysis workflow and gain experience communicating statistical results. Throughout the semester, students will work on a team project where they will develop a research question, answer it using methods learned in the course, and share results through a written report and presentation.\nTopics include applications of linear and logistic regression, interpretation, diagnostics, model selection, and model assessment. Students will gain experience using the computing tools R and GitHub to analyze real-world data from a variety of fields. This class emphasizes data analysis over mathematical theory.\n\n\n100-level Statistical Science course or Statistical Science 230, 231, or 240L",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#pre-requisites",
    "href": "overview.html#pre-requisites",
    "title": "STA 210 - Regression Analysis",
    "section": "",
    "text": "100-level Statistical Science course or Statistical Science 230, 231, or 240L",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#teaching-assistants",
    "href": "overview.html#teaching-assistants",
    "title": "STA 210 - Regression Analysis",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\nName\nRole\n\n\nAdeli Hutton\nLab leader\n\n\nShane Rybacki\nLab leader\n\n\n\nSee Canvas for office hours times and locations.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "labs/lab-06.html",
    "href": "labs/lab-06.html",
    "title": "Lab 06",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 06"
    ]
  },
  {
    "objectID": "labs/lab-05.html",
    "href": "labs/lab-05.html",
    "title": "Lab 05",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 05"
    ]
  },
  {
    "objectID": "labs/lab-01-DRAFT.html",
    "href": "labs/lab-01-DRAFT.html",
    "title": "Lab 01: Linear regression",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due on Thursday, January 29 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope"
  },
  {
    "objectID": "labs/lab-01-DRAFT.html#learning-goals",
    "href": "labs/lab-01-DRAFT.html#learning-goals",
    "title": "Lab 01: Linear regression",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the lab you will…\n\nFit and interpret a linear regression models in R.\nUse simulation-based inference to draw conclusions about the slope.\nContinue developing a workflow for reproducible data analysis."
  },
  {
    "objectID": "labs/lab-01.html",
    "href": "labs/lab-01.html",
    "title": "Lab 01",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 01"
    ]
  },
  {
    "objectID": "labs/lab-02.html",
    "href": "labs/lab-02.html",
    "title": "Lab 02",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 02"
    ]
  },
  {
    "objectID": "labs/lab-03.html",
    "href": "labs/lab-03.html",
    "title": "Lab 03",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 03"
    ]
  },
  {
    "objectID": "labs/lab-00.html",
    "href": "labs/lab-00.html",
    "title": "Lab 00: Getting started",
    "section": "",
    "text": "Important\n\n\n\nPlease complete all tasks before leaving lab today.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#rstudio",
    "href": "labs/lab-00.html#rstudio",
    "title": "Lab 00: Getting started",
    "section": "RStudio",
    "text": "RStudio\n\n\n\n\n\n\nTip\n\n\n\nR is the name of the programming language itself and RStudio is a convenient interface.\n\n\n\nReserve RStudio container\n\nGo to https://cmgr.oit.duke.edu/containers. You will log in using your NetID credentials.\nClick “Reserve STA 221” to reserve an RStudio container (OIT has included containers for STA 210 under the STA221 container header.) Be sure you reserve the container labeled STA 221 to ensure you have the computing set up you need for the class.\n\nYou only need to reserve a container once per semester.\n\n\nOpen RStudio container\n\nGo to https://cmgr.oit.duke.edu/containers and log in with your Duke NetID and Password.\nClick STA221 to log into the Docker container. You should now see the RStudio environment.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#git-and-github",
    "href": "labs/lab-00.html#git-and-github",
    "title": "Lab 00: Getting started",
    "section": "Git and GitHub",
    "text": "Git and GitHub\nIn addition to R and RStudio, we will use git and GitHub for version control and collaboration.\n\n\n\n\n\n\nTip\n\n\n\nGit is a version control system (like “Track Changes” features from Microsoft Word but more powerful) and GitHub is the home for your Git-based projects on the internet (like DropBox but much better).\n\n\n\nSign up for GitHub account\nYou will need a GitHub account to access the assignments, project, and in-class exercises for the course.\n\nIf you do not have a GitHub account, go to https://github.com and sign up for an account. If you already have a GitHub account, you can move on to the next step.\n\n\n\n\n\n\n\nTip\n\n\n\nClick here for advice on choosing a username.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#connect-rstudio-and-github",
    "href": "labs/lab-00.html#connect-rstudio-and-github",
    "title": "Lab 00: Getting started",
    "section": "Connect RStudio and GitHub",
    "text": "Connect RStudio and GitHub\nNow that you have RStudio and a GitHub account, we will configure git so that RStudio and GitHub communicate with one another.\n\nSet up your SSH Key\nYou will authenticate GitHub using SSH. An outline of the authentication steps is below; you are encouraged to follow along as your TA demonstrates the steps.\n\n\n\n\n\n\nNote\n\n\n\nYou only need to do this authentication process one time on a single system.\n\n\n\nStep 0: Open your RStudio container.\nStep 1: Type credentials::ssh_setup_github() into the console on the bottom left of the RStudio environment.\nStep 2: R will ask “No SSH key found. Generate one now?” Click 1 for yes.\nStep 3: You will generate a key. It will begin with “ssh-rsa….” R will then ask “Would you like to open a browser now?” Click 1 for yes.\nStep 4: You may be asked to provide your username and password to log into GitHub. This would be the ones associated with your account that you set up. After entering this information, paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta210)\n\n\n\nConfigure git\nThe last thing we need to do is configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package.\nType the following lines of code in the console in RStudio filling in your name and the email address associated with your GitHub account.\n\nusethis::use_git_config(\n  user.name = \"Your name\", \n  user.email = \"Email associated with your GitHub account\")\n\nFor example, mine would be\n\nusethis::use_git_config(\n  user.name = \"Maria Tackett\",\n  user.email = \"maria.tackett@duke.edu\")\n\nIt may look like nothing happened but you are now ready interact between GitHub and RStudio!",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#getting-started",
    "href": "labs/lab-00.html#getting-started",
    "title": "Lab 00: Getting started",
    "section": "Getting started",
    "text": "Getting started\n\nClick here to create your individual lab-00 repo: https://classroom.github.com/a/covo7pM-\nClick to open your lab-00 repo.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File → New Project → Version Control → Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-00.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#update-the-quarto-document",
    "href": "labs/lab-00.html#update-the-quarto-document",
    "title": "Lab 00: Getting started",
    "section": "Update the Quarto document",
    "text": "Update the Quarto document\n\nTask 1: Change the author name at the top of the document to your name. Render the document. You will see your name at the top of the rendered PDF.\nTask 2: The plot shows the relationship between the daily temperature and number of bike rentals in Washington, D.C.’s Capital Bikeshare in 2012.\n\n\n\n\n\n\n\n\n\n\nWrite 1 - 2 observations from the plot. Render the document. You will see your response in the rendered PDF.",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-00.html#commit-and-push-changes-to-github",
    "href": "labs/lab-00.html#commit-and-push-changes-to-github",
    "title": "Lab 00: Getting started",
    "section": "Commit and push changes to GitHub",
    "text": "Commit and push changes to GitHub\n\nOnce you have made your final updates, go to the Git pane in your RStudio instance. This is a tab in the top right corner of the RStudio window.\nCheck the appropriate boxes on every file in the Git pane. All checked files will be sent to GitHub.\nNext, write a meaningful commit message (for instance, “updated author name”) in the Commit message box.\nClick Commit. Note that every commit needs to have a commit message associated with it.\nNow that you have made an update and committed this change, click Push to send the changes to GitHub.\nGo to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you’re good to go!",
    "crumbs": [
      "Labs",
      "Lab 00"
    ]
  },
  {
    "objectID": "labs/lab-04.html",
    "href": "labs/lab-04.html",
    "title": "Lab 04",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 04"
    ]
  },
  {
    "objectID": "labs/lab-07.html",
    "href": "labs/lab-07.html",
    "title": "Lab 07",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 07"
    ]
  },
  {
    "objectID": "labs/lab-08.html",
    "href": "labs/lab-08.html",
    "title": "Lab 08",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Labs",
      "Lab 08"
    ]
  },
  {
    "objectID": "hw/hw-05.html",
    "href": "hw/hw-05.html",
    "title": "HW 05",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "hw/hw-01.html",
    "href": "hw/hw-01.html",
    "title": "HW 01: Simple linear regression",
    "section": "",
    "text": "Important\n\n\n\nThis assignment is due on Tuesday, January 27 at 11:59pm. To be considered on time, the following must be done by the due date:\n\nFinal .qmd and .pdf files pushed to your GitHub repo\nFinal .pdf file submitted on Gradescope",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#part-1-exploratory-data-analysis",
    "href": "hw/hw-01.html#part-1-exploratory-data-analysis",
    "title": "HW 01: Simple linear regression",
    "section": "Part 1: Exploratory data analysis",
    "text": "Part 1: Exploratory data analysis\n\nExercise 1\nCreate a histogram of the distribution of the response variable mc_preschool and compute the summary statistics. Use the visualization and summary statistics to describe the distribution. Include an informative title and axis labels on the plot.\n\n\n\n\n\n\nTip\n\n\n\nThe description should include shape, center, spread, and presence of outliers. Use specific values in your description. See Section 3.4.2 of Introduction to Regression Analysis for more information about describing univariate distributions. See the ggplot2 reference for example code and plots.\n\n\n\n\nExercise 2\nLet’s view the data in another way. Below is a map showing the 600 counties in our sample filled in based on values of mc_preschool. The code for the map was adapted from code produced by ChatGPT (model GPT-5.2).\n\nWhat are 2 observations you have from the map?\nWhat is a feature that is apparent in the map that wasn’t as easily apparent from the histogram in the previous exercise? What is a feature that is apparent in the histogram that is not as easily apparent from the map?\n\n\n\nCode\nmap_data_sample &lt;-  read_csv(\"data/county-map-2018.csv\") \n\n# create data frame containing mapping data for all counties\ncounties_sf &lt;- counties(cb = TRUE, year = 2018) |&gt;\n  st_as_sf() |&gt;\n  mutate(fips = paste0(STATEFP, COUNTYFP))\n\n# join mapping data to analysis data\ncounty_map_data &lt;- counties_sf |&gt;\n  left_join(childcare, by = \"fips\") \n\n# produce map\ncounty_map &lt;- ggplot(county_map_data) +\n  geom_sf(aes(fill = mc_toddler), color = NA) +\n  scale_fill_viridis_c(na.value = \"grey90\") +\n  coord_sf(\n    xlim = c(-125, -66),\n    ylim = c(24, 50),\n    expand = FALSE)  +\n  labs(title = \"Median weekly preschool costs\",\n       subtitle = \"for 600 counties in the United States\",\n       fill = \"Median cost\") +\n  theme_void() \n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 3\nCreate a visualization of the relationship between me_2018 and mc_toddler and compute the correlation. Use the visualization and correlation to describe the relationship between the two variables.\n\nThis is a good place to render, commit, and push changes to your hw-01 repo on GitHub. Write an informative commit message (e.g. “Completed exercises 1 - 3”), and push every file to GitHub by clicking the check box next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#part-2-modeling",
    "href": "hw/hw-01.html#part-2-modeling",
    "title": "HW 01: Simple linear regression",
    "section": "Part 2: Modeling",
    "text": "Part 2: Modeling\n\nExercise 4\nWe will use a linear regression model to explain variability in mc_preschool based on me_2018.\nWrite the form of the statistical (theoretical) model using mathematical notation. In your response, make it clear which variable (me_2018 or mc_preschool) is the predictor and which variable is the response.\n\n\n\n\n\n\nTip\n\n\n\nUse the following code format to make the variable names properly render in the PDF document.\n\\(\\text{me\\_2018}\\) = \\text{me\\_2018}\n\\(\\text{mc\\_preschool}\\) = \\text{mc\\_preschool}\n\n\n\n\nExercise 5\n\nFit the regression line corresponding to the statistical model in the previous exercise. Neatly display the model output using 3 digits.\nWrite the equation of the fitted model using mathematical notation. In your response, make it clear which variable (me_2018 or mc_preschool) is the predictor and which variable is the response.\n\n\n\nExercise 6\n\nInterpret the slope in the context of the data.\nDoes the intercept have a meaningful interpretation? If so, write the interpretation in the context of the data. Otherwise, briefly explain why not.\n\n\n\nExercise 7\n\nIn 2018, the median income in Durham County was $35,436. What is the predicted median weekly cost for preschool based on the model in Exercise 5?\nThe actual median cost for preschool was $173 per week. What is the residual?\n\n\nThis is a good place to render, commit, and push changes to your hw-01 repo on GitHub. Write an informative commit message (e.g. “Completed exercises 4 -7”), and push every file to GitHub by clicking the check box next to each file in the Git pane. After you push the changes, the Git pane in RStudio should be empty.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-01.html#part-3-inference",
    "href": "hw/hw-01.html#part-3-inference",
    "title": "HW 01: Simple linear regression",
    "section": "Part 3: Inference",
    "text": "Part 3: Inference\nWe will use the data from these 600 randomly selected counties to draw conclusions about the relationship between income and weekly cost of preschool for the over 3,000 counties in the United States.\n\nExercise 8\n\nWhat is the population in this analysis? What is the sample?\nIs it reasonable to treat the sample in this analysis as representative of the population? Briefly explain why or why not.\n\n\n\nExercise 9\nConstruct a 90% bootstrap confidence interval for the slope. Use set.seed(2026) and 1000 iterations. Show all relevant code and output used to produce the interval.\nWrite the 90% confidence interval using 3 digits.\n\n\nExercise 10\n\nInterpret the interval from the previous exercise in the context of the data.\nYou want to use the confidence interval to evaluate the claim that there is no linear relationship between median income and cost of preschool. In other words, you want to evaluate the claim that \\(\\beta_1 = 0\\) in the model written in Exercise 4.\nDoes the confidence interval from the previous exercise support this claim? Briefly explain why or why not.\n\n\nNow is a good time to render your document again if you haven’t done so recently, commit (with an informative commit message), and push all updates.",
    "crumbs": [
      "Homework",
      "HW 01"
    ]
  },
  {
    "objectID": "hw/hw-02.html",
    "href": "hw/hw-02.html",
    "title": "HW 02",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Homework",
      "HW 02"
    ]
  },
  {
    "objectID": "prepare/prepare-lec18.html",
    "href": "prepare/prepare-lec18.html",
    "title": "Prepare for Lecture 18: Logistic regression - Prediction",
    "section": "",
    "text": "📖 Classification module in Google Machine Learning Crash Course"
  },
  {
    "objectID": "prepare/prepare-lec10.html",
    "href": "prepare/prepare-lec10.html",
    "title": "Prepare for Lecture 10: Inference + Model conditions",
    "section": "",
    "text": "📖 Read Model conditions"
  },
  {
    "objectID": "prepare/prepare-lec05.html",
    "href": "prepare/prepare-lec05.html",
    "title": "Prepare for Lecture 05: Inference - permutation tests",
    "section": "",
    "text": "📖 Read Sections 5.5 - 5.7\n💻 Reference Section 5.9.2 for R code"
  },
  {
    "objectID": "prepare/prepare-lec06.html",
    "href": "prepare/prepare-lec06.html",
    "title": "Prepare for Lecture 06: Inference - Mathematical models",
    "section": "",
    "text": "📖 Read Section 5.8\n💻 Reference Section 5.9.3"
  },
  {
    "objectID": "prepare/prepare-lec03.html",
    "href": "prepare/prepare-lec03.html",
    "title": "Prepare for Lecture 03",
    "section": "",
    "text": "Required\n📖 Read Chapter 4\n\nOptional\nRead Chapter 3 for review of exploratory data analysis"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html",
    "href": "ae/ae-07-exam-01-review.html",
    "title": "AE 07: Exam 01 review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-07- to get started.\nRender, commit, and push your responses to GitHub by the end of class."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#packages",
    "href": "ae/ae-07-exam-01-review.html#packages",
    "title": "AE 07: Exam 01 review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#trail-users",
    "href": "ae/ae-07-exam-01-review.html#trail-users",
    "title": "AE 07: Exam 01 review",
    "section": "Trail users",
    "text": "Trail users\nThe Pioneer Valley Planning Commission (PVPC) collected data for ninety days from April 5, 2005 to November 15, 2005. Data collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.\nWe will use regression analysis to predict the number of trail users based on weather and other features describing the day.\nThe variables we’ll focus on for this analysis are\n\nvolume estimated number of trail users that day (number of breaks recorded)\nhightemp daily high temperature (in degrees Fahrenheit)\nseason one of “Fall”, “Spring”, or “Summer”\ndaytype one of “weekday” or “weekend”\n\nView the data set1 to see the remaining variables.\n\nrail_trail &lt;- read_csv(\"data/rail-trail.csv\")"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#exploratory-analysis",
    "href": "ae/ae-07-exam-01-review.html#exploratory-analysis",
    "title": "AE 07: Exam 01 review",
    "section": "Exploratory analysis",
    "text": "Exploratory analysis\n\nExercise 1\nVisualize, summarize, and describe the distribution of volume.\n\n\nExercise 2\n\nVisualize and describe the relationship between hightemp and volume.\nModify the plot to consider if the relationship between these variables differs by daytype."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#modeling",
    "href": "ae/ae-07-exam-01-review.html#modeling",
    "title": "AE 07: Exam 01 review",
    "section": "Modeling",
    "text": "Modeling\nFit a model using hightemp and daytype to predict the volume for this trail.\n\nExercise 3\n\nWrite the statistical model.\nFit the model and write the estimated regression equation. Neatly display the results using 3 digits and the 90% confidence interval for the coefficients.\n\n\n\nExercise 4\nInterpret the slope of hightemp in the context of the data.\n\n\nExercise 5\n\nDoes it make sense to interpret the intercept? Explain your reasoning.\nIf not, what can we do to make the interpretation meaningful?"
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#inference-for-coefficients",
    "href": "ae/ae-07-exam-01-review.html#inference-for-coefficients",
    "title": "AE 07: Exam 01 review",
    "section": "Inference for coefficients",
    "text": "Inference for coefficients\n\nExercise 6\nThe following code can be used to create a bootstrap distribution for the model coefficients. Describe what each line of code does, supplemented by any visualizations that might help with your description.\n\nset.seed(1234)\n\n1boot_dist &lt;- rail_trail |&gt;\n2  specify(volume ~ hightemp + daytype) |&gt;\n3  generate(reps = 100, type = \"bootstrap\") |&gt;\n4  fit()\n\n\n1\n\n___\n\n2\n\n___\n\n3\n\n___\n\n4\n\n___\n\n\n\n\n\n\nExercise 7\nUse the bootstrap distribution created in Exercise 6, boot_dist, to construct a 90% confidence interval for the coefficient of hightemp using bootstrapping and the percentile method and interpret it in context of the data.\n\n\nExercise 8\nConduct a hypothesis test for the coefficient of hightemp significance level using permutation with 100 reps. State the hypotheses in words and mathematical notation. Also include a visualization of the null distribution of the slope with the observed slope marked as a vertical line.\n\n\nExercise 9\nNow repeat Exercises 7 and 8 using approaches based on mathematical models. You can reference output from previous exercises and/or write new code as needed."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#inference-for-prediction",
    "href": "ae/ae-07-exam-01-review.html#inference-for-prediction",
    "title": "AE 07: Exam 01 review",
    "section": "Inference for prediction",
    "text": "Inference for prediction\n\nExercise 10\nBased on your model, predict the volume for a weekday with high temperature of degrees.\n\n\nExercise 11\nSuppose you’re asked to construct a confidence and a prediction interval for your finding in the previous exercise. Which one would you expect to be wider and why? In your answer clearly state the difference between these intervals.\n\n\nExercise 12\nNow construct the intervals and comment on whether your guess is confirmed."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#interaction-terms",
    "href": "ae/ae-07-exam-01-review.html#interaction-terms",
    "title": "AE 07: Exam 01 review",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nExercise 13\nNow fit the model using hightemp and daytype to predict volume such that the effect of hightemp can differ by daytype.\n\n\nExercise 14\n\nWrite the estimated regression equation for weekends.\nWrite the estimated regression equation for weekdays.\n\n\n\nExercise 15\nAccording to this model, does the effect of hightemp differ for weekends vs. weekdays? Explain."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#model-comparison",
    "href": "ae/ae-07-exam-01-review.html#model-comparison",
    "title": "AE 07: Exam 01 review",
    "section": "Model comparison",
    "text": "Model comparison\n\nExercise 16\nWhich model is a better fit for the data - the model with or without the interaction? Show any work to support your choice.\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-07- repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-07-exam-01-review.html#footnotes",
    "href": "ae/ae-07-exam-01-review.html#footnotes",
    "title": "AE 07: Exam 01 review",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSource: Pioneer Valley Planning Commission via the mosaicData package.↩︎"
  },
  {
    "objectID": "ae/ae-02-life-expectancy.html",
    "href": "ae/ae-02-life-expectancy.html",
    "title": "Lecture 02 AE",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-02-life-expectancy.html#introduction",
    "href": "ae/ae-02-life-expectancy.html#introduction",
    "title": "Lecture 02 AE",
    "section": "Introduction",
    "text": "Introduction\nThe data set comes from Zarulli et al. (2021), who analyze the effects of a country’s healthcare expenditures and other factors on the country’s life expectancy. The data are originally from the Human Development Database and World Health Organization.\nThis AE will focus on the following variables:\n\nlife_exp: The average number of years that a newborn could expect to live, if he or she were to pass through life exposed to the sex- and age-specific death rates prevailing at the time of his or her birth, for a specific year, in a given country, territory, or geographic area. ( from the World Health Organization)\nhealth_pct_gdp: Spending on healthcare goods and services, expressed as a percentage of GDP. It excludes capital health expenditures such as buildings, machinery, information technology and stocks of vaccines for emergency or outbreaks.\n\nClick here for the original research paper and a full list of variables in the original data set.\n\nlife_exp &lt;- read_excel(\"data/life-expectancy-data.xlsx\") |&gt; \n  rename(life_exp = `Life_expectancy_at_birth`, \n         health_pct_gdp = `Domestic_general_government_health_expenditure_pct_of_GDP`)\n\n\nlife_exp |&gt;\n  select(life_exp, health_pct_gdp) |&gt;\n  glimpse()\n\nRows: 140\nColumns: 2\n$ life_exp       &lt;dbl&gt; 63.8, 78.2, 59.9, 76.2, 74.6, 83.0, 81.3, 72.5, 71.8, 7…\n$ health_pct_gdp &lt;dbl&gt; 5, 41, 44, 74, 16, 68, 73, 20, 18, 61, 84, 66, 21, 74, …"
  },
  {
    "objectID": "ae/ae-02-life-expectancy.html#exercises",
    "href": "ae/ae-02-life-expectancy.html#exercises",
    "title": "Lecture 02 AE",
    "section": "Exercises",
    "text": "Exercises\nWe begin by visualizing the distributions of life expectancy, health expenditure percentage, and the relationship between these two variables.\n\np1 &lt;- ggplot(life_exp, aes(x = life_exp)) +\n  geom_histogram() + \n  labs(x = \"Life expectancy\")\n\np2 &lt;- ggplot(life_exp, aes(x = health_pct_gdp)) +\n  geom_histogram() + \n  labs(x = \"% Health expenditure\")\n\np3 &lt;- ggplot(life_exp, aes(x = health_pct_gdp, y = life_exp)) +\n  geom_point() + \n  labs(x = \"% Health expenditure\", \n       y = \"Life expectancy\")\n\n(p1 | p2) / p3\n\n\n\n\n\n\n\n\n\nExercise 1\nDescribe the relationship between life expectancy and healthcare expenditure as a percentage of the GDP. Comment on how we expect the life expectancy to change as the percentage on healthcare expenditure changes.\n\n\nExercise 2\nSuppose you want to fit a model so you can use the healthcare expenditure as a percentage of GDP to predict life expectancy. Would a model of the form\n\\[\\text{life_exp} = \\beta_0 + \\beta_1 ~ \\text{health_pct_gdp} + \\epsilon\\]\nbe a useful model for the data? Briefly explain your choice.\nSubmit your response below (counts towards participation points):\n\n \n🔗 https://forms.office.com/r/u6zwyypDaZ"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html",
    "href": "ae/ae-12-exam-02-review.html",
    "title": "AE 12: Exam 02 Review",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-12 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE."
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#packages",
    "href": "ae/ae-12-exam-02-review.html#packages",
    "title": "AE 12: Exam 02 Review",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(pROC)"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-1",
    "href": "ae/ae-12-exam-02-review.html#exercise-1",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 1",
    "text": "Exercise 1\nSuppose you fit a simple linear regression model.\n\nDraw or describe a scatterplot that contains an observation with large leverage but low Cook’s distance.\nDraw or describe a scatterplot that contains an observation with large leverage and high Cook’s distance.\nDraw or describe a scatterplot that contains an observation with a large studentized residual."
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#data-credit-cards",
    "href": "ae/ae-12-exam-02-review.html#data-credit-cards",
    "title": "AE 12: Exam 02 Review",
    "section": "Data: Credit cards",
    "text": "Data: Credit cards\nThe data for this analysis is about credit card customers. It can be found in the file credit.csv. The following variables are in the data set:\n\nincome: Income in $1,000’s\nlimit: Credit limit\nrating: Credit rating\ncards: Number of credit cards\nage: Age in years\neducation: Number of years of education\nown: A factor with levels No and Yes indicating whether the individual owns their home\nstudent: A factor with levels No and Yes indicating whether the individual was a student\nmarried: A factor with levels No and Yes indicating whether the individual was married\nregion: A factor with levels South, East, and West indicating the region of the US the individual is from\nbalance: Average credit card balance in $.\n\nThe objective of this analysis is to predict whether a person has maxed out their credit card, i.e., had $0 average card balance.\n\ncredit &lt;- read_csv(\"data/credit.csv\") |&gt;\n  mutate(maxed = factor(if_else(balance == 0, 1, 0)))"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-2",
    "href": "ae/ae-12-exam-02-review.html#exercise-2",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWhy is logistic regression the best modeling approach for this analysis?\nDescribe where each of the following show up in the analysis:\n\nlog-odds …\nodds\nprobabilities"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-3",
    "href": "ae/ae-12-exam-02-review.html#exercise-3",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe’ll start by splitting the model into training and testing data. Then we’ll using the training data to fit a model for predicting the odds of maxed = 1 using income, rating, and region.\n\n# make training and test sets\nset.seed(210)\ncredit_split &lt;- initial_split(credit, prop = 0.8)\ncredit_train &lt;- training(credit_split)\ncredit_test &lt;- testing(credit_split)\n\ncredit_fit &lt;- glm(maxed ~ income + rating + region, data = credit_train, \n                  family = \"binomial\")\n\ntidy(credit_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n10.097\n1.687\n5.987\n0.000\n\n\nincome\n0.115\n0.026\n4.444\n0.000\n\n\nrating\n-0.058\n0.009\n-6.428\n0.000\n\n\nregionSouth\n-0.632\n0.715\n-0.884\n0.377\n\n\nregionWest\n-0.332\n0.724\n-0.458\n0.647\n\n\n\n\n\nThe logistic regression model takes the following form:\n\\[\n\\log(\\frac{\\pi_i}{1 - \\pi_i}) = \\beta_0 + \\beta_1 ~ income + \\beta_2 ~ rating + \\beta_3 ~ regionSouth + \\beta_4 ~ regionWest\n\\]\n\nWrite the interpretation of income in terms of the odds of maxing out a credit card.\nUse the equation above to show the expected change in the odds of maxing out a credit card when the credit rating increases by 10 points. Assume income and region are constant. Write your answer in terms of \\(\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4\\).\nSuppose there are two individuals. Individual 1 has an income of $64,000, a credit rating of 590, and is from the South region. Individual 2 has an income of $135,000, a credit rating of 695, and is from the East region. Use the equation above to show how the odds of maxing out a credit card differ between Individual 1 and Individual 2. Write your answer in terms of \\(\\beta_0, \\beta_1, \\beta_2\\), etc."
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-4",
    "href": "ae/ae-12-exam-02-review.html#exercise-4",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 4",
    "text": "Exercise 4\nWe consider adding the interaction between region and income to the current model. We’ll use a drop-in-deviance test to determine whether or not to add the interaction term.\n\nState the null and alternative hypotheses in words and using mathematical notation.\nDescribe what the test statistic \\(G\\) means in the context of the data.\nShow why the degrees of freedom for the test statistic are equal to 2.\nConduct the drop-in-deviance test and state your conclusion in the context of the data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-5",
    "href": "ae/ae-12-exam-02-review.html#exercise-5",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 5",
    "text": "Exercise 5\nNow let’s evaluate the performance of the selected model using the testing data.\nCreate a confusion matrix using a cutoff probability of 0.3.\n\n# add code here\n\n\nWhat is the sensitivity? What does it mean in the context of the data ?\nWhat is the specificity? What does it mean in the context of the data?\nWhat is the false positive rate? What does it mean in the context of the data?\nWhat is the false negative rate? What does it mean in the context of the data?"
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-6",
    "href": "ae/ae-12-exam-02-review.html#exercise-6",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 6",
    "text": "Exercise 6\nProduce the ROC curve.\n\n# add code here\n\n\nDescribe how you can use this curve to select a cutoff probability (rather than just going with 0.5)."
  },
  {
    "objectID": "ae/ae-12-exam-02-review.html#exercise-7",
    "href": "ae/ae-12-exam-02-review.html#exercise-7",
    "title": "AE 12: Exam 02 Review",
    "section": "Exercise 7",
    "text": "Exercise 7\nQuestions about checking conditions for logistic regression:\n\nDo we assess conditions on the training or testing set?\nWhy do we not consider categorical predictors when checking linearity?\nWhy do we not need to check constant variance for logistic regression?"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html",
    "href": "ae/ae-05-sim-testing.html",
    "title": "AE 05: Permutation test for the slope",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-05 repo to get started.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#data",
    "href": "ae/ae-05-sim-testing.html#data",
    "title": "AE 05: Permutation test for the slope",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\nGoal: Use statistical inference to evaluate whether there is a relationship between the age of the house at time of sale and its price."
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#exploratory-data-analysis",
    "href": "ae/ae-05-sim-testing.html#exploratory-data-analysis",
    "title": "AE 05: Permutation test for the slope",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\nLet’s begin by creating a new variable that is the age of the house in 2020.\n\nduke_forest &lt;- duke_forest |&gt;\n  mutate(age_2020 = 2020 - year_built)\n\nNow let’s visualize the relationship between the age of the house in 2020 and the sales price.\n\nggplot(duke_forest, aes(x = age_2020, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Age in 2020 (years)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and age of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#model",
    "href": "ae/ae-05-sim-testing.html#model",
    "title": "AE 05: Permutation test for the slope",
    "section": "Model",
    "text": "Model\n\ndf_fit &lt;- lm(price ~ age_2020, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n690891.015\n68637.793\n10.066\n0.000\n\n\nage_2020\n-2473.935\n1225.191\n-2.019\n0.046"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#hypothesis-test",
    "href": "ae/ae-05-sim-testing.html#hypothesis-test",
    "title": "AE 05: Permutation test for the slope",
    "section": "Hypothesis test",
    "text": "Hypothesis test\n\n\n\n\n\n\nTip\n\n\n\nFor code chunks with fill-in-the-blank code, change code chunk option to #| eval: true once you’ve filled in the code.\n\n\n\nState the null and alternative hypotheses\nWrite the null and alternative hypotheses in words and mathematical notation.\n\n\nGenerate null distribution using permutation\nFill in the code, then set eval: true .\n\nn = 100\nset.seed(012226)\n\nnull_dist &lt;- _____ |&gt;\n  specify(______) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = _____, type = \"permute\") |&gt;\n  fit()\n\n\n\nVisualize distribution\n\n# Code for histogram of null distribution\n\n\n\nCompute the p-value\n\n# get observed fit \nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ age_2020) |&gt;\n  fit()\n\n# calculate p-value\nget_p_value(\n  ____,\n  obs_stat = ____,\n  direction = \"two-sided\"\n)\n\n\n\nState conclusion\nWrite your conclusion in the context of the data. You can use 0.05 as the decision-making threshold."
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#bootstrap-ci",
    "href": "ae/ae-05-sim-testing.html#bootstrap-ci",
    "title": "AE 05: Permutation test for the slope",
    "section": "Bootstrap CI",
    "text": "Bootstrap CI\n\nConstruct the bootstrap CI\nConstruct a 95% bootstrap confidence interval.\n\n# Code for ci\n\n\n\nDraw conclusion\n\nInterpret the interval in the context of the data.\nIs the interval consistent with the conclusion from your hypothesis test? Briefly explain why or why not."
  },
  {
    "objectID": "ae/ae-03-slr.html",
    "href": "ae/ae-03-slr.html",
    "title": "AE 03: Simple linear regression",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-03 repo to get started. If you do not see an ae-03 repo, use the link below to create one:\nhttps://classroom.github.com/a/JpQEbKBU\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-1",
    "href": "ae/ae-03-slr.html#exercise-1",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nVisualizations for the univariate and bivariate exploratory data analysis of daily bike rentals and temperature are below.\n\np1 &lt;- ggplot(bikeshare, aes(x = count)) +\n  geom_histogram(binwidth = 250) + \n  labs(x = \"Daily bike rentals\")\n\np2 &lt;- ggplot(bikeshare, aes(x = temp_orig)) +\n  geom_histogram() + \n  labs(x = \"Temperature (Celsius)\")\n\np3 &lt;- ggplot(bikeshare, aes(y = count, x = temp_orig)) +\n  geom_point() + \n  labs(x = \"Temperature (Celsius)\", \n       y = \"Daily bike rentals\")\n\n(p1 | p2) / p3\n\n\n\n\n\n\n\n\nThere appears to be one day with a very small number of bike rentals. What was the day? Why were the number of bike rentals so low on that day? Hint: You can Google the date to figure out what was going on that day."
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-2",
    "href": "ae/ae-03-slr.html#exercise-2",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nIn the raw data, seasons are coded as 1, 2, 3, 4, numeric values that correspond to winter, spring, summer, and fall respectively. Complete the code below to make season a categorical variable with levels corresponding to season names stored in the original order.\n\nbikeshare &lt;- bikeshare |&gt;\n  mutate(season = case_when(\n    season == 1 ~ \"Winter\", \n    season == 2 ~ \"Spring\", \n    season == 3 ~ \"Summer\", \n    season == 4 ~ \"Fall\"\n  ))"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-3",
    "href": "ae/ae-03-slr.html#exercise-3",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nWe want to evaluate whether the relationship between temperature and daily bike rentals is the same for each season. To answer this question, begin by creating a scatter plot of daily bike rentals vs. temperature faceted by season.\n\n# add code developed during livecoding here"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-4",
    "href": "ae/ae-03-slr.html#exercise-4",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nWhich season appears to have the strongest relationship between temperature and daily bike rentals? Why do you think the relationship is strongest in this season?\nWhich season appears to have the weakest relationship between temperature and daily bike rentals? Why do you think the relationship is weakest in this season?"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-5",
    "href": "ae/ae-03-slr.html#exercise-5",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 5",
    "text": "Exercise 5\nFilter your data for the season with the strongest apparent relationship between temperature and daily bike rentals.\n\n# add code developed during livecoding here"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-6",
    "href": "ae/ae-03-slr.html#exercise-6",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nUsing the data from Exercise 5, fit a linear model to predict daily bike rentals using temperature for this season.\n\n# add code developed during livecoding here"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-7",
    "href": "ae/ae-03-slr.html#exercise-7",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nUse the output to write out the estimated regression equation."
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-8",
    "href": "ae/ae-03-slr.html#exercise-8",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nInterpret the slope in the context of the data.\nDoes the intercept have a meaningful interpretation? If so, interpret the intercept in the context of the data. Otherwise, explain why not."
  },
  {
    "objectID": "ae/ae-03-slr.html#exercise-9",
    "href": "ae/ae-03-slr.html#exercise-9",
    "title": "AE 03: Simple linear regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nSuppose you work for a bike share company in Durham, NC, and they want to predict daily bike rentals in 2026. What is one reason you might recommend they use your analysis for this task? What is one reason you would recommend they not use your analysis for this task?"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html",
    "href": "ae/ae-09-prob-odds.html",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-09 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class to submit your AE.\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(tidymodels)"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-1",
    "href": "ae/ae-09-prob-odds.html#exercise-1",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nWhat is the probability a randomly selected respondent has heard a lot about AI?\nWhat are the odds a randomly selected respondent has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-2",
    "href": "ae/ae-09-prob-odds.html#exercise-2",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWhat is the probability a randomly selected respondent who is concerned about increased use of AI in daily life has heard a lot about AI?\nWhat are the odds a randomly selected respondent who is concerned about increased use of AI in daily life has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-3",
    "href": "ae/ae-09-prob-odds.html#exercise-3",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 3",
    "text": "Exercise 3\nMake a plot to visualize the relationship between how much a respondent has heard about AI and being concerned with increased use of AI in daily life. Use the plot to describe the relationship between the two variables."
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-4",
    "href": "ae/ae-09-prob-odds.html#exercise-4",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nHow do the odds of being concerned about increased use of AI in daily life for a randomly selected respondent who has heard nothing about AI compare to the odds for a randomly selected respondent who has heard a lot about AI?\nHow do the odds of being concerned about increased use of AI in daily life for a randomly selected respondent who has heard a little about AI compare to the odds for a randomly selected respondent who has heard a lot about AI?"
  },
  {
    "objectID": "ae/ae-09-prob-odds.html#exercise-5",
    "href": "ae/ae-09-prob-odds.html#exercise-5",
    "title": "AE 09: Probabilities, Odds, Odds ratios",
    "section": "Exercise 5",
    "text": "Exercise 5\nWe can use a logistic regression model to understand the relationship between how much someone has heard about AI and whether they are concerned about increased use of AI in daily life. (We will discuss this in detail next class, but will get a preview for now.)\nLet \\(p\\) be the probability a randomly selected respondent is concerned about increased use of AI in daily life. The statistical model is\n\\[\n\\begin{aligned}\n\\log\\Big(\\frac{p_i}{1-p_i}\\Big) = \\beta_0 &+ \\beta_1\\boldsymbol{1}(ai\\_heard_i = \\text{A little}) \\\\ &+ \\beta_2\\mathbf{1}(ai\\_heard_i = \\text{Nothing}) \\\\  &+ \\beta_3\\mathbf{1}(ai\\_heard_i = \\text{Refused})\n\\end{aligned}\n\\]\nThe code and output to fit this model is shown below:\n\nai_concern_fit &lt;- glm(ai_concern ~ ai_heard, data = pew_data,\n                      family = \"binomial\")\ntidy(ai_concern_fit) |&gt; \n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-0.065\n0.031\n-2.082\n0.037\n\n\nai_heardA little\n0.383\n0.040\n9.504\n0.000\n\n\nai_heardNothing at all\n-0.276\n0.079\n-3.505\n0.000\n\n\nai_heardRefused\n-0.697\n0.459\n-1.520\n0.129\n\n\n\n\n\n\nInterpret the intercept in the context of the data in terms of the log-odds of being concerned about increased use of AI in daily life.\nInterpret the coefficient of ai_heardA little in the context of the data in terms of the log-odds of being concerned about increased use of AI in daily life.\nInterpret the coefficient of ai_heardNothing at all in the context of the data in terms of the odds of being concerned about the increased use of AI in daily life. How does this compare to your response to Exercise 4?\n\n\n\n\n\n\n\nImportantSubmission\n\n\n\nTo submit the AE:\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your AE repo on GitHub. You’re done! 🎉"
  },
  {
    "objectID": "support.html",
    "href": "support.html",
    "title": "Course support",
    "section": "",
    "text": "We expect everyone will have questions at some point in the semester, so we want to make sure you can identify when that is and feel comfortable seeking help.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#lectures-and-labs",
    "href": "support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#office-hours",
    "href": "support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on Canvas to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage you to take advantage of them!\nMake a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours on the course Canvas site.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#ed-discussion",
    "href": "support.html#ed-discussion",
    "title": "Course support",
    "section": "Ed Discussion",
    "text": "Ed Discussion\nOutside of class and office hours, any general questions about course content or assignments should be posted on Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts on Ed Discussion before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#email",
    "href": "support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nIf you have questions about personal matters that are not appropriate for the class discussion forum (e.g. illness, accommodations, etc.), you may me at maria.tackett@duke.edu. If you email me, please include “STA 210” in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#academic-support",
    "href": "support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThe Academic Resource Center (the ARC) offers services to support students academically during their undergraduate careers at Duke. The ARC can provide support with time management, academic skills and strategies, course-specific tutoring, presentation skills, public speaking, and more. ARC services are available free to all Duke undergraduate students studying any discipline. Learn more:\n\nLearning Consultations – time management, study strategies, learning preferences, and more\nVOICE Lab – strengthen public speaking, practice presentations, and more\n\nYou can contact the Academic Resource Center by phone at (919) 684-5917, by email at theARC@duke.edu, or by visiting http://arc.duke.edu/.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#mental-health-and-wellbeing-resources",
    "href": "support.html#mental-health-and-wellbeing-resources",
    "title": "Course support",
    "section": "Mental health and wellbeing resources",
    "text": "Mental health and wellbeing resources\n\nDukeReach provides comprehensive outreach services to support students in managing all aspects of wellbeing, including referrals and follow-up services for students who are experiencing significant challenges related to mental health, physical health, social adjustment, and/or a variety of other stressors. You can contact the DukeReach team at dukereach@duke.edu and/or submit a referral at support.students.duke.edu. \nCounseling and Psychological Services (CAPS) offers counseling services to Duke students including virtual appointments, and referrals in the community. You do not need an appointment for an initial assessment. You may walk in or call 919-660-1000 to get started. Hours: Monday-Friday 9:00am - 4:00pm. After hours counseling services are available at no additional cost to students, you can call: 919-660-1000 Option 2.\nTimelyCare (formerly known as Blue Devils Care) is an online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling.\nDuke Student Health offers a wide range of healthcare services for all Duke students, many of which are covered by the student health fee. To make an appointment call (919) 681-9355. Hours: Monday - Friday, 8am - 4:30pm, Thursday 9am - 4:30pm. Closed from 12-12:30 each day.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#technology-accommodations",
    "href": "support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nHighly aided students who have limited access to computers may request loaner laptops through the DukeLIFE Technology Assistance Program. Please note that supplies are limited.\nNote that we will be using Duke’s computational resources in this course. These resources are freely available to you. As long as your computer can connect to the internet and open a browser window, you can perform the necessary computing for this course. All software we use is open-source and/or freely available.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#course-materials-costs",
    "href": "support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.).",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "support.html#assistance-with-zoom-or-canvas",
    "href": "support.html#assistance-with-zoom-or-canvas",
    "title": "Course support",
    "section": "Assistance with Zoom or Canvas",
    "text": "Assistance with Zoom or Canvas\nFor technical help with Canvas or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Canvas here.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person.",
    "crumbs": [
      "Support"
    ]
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Duke University Department of Statistical Science, go to the Duke Container Manager website, cmgr.oit.duke.edu/containers.\nIf this is your first time accessing the containers, click on reserve STA210 on the Reservations available menu on the right. You only need to do this once, and when you do, you’ll see this container moved to the My reservations menu on the left.\nNext, click on STA210 under My reservations to access the RStudio instance you’ll use for the course.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html",
    "href": "slides/04-slr-bootstrap-notes.html",
    "title": "SLR: Simulation-based inference",
    "section": "",
    "text": "HW 01 due Tuesday, January 27 at 11:59pm\n\nReleased after class today\nAI Disclosure"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#announcements",
    "href": "slides/04-slr-bootstrap-notes.html#announcements",
    "title": "SLR: Simulation-based inference",
    "section": "",
    "text": "HW 01 due Tuesday, January 27 at 11:59pm\n\nReleased after class today\nAI Disclosure"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#topics",
    "href": "slides/04-slr-bootstrap-notes.html#topics",
    "title": "SLR: Simulation-based inference",
    "section": "Topics",
    "text": "Topics\n\nIntroduce inference for a population slope\nFind range of plausible values for the slope using bootstrap confidence intervals"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#computational-setup",
    "href": "slides/04-slr-bootstrap-notes.html#computational-setup",
    "title": "SLR: Simulation-based inference",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables\nlibrary(kableExtra)  # also for neatly formatted tablesf\n\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#data-houses-in-duke-forest",
    "href": "slides/04-slr-bootstrap-notes.html#data-houses-in-duke-forest",
    "title": "SLR: Simulation-based inference",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#exploratory-data-analysis",
    "href": "slides/04-slr-bootstrap-notes.html#exploratory-data-analysis",
    "title": "SLR: Simulation-based inference",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\nCode\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sales price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#modeling",
    "href": "slides/04-slr-bootstrap-notes.html#modeling",
    "title": "SLR: Simulation-based inference",
    "section": "Modeling",
    "text": "Modeling\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2) #neatly format table to 2 digits\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n. . .\n\nIntercept: Duke Forest houses that are 0 square feet are expected to sell, for $116,652, on average.\n\nIs this interpretation meaningful?\n\nSlope: For each additional square foot, we expect the sales price of Duke Forest houses to be higher by $159, on average."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#from-sample-to-population",
    "href": "slides/04-slr-bootstrap-notes.html#from-sample-to-population",
    "title": "SLR: Simulation-based inference",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor each additional square foot, we expect the sales price of Duke Forest houses to be higher by $159, on average.\n\n\n\nThis estimate is valid for the single sample of 98 houses.\nBut what if we’re not interested quantifying the relationship between the size and price of a house in this single sample?\nWhat if we want to say something about the relationship between these variables for all houses in Duke Forest?"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#statistical-inference",
    "href": "slides/04-slr-bootstrap-notes.html#statistical-inference",
    "title": "SLR: Simulation-based inference",
    "section": "Statistical inference",
    "text": "Statistical inference\n\n\n\n\nStatistical inference provides methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be representative (ideally random) of the population we’re interested in\n\n\n\n\n\n\nImage source: Eugene Morgan © Penn State"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#inference-for-simple-linear-regression",
    "href": "slides/04-slr-bootstrap-notes.html#inference-for-simple-linear-regression",
    "title": "SLR: Simulation-based inference",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCompute a confidence interval for the slope, \\(\\beta_1\\)\nConduct a hypothesis test for the slope, \\(\\beta_1\\)\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can use the same methods for inference on the intercept, \\(\\beta_0\\), but we are often not interested in inference on the intercept in practice."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#confidence-interval",
    "href": "slides/04-slr-bootstrap-notes.html#confidence-interval",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence interval",
    "text": "Confidence interval\n\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#confidence-interval-for-the-slope-1",
    "href": "slides/04-slr-bootstrap-notes.html#confidence-interval-for-the-slope-1",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\nA confidence interval will allow us to make a statement like “For each additional square foot, the model predicts the sales price of Duke Forest houses to be higher, on average, by $159, plus or minus X dollars.”\n. . .\n\nShould X be $10? $100? $1000?\nIf we were to take another sample of 98 would we expect the slope calculated based on that sample to be exactly $159? Off by $10? $100? $1000?\nThe answer depends on how variable (from one sample to another sample) the sample statistic (the slope) is\nWe need a way to quantify the variability of the sample statistic"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#quantify-the-variability-of-the-slope",
    "href": "slides/04-slr-bootstrap-notes.html#quantify-the-variability-of-the-slope",
    "title": "SLR: Simulation-based inference",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor estimation\n\n\nTwo approaches:\n\nVia simulation (what we’ll do today)\nVia theoretical results and mathematical models (what we’ll do in an upcoming class)\n\nBootstrapping to quantify the variability of the slope for the purpose of estimation:\n\nBootstrap new samples from the original sample, i.e. take sample of size \\(n\\) with replacement\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-1",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-1",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 1",
    "text": "Bootstrap sample 1"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-2",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-2",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 2",
    "text": "Bootstrap sample 2"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-3",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-3",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 3",
    "text": "Bootstrap sample 3"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-4",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-4",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 4",
    "text": "Bootstrap sample 4"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-5",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-sample-5",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 5",
    "text": "Bootstrap sample 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n. . .\nso on and so forth…"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-samples-1---5",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-samples-1---5",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap samples 1 - 5",
    "text": "Bootstrap samples 1 - 5"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-samples-1---100",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-samples-1---100",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap samples 1 - 100",
    "text": "Bootstrap samples 1 - 100"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#slopes-of-bootstrap-samples",
    "href": "slides/04-slr-bootstrap-notes.html#slopes-of-bootstrap-samples",
    "title": "SLR: Simulation-based inference",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sales price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#slopes-of-bootstrap-samples-1",
    "href": "slides/04-slr-bootstrap-notes.html#slopes-of-bootstrap-samples-1",
    "title": "SLR: Simulation-based inference",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, we expect the sales price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-sampling-distribution",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-sampling-distribution",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sampling distribution",
    "text": "Bootstrap sampling distribution\nLet’s increase the number of bootstrap samples to 1000. The bootstrap sampling distribution is the distribution of estimated slopes given samples of size \\(n\\) (the same as our data)."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#bootstrap-sampling-distribution-1",
    "href": "slides/04-slr-bootstrap-notes.html#bootstrap-sampling-distribution-1",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sampling distribution",
    "text": "Bootstrap sampling distribution\n\nQuestionSubmit\n\n\n\n\n\nWhat is the approximate center of the bootstrap sampling distribution?\nThe standard deviation of the bootstrap sampling distribution is 32.319. What does this value represent?\n\n\n🔗 https://forms.office.com/r/naWVT11vBu"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#confidence-level",
    "href": "slides/04-slr-bootstrap-notes.html#confidence-level",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence level",
    "text": "Confidence level\n\nHow confident are you that the true slope is between $0 and $250? How about $150 and $170? How about $90 and $210?"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#confidence-interval-1",
    "href": "slides/04-slr-bootstrap-notes.html#confidence-interval-1",
    "title": "SLR: Simulation-based inference",
    "section": "95% confidence interval",
    "text": "95% confidence interval\n\n\n\n\n\n\n\n\n\n\n\nA 95% confidence interval is bounded by the middle 95% of the bootstrap distribution\nWe are 95% confident that for each additional square foot, sales price of Duke Forest houses to be higher, on average, by $90.97 to $214.93."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#computing-the-ci-for-the-slope-i",
    "href": "slides/04-slr-bootstrap-notes.html#computing-the-ci-for-the-slope-i",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope I",
    "text": "Computing the CI for the slope I\nCalculate the observed slope:\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#computing-the-ci-for-the-slope-ii",
    "href": "slides/04-slr-bootstrap-notes.html#computing-the-ci-for-the-slope-ii",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope II",
    "text": "Computing the CI for the slope II\nTake 100 bootstrap samples and fit models to each one:\n\n\n\nset.seed(1120)\n\nboot_fits &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 100, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   47819.\n 2         1 area          191.\n 3         2 intercept  144645.\n 4         2 area          134.\n 5         3 intercept  114008.\n 6         3 area          161.\n 7         4 intercept  100639.\n 8         4 area          166.\n 9         5 intercept  215264.\n10         5 area          125.\n# ℹ 190 more rows\n\n\n\nUse ~ 100 bootstrap samples to write code, and 1000+ samples for final analysis results."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#computing-the-ci-for-the-slope-iii",
    "href": "slides/04-slr-bootstrap-notes.html#computing-the-ci-for-the-slope-iii",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope III",
    "text": "Computing the CI for the slope III\nPercentile method: Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\" #default method\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#precision-vs.-accuracy",
    "href": "slides/04-slr-bootstrap-notes.html#precision-vs.-accuracy",
    "title": "SLR: Simulation-based inference",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n\n. . ."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#precision-vs.-accuracy-1",
    "href": "slides/04-slr-bootstrap-notes.html#precision-vs.-accuracy-1",
    "title": "SLR: Simulation-based inference",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nHow can we get best of both worlds – high precision and high accuracy?\n\n\n. . .\n\nConsider a 90%, 95%, and 99% confidence interval.\n\nWhich interval is most precise?\nWhich is most accurate?"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#changing-confidence-level",
    "href": "slides/04-slr-bootstrap-notes.html#changing-confidence-level",
    "title": "SLR: Simulation-based inference",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.90, type = \"percentile\"\n) \n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          104.     212.\n2 intercept  -24380.  256730.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          56.3     226.\n2 intercept -61950.   370395."
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#recap",
    "href": "slides/04-slr-bootstrap-notes.html#recap",
    "title": "SLR: Simulation-based inference",
    "section": "Recap",
    "text": "Recap\n\nPopulation: Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. (population size = \\(N\\))\nSample: Subset of the population, ideally random and representative (sample size = \\(n\\))\nSample statistic \\(\\ne\\) population parameter, but if the sample is good, it can be a good estimate\nStatistical inference: Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\nWe report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\nSince we can’t continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability"
  },
  {
    "objectID": "slides/04-slr-bootstrap-notes.html#for-next-class",
    "href": "slides/04-slr-bootstrap-notes.html#for-next-class",
    "title": "SLR: Simulation-based inference",
    "section": "For next class",
    "text": "For next class\n\nSimulation-based inference: Permutation tests\nComplete Lecture 05 prepare"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#announcements",
    "href": "slides/04-slr-bootstrap.html#announcements",
    "title": "SLR: Simulation-based inference",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01 due Tuesday, January 27 at 11:59pm\n\nReleased after class today\nAI Disclosure"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#topics",
    "href": "slides/04-slr-bootstrap.html#topics",
    "title": "SLR: Simulation-based inference",
    "section": "Topics",
    "text": "Topics\n\nIntroduce inference for a population slope\nFind range of plausible values for the slope using bootstrap confidence intervals"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#computational-setup",
    "href": "slides/04-slr-bootstrap.html#computational-setup",
    "title": "SLR: Simulation-based inference",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables\nlibrary(kableExtra)  # also for neatly formatted tablesf\n\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#data-houses-in-duke-forest",
    "href": "slides/04-slr-bootstrap.html#data-houses-in-duke-forest",
    "title": "SLR: Simulation-based inference",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#exploratory-data-analysis",
    "href": "slides/04-slr-bootstrap.html#exploratory-data-analysis",
    "title": "SLR: Simulation-based inference",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\nCode\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sales price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#modeling",
    "href": "slides/04-slr-bootstrap.html#modeling",
    "title": "SLR: Simulation-based inference",
    "section": "Modeling",
    "text": "Modeling\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2) #neatly format table to 2 digits\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\nIntercept: Duke Forest houses that are 0 square feet are expected to sell, for $116,652, on average.\n\nIs this interpretation meaningful?\n\nSlope: For each additional square foot, we expect the sales price of Duke Forest houses to be higher by $159, on average."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#from-sample-to-population",
    "href": "slides/04-slr-bootstrap.html#from-sample-to-population",
    "title": "SLR: Simulation-based inference",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor each additional square foot, we expect the sales price of Duke Forest houses to be higher by $159, on average.\n\n\n\nThis estimate is valid for the single sample of 98 houses.\nBut what if we’re not interested quantifying the relationship between the size and price of a house in this single sample?\nWhat if we want to say something about the relationship between these variables for all houses in Duke Forest?"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#statistical-inference",
    "href": "slides/04-slr-bootstrap.html#statistical-inference",
    "title": "SLR: Simulation-based inference",
    "section": "Statistical inference",
    "text": "Statistical inference\n\n\n\n\nStatistical inference provides methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be representative (ideally random) of the population we’re interested in\n\n\n\n\n\n\nImage source: Eugene Morgan © Penn State"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#inference-for-simple-linear-regression",
    "href": "slides/04-slr-bootstrap.html#inference-for-simple-linear-regression",
    "title": "SLR: Simulation-based inference",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCompute a confidence interval for the slope, \\(\\beta_1\\)\nConduct a hypothesis test for the slope, \\(\\beta_1\\)\n\n\n\n\n\n\n\n\nNote\n\n\nWe can use the same methods for inference on the intercept, \\(\\beta_0\\), but we are often not interested in inference on the intercept in practice."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#confidence-interval",
    "href": "slides/04-slr-bootstrap.html#confidence-interval",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence interval",
    "text": "Confidence interval\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#confidence-interval-for-the-slope-1",
    "href": "slides/04-slr-bootstrap.html#confidence-interval-for-the-slope-1",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\nA confidence interval will allow us to make a statement like “For each additional square foot, the model predicts the sales price of Duke Forest houses to be higher, on average, by $159, plus or minus X dollars.”\n\n\nShould X be $10? $100? $1000?\nIf we were to take another sample of 98 would we expect the slope calculated based on that sample to be exactly $159? Off by $10? $100? $1000?\nThe answer depends on how variable (from one sample to another sample) the sample statistic (the slope) is\nWe need a way to quantify the variability of the sample statistic"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#quantify-the-variability-of-the-slope",
    "href": "slides/04-slr-bootstrap.html#quantify-the-variability-of-the-slope",
    "title": "SLR: Simulation-based inference",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor estimation\n\nTwo approaches:\n\nVia simulation (what we’ll do today)\nVia theoretical results and mathematical models (what we’ll do in an upcoming class)\n\nBootstrapping to quantify the variability of the slope for the purpose of estimation:\n\nBootstrap new samples from the original sample, i.e. take sample of size \\(n\\) with replacement\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-1",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-1",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 1",
    "text": "Bootstrap sample 1"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-2",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-2",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 2",
    "text": "Bootstrap sample 2"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-3",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-3",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 3",
    "text": "Bootstrap sample 3"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-4",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-4",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 4",
    "text": "Bootstrap sample 4"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-5",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-5",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 5",
    "text": "Bootstrap sample 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nso on and so forth…"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-samples-1---5",
    "href": "slides/04-slr-bootstrap.html#bootstrap-samples-1---5",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap samples 1 - 5",
    "text": "Bootstrap samples 1 - 5"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-samples-1---100",
    "href": "slides/04-slr-bootstrap.html#bootstrap-samples-1---100",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap samples 1 - 100",
    "text": "Bootstrap samples 1 - 100"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#slopes-of-bootstrap-samples",
    "href": "slides/04-slr-bootstrap.html#slopes-of-bootstrap-samples",
    "title": "SLR: Simulation-based inference",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sales price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#slopes-of-bootstrap-samples-1",
    "href": "slides/04-slr-bootstrap.html#slopes-of-bootstrap-samples-1",
    "title": "SLR: Simulation-based inference",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, we expect the sales price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sampling-distribution",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sampling-distribution",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sampling distribution",
    "text": "Bootstrap sampling distribution\nLet’s increase the number of bootstrap samples to 1000. The bootstrap sampling distribution is the distribution of estimated slopes given samples of size \\(n\\) (the same as our data)."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sampling-distribution-1",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sampling-distribution-1",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sampling distribution",
    "text": "Bootstrap sampling distribution\n\nQuestionSubmit\n\n\n\n\n\nWhat is the approximate center of the bootstrap sampling distribution?\nThe standard deviation of the bootstrap sampling distribution is 32.319. What does this value represent?\n\n\n🔗 https://forms.office.com/r/naWVT11vBu"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#confidence-level",
    "href": "slides/04-slr-bootstrap.html#confidence-level",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence level",
    "text": "Confidence level\n\nHow confident are you that the true slope is between $0 and $250? How about $150 and $170? How about $90 and $210?"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#confidence-interval-1",
    "href": "slides/04-slr-bootstrap.html#confidence-interval-1",
    "title": "SLR: Simulation-based inference",
    "section": "95% confidence interval",
    "text": "95% confidence interval\n\n\nA 95% confidence interval is bounded by the middle 95% of the bootstrap distribution\nWe are 95% confident that for each additional square foot, sales price of Duke Forest houses to be higher, on average, by $90.97 to $214.93."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-i",
    "href": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-i",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope I",
    "text": "Computing the CI for the slope I\nCalculate the observed slope:\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-ii",
    "href": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-ii",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope II",
    "text": "Computing the CI for the slope II\nTake 100 bootstrap samples and fit models to each one:\n\n\n\nset.seed(1120)\n\nboot_fits &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 100, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   47819.\n 2         1 area          191.\n 3         2 intercept  144645.\n 4         2 area          134.\n 5         3 intercept  114008.\n 6         3 area          161.\n 7         4 intercept  100639.\n 8         4 area          166.\n 9         5 intercept  215264.\n10         5 area          125.\n# ℹ 190 more rows\n\n\n\nUse ~ 100 bootstrap samples to write code, and 1000+ samples for final analysis results."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-iii",
    "href": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-iii",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope III",
    "text": "Computing the CI for the slope III\nPercentile method: Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\" #default method\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#precision-vs.-accuracy",
    "href": "slides/04-slr-bootstrap.html#precision-vs.-accuracy",
    "title": "SLR: Simulation-based inference",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#precision-vs.-accuracy-1",
    "href": "slides/04-slr-bootstrap.html#precision-vs.-accuracy-1",
    "title": "SLR: Simulation-based inference",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nHow can we get best of both worlds – high precision and high accuracy?\n\n\n\n\nConsider a 90%, 95%, and 99% confidence interval.\n\nWhich interval is most precise?\nWhich is most accurate?"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#changing-confidence-level",
    "href": "slides/04-slr-bootstrap.html#changing-confidence-level",
    "title": "SLR: Simulation-based inference",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.90, type = \"percentile\"\n) \n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          104.     212.\n2 intercept  -24380.  256730.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          56.3     226.\n2 intercept -61950.   370395."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#recap",
    "href": "slides/04-slr-bootstrap.html#recap",
    "title": "SLR: Simulation-based inference",
    "section": "Recap",
    "text": "Recap\n\nPopulation: Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. (population size = \\(N\\))\nSample: Subset of the population, ideally random and representative (sample size = \\(n\\))\nSample statistic \\(\\ne\\) population parameter, but if the sample is good, it can be a good estimate\nStatistical inference: Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\nWe report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\nSince we can’t continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#for-next-class",
    "href": "slides/04-slr-bootstrap.html#for-next-class",
    "title": "SLR: Simulation-based inference",
    "section": "For next class",
    "text": "For next class\n\nSimulation-based inference: Permutation tests\nComplete Lecture 05 prepare"
  },
  {
    "objectID": "slides/lab-00.html#meet-your-lab-ta",
    "href": "slides/lab-00.html#meet-your-lab-ta",
    "title": "Welcome to STA 210 labs!",
    "section": "Meet your lab TA!",
    "text": "Meet your lab TA!"
  },
  {
    "objectID": "slides/lab-00.html#meet-your-classmates",
    "href": "slides/lab-00.html#meet-your-classmates",
    "title": "Welcome to STA 210 labs!",
    "section": "Meet your classmates!",
    "text": "Meet your classmates!\n\nPlease share the following with the class:\n\nName\nYear in school\nMajor / academic interests\nOne boring fact\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/lab-00.html#what-to-expect-in-lab",
    "href": "slides/lab-00.html#what-to-expect-in-lab",
    "title": "Welcome to STA 210 labs!",
    "section": "What to expect in lab",
    "text": "What to expect in lab\n\nIntroduction to the lab assignment (~ 5 - 10 minutes)\nReview lecture content, as needed (~ 10 minutes)\nWork on the lab assignment (individual in the beginning and with teams for the remainder of the semester)\nStarting with Lab 01, you will find the starter materials for lab in your repo in the course GitHub organization."
  },
  {
    "objectID": "slides/lab-00.html#todays-lab",
    "href": "slides/lab-00.html#todays-lab",
    "title": "Welcome to STA 210 labs!",
    "section": "Today’s lab",
    "text": "Today’s lab\nThe rest of the today’s lab is focused on setting up the computing for the course and completing the class survey. Click the link below for the Lab 00 instructions. The instructions are available on the course website.\nYour TA will demonstrate the steps to set up computing and interact with RStudio and GitHub.\n\n🔗 https://sta210-sp26.github.io/labs/lab-00.html"
  },
  {
    "objectID": "slides/01-welcome-notes.html",
    "href": "slides/01-welcome-notes.html",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "Education and career journey\n\nBS in Math and MS in Statistics from University of Tennessee\nStatistician at Capital One\nPhD in Statistics from University of Virginia\nAssociate Professor of the Practice, Department of Statistical Science at Duke\n\nWork focuses on statistics education and inclusive teaching practices\nCo-leader of the Bass Connections team Mental Health and the Justice System in Durham County\nMom of 3-year-old twins 🙂 (and one grumpy cat)\n\n\n\n\n\n\nAdeli Hutton (PhD): Lab 02 leader\nShane Rybacki (PhD): Lab 01 leader\n\n\n\n\n\nFind a partner and share the following:\n\nName\nYear\nMajor or academic interests\nHighlight / something you enjoyed during winter break\n\nEveryone will introduce their partner to the class.\n\n\n\n\n\nIntroduction to the course\nSyllabus activity\n\n\n\n\n\n\n\nSource: Introduction to Regression Analysis\n\n\n\n\n\n\n\nIn statistical modeling, regression analysis is a statistical method for estimating the relationship between a dependent variable (often called the outcome or response variable, or a label in machine learning parlance) and one or more independent variables (often called regressors, predictors, covariates, explanatory variables or features).[1][2]\n\nSource: Wikipedia (January 2026)\n\n\n\n\n\n\n\n\n\n\n\nRodgers, J. L. (2024). Reading Harry Potter in French: Using Regression to Evaluate Foreign Language Vocabulary Learning by an Old Guy. CHANCE, 37(3), 13–21.\n\n\n\n\n\n\n\n\n\\[\n\\text{Lookups} = 23.0 - 0.04 \\times \\text{Page Number}\n\\]\n\n\nRodgers, J. L. (2024). Reading Harry Potter in French: Using Regression to Evaluate Foreign Language Vocabulary Learning by an Old Guy. CHANCE, 37(3), 13–21.\n\n\n\nPew Research Center conducted the 2025 What Web Browsing Data Tells Us About How AI Appears Online.\n\n\n\nSource: Pew Research\n\n\n\n\n\nChapekis, A., Lieb, A., Shah, S., Smith, A. (2025) What Web Browsing Data Tells Us about How AI Appears Online. Pew Research Center.https://www.pewresearch.org/data-labs/2025/05/23/what-web-browsing-data-tells-us-about-how-ai-appears-online/\n\n\n\n\nResearchers used logistic regression to classify online articles in which AI was a central focus versus an incidental mention.\n\n\n\n\n\nSource: Pew Research Center\n\n\n\n\n\\[\n\\log\\Big(\\frac{\\pi}{1-\\pi}\\Big) = \\beta_0 + \\beta_1X_1 + \\dots + \\beta_pX_p\n\\]"
  },
  {
    "objectID": "slides/01-welcome-notes.html#meet-prof.-tackett",
    "href": "slides/01-welcome-notes.html#meet-prof.-tackett",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "Education and career journey\n\nBS in Math and MS in Statistics from University of Tennessee\nStatistician at Capital One\nPhD in Statistics from University of Virginia\nAssociate Professor of the Practice, Department of Statistical Science at Duke\n\nWork focuses on statistics education and inclusive teaching practices\nCo-leader of the Bass Connections team Mental Health and the Justice System in Durham County\nMom of 3-year-old twins 🙂 (and one grumpy cat)"
  },
  {
    "objectID": "slides/01-welcome-notes.html#meet-the-teaching-assistants-tas",
    "href": "slides/01-welcome-notes.html#meet-the-teaching-assistants-tas",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "Adeli Hutton (PhD): Lab 02 leader\nShane Rybacki (PhD): Lab 01 leader"
  },
  {
    "objectID": "slides/01-welcome-notes.html#meet-your-classmates",
    "href": "slides/01-welcome-notes.html#meet-your-classmates",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "Find a partner and share the following:\n\nName\nYear\nMajor or academic interests\nHighlight / something you enjoyed during winter break\n\nEveryone will introduce their partner to the class."
  },
  {
    "objectID": "slides/01-welcome-notes.html#topics",
    "href": "slides/01-welcome-notes.html#topics",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "Introduction to the course\nSyllabus activity"
  },
  {
    "objectID": "slides/01-welcome-notes.html#data-science-workflow",
    "href": "slides/01-welcome-notes.html#data-science-workflow",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "Source: Introduction to Regression Analysis"
  },
  {
    "objectID": "slides/01-welcome-notes.html#what-is-regression-analysis",
    "href": "slides/01-welcome-notes.html#what-is-regression-analysis",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "In statistical modeling, regression analysis is a statistical method for estimating the relationship between a dependent variable (often called the outcome or response variable, or a label in machine learning parlance) and one or more independent variables (often called regressors, predictors, covariates, explanatory variables or features).[1][2]\n\nSource: Wikipedia (January 2026)"
  },
  {
    "objectID": "slides/01-welcome-notes.html#linear-regression-in-practice",
    "href": "slides/01-welcome-notes.html#linear-regression-in-practice",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "Rodgers, J. L. (2024). Reading Harry Potter in French: Using Regression to Evaluate Foreign Language Vocabulary Learning by an Old Guy. CHANCE, 37(3), 13–21."
  },
  {
    "objectID": "slides/01-welcome-notes.html#example-reading-harry-potter",
    "href": "slides/01-welcome-notes.html#example-reading-harry-potter",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "\\[\n\\text{Lookups} = 23.0 - 0.04 \\times \\text{Page Number}\n\\]\n\n\nRodgers, J. L. (2024). Reading Harry Potter in French: Using Regression to Evaluate Foreign Language Vocabulary Learning by an Old Guy. CHANCE, 37(3), 13–21."
  },
  {
    "objectID": "slides/01-welcome-notes.html#logistic-regression-in-practice",
    "href": "slides/01-welcome-notes.html#logistic-regression-in-practice",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "Pew Research Center conducted the 2025 What Web Browsing Data Tells Us About How AI Appears Online.\n\n\n\nSource: Pew Research\n\n\n\n\n\nChapekis, A., Lieb, A., Shah, S., Smith, A. (2025) What Web Browsing Data Tells Us about How AI Appears Online. Pew Research Center.https://www.pewresearch.org/data-labs/2025/05/23/what-web-browsing-data-tells-us-about-how-ai-appears-online/"
  },
  {
    "objectID": "slides/01-welcome-notes.html#example-ai-mentions",
    "href": "slides/01-welcome-notes.html#example-ai-mentions",
    "title": "Welcome to STA 210!",
    "section": "",
    "text": "Researchers used logistic regression to classify online articles in which AI was a central focus versus an incidental mention.\n\n\n\n\n\nSource: Pew Research Center\n\n\n\n\n\\[\n\\log\\Big(\\frac{\\pi}{1-\\pi}\\Big) = \\beta_0 + \\beta_1X_1 + \\dots + \\beta_pX_p\n\\]"
  },
  {
    "objectID": "slides/01-welcome-notes.html#what-is-sta-210",
    "href": "slides/01-welcome-notes.html#what-is-sta-210",
    "title": "Welcome to STA 210!",
    "section": "What is STA 210?",
    "text": "What is STA 210?\nLearn how to use linear and and logistic regression models to analyze multivariable relationships and answer questions about real-world phenomena using a data-driven approach.\nThis course emphasizes application over mathematical theory.\nPre-requisites\n100-level Statistical Science course or Statistical Science 230, 231, or 240L\n. . .\n\n\n\n\n\n\nNote\n\n\n\nIf you are interested in the theoretical aspects of regression and/or becoming a statistics major, STA 221 - Regression Analysis: Theory and Applications may be a better fit. Come talk with me after class!"
  },
  {
    "objectID": "slides/01-welcome-notes.html#course-learning-objectives",
    "href": "slides/01-welcome-notes.html#course-learning-objectives",
    "title": "Welcome to STA 210!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze real-world data to answer questions about multivariable relationships.\nuse R to fit and evaluate linear and logistic regression models.\nassess whether a proposed model is appropriate and describe its limitations.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions."
  },
  {
    "objectID": "slides/01-welcome-notes.html#course-topics",
    "href": "slides/01-welcome-notes.html#course-topics",
    "title": "Welcome to STA 210!",
    "section": "Course topics",
    "text": "Course topics\n\n\n\n\nLinear regression\n\nCoefficient estimation and interpretation\nPrediction\nInference\nModel evaluation\nModel assumptions and diagnostics\nTypes of predictors\nModel comparison + cross validation\n\n\n\n\n\n\nLogistic regression\n\nCoefficient estimation and interpretation\nPrediction\nModel evaluation\nInference\n\n\n\n\n\nSpecial topics\n\n\n\n\n\nGeneral topics\n\nComputing using R and GitHub\nPresenting statistical results\nCollaboration and teamwork\nEthics"
  },
  {
    "objectID": "slides/01-welcome-notes.html#course-toolkit",
    "href": "slides/01-welcome-notes.html#course-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Course toolkit",
    "text": "Course toolkit\n\nWebsite: https://sta210-sp26.github.io\n\nCentral hub for the course!\nTour of the website\n\nCanvas: https://canvas.duke.edu/courses/68771\n\nOffice hours\nGradebook\nAnnouncements\nGradescope\nEd Discussion\n\nGitHub: https://github.com/sta210-sp26\n\nDistribute assignments\nPlatform for version control and collaboration"
  },
  {
    "objectID": "slides/01-welcome-notes.html#computing-toolkit",
    "href": "slides/01-welcome-notes.html#computing-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Computing toolkit",
    "text": "Computing toolkit\n\n\n\n\n\n\n\n\n\n\n\nAll analyses using R, a statistical programming language\nWrite reproducible reports in Quarto\nAccess RStudio through Docker Containers (use containers labeled STA221)\n\n\n\n\n\n\n\n\n\n\n\n\nAccess assignments\nFacilitates version control and collaboration\nAll work in STA 210 course organization"
  },
  {
    "objectID": "slides/01-welcome-notes.html#classroom-community",
    "href": "slides/01-welcome-notes.html#classroom-community",
    "title": "Welcome to STA 210!",
    "section": "Classroom community",
    "text": "Classroom community\n\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know.\nPlease let me know your preferred pronouns, if you are comfortable sharing.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said or done in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/01-welcome-notes.html#accessibility",
    "href": "slides/01-welcome-notes.html#accessibility",
    "title": "Welcome to STA 210!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nIf you have documented accommodations from SDAO, please send the documentation as soon as possible.\nI am committed to making all course activities and materials accessible. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/01-welcome-notes.html#syllabus-activity",
    "href": "slides/01-welcome-notes.html#syllabus-activity",
    "title": "Welcome to STA 210!",
    "section": "Syllabus activity",
    "text": "Syllabus activity\n\n\nIntroduce yourself to your group members.\nChoose a reporter. This person will share the group’s summary with the class.\nRead the portion of the syllabus assigned to your group.\nDiscuss the key points and questions you my have.\nThe reporter will share a summary with the class."
  },
  {
    "objectID": "slides/01-welcome-notes.html#syllabus-activity-assignments",
    "href": "slides/01-welcome-notes.html#syllabus-activity-assignments",
    "title": "Welcome to STA 210!",
    "section": "Syllabus activity assignments",
    "text": "Syllabus activity assignments\n\nGroup 1: Labs\nGroup 2: Homework\nGroup 3: Exams\nGroup 4: Participation\nGroup 5: Academic honesty (except AI policy)\nGroup 6: AI policy\nGroup 7: Late work policy and waiver for extenuating circumstances"
  },
  {
    "objectID": "slides/01-welcome-notes.html#syllabus-activity-report-out",
    "href": "slides/01-welcome-notes.html#syllabus-activity-report-out",
    "title": "Welcome to STA 210!",
    "section": "Syllabus activity report out",
    "text": "Syllabus activity report out\n\n\nGroup 1: Labs\nGroup 2: Homework\nGroup 3: Exams\nGroup 4: Participation\nGroup 5: Academic honesty (except AI policy)\nGroup 6: AI policy\nGroup 7: Late work policy and waiver for extenuating circumstances"
  },
  {
    "objectID": "slides/01-welcome-notes.html#grading",
    "href": "slides/01-welcome-notes.html#grading",
    "title": "Welcome to STA 210!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nLabs\n10%\n\n\nHomework\n15%\n\n\nExam 01\n25%\n\n\nExam 02\n25%\n\n\nFinal project\n20%\n\n\nParticipation\n5%"
  },
  {
    "objectID": "slides/01-welcome-notes.html#five-tips-for-success-in-sta-210",
    "href": "slides/01-welcome-notes.html#five-tips-for-success-in-sta-210",
    "title": "Welcome to STA 210!",
    "section": "Five tips for success in STA 210",
    "text": "Five tips for success in STA 210\n\nComplete all prepare readings and tasks before class.\nActively participate and engage in lectures and labs.\nAsk questions frequently during lecture, in office hours, on Ed Discussion, and among your classmates.\nComplete all homework and labs, asking yourself “why” questions as you go through the steps to complete each exercise.\nStay current with the course material, as each new concept builds on previous ones."
  },
  {
    "objectID": "slides/01-welcome-notes.html#minute-paper",
    "href": "slides/01-welcome-notes.html#minute-paper",
    "title": "Welcome to STA 210!",
    "section": "Minute paper",
    "text": "Minute paper\nSubmit your response to the question below. The form will record your NetID. 🔗 https://forms.office.com/r/r6fsAxjCqQ"
  },
  {
    "objectID": "slides/01-welcome-notes.html#before-next-class",
    "href": "slides/01-welcome-notes.html#before-next-class",
    "title": "Welcome to STA 210!",
    "section": "Before next class",
    "text": "Before next class\n\nComplete Lecture 02 Prepare\nReview the syllabus\nLabs start on Monday, January 12\nOffice hours start on Monday, January 12"
  },
  {
    "objectID": "slides/01-welcome.html#meet-prof.-tackett",
    "href": "slides/01-welcome.html#meet-prof.-tackett",
    "title": "Welcome to STA 210!",
    "section": "Meet Prof. Tackett!",
    "text": "Meet Prof. Tackett!\n\nEducation and career journey\n\nBS in Math and MS in Statistics from University of Tennessee\nStatistician at Capital One\nPhD in Statistics from University of Virginia\nAssociate Professor of the Practice, Department of Statistical Science at Duke\n\nWork focuses on statistics education and inclusive teaching practices\nCo-leader of the Bass Connections team Mental Health and the Justice System in Durham County\nMom of 3-year-old twins 🙂 (and one grumpy cat)"
  },
  {
    "objectID": "slides/01-welcome.html#meet-the-teaching-assistants-tas",
    "href": "slides/01-welcome.html#meet-the-teaching-assistants-tas",
    "title": "Welcome to STA 210!",
    "section": "Meet the Teaching Assistants (TAs)!",
    "text": "Meet the Teaching Assistants (TAs)!\n\nAdeli Hutton (PhD): Lab 02 leader\nShane Rybacki (PhD): Lab 01 leader"
  },
  {
    "objectID": "slides/01-welcome.html#meet-your-classmates",
    "href": "slides/01-welcome.html#meet-your-classmates",
    "title": "Welcome to STA 210!",
    "section": "Meet your classmates",
    "text": "Meet your classmates\n\nFind a partner and share the following:\n\nName\nYear\nMajor or academic interests\nHighlight / something you enjoyed during winter break\n\nEveryone will introduce their partner to the class."
  },
  {
    "objectID": "slides/01-welcome.html#topics",
    "href": "slides/01-welcome.html#topics",
    "title": "Welcome to STA 210!",
    "section": "Topics",
    "text": "Topics\n\nIntroduction to the course\nSyllabus activity"
  },
  {
    "objectID": "slides/01-welcome.html#data-science-workflow",
    "href": "slides/01-welcome.html#data-science-workflow",
    "title": "Welcome to STA 210!",
    "section": "Data science workflow",
    "text": "Data science workflow\n\nSource: Introduction to Regression Analysis"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-regression-analysis",
    "href": "slides/01-welcome.html#what-is-regression-analysis",
    "title": "Welcome to STA 210!",
    "section": "What is regression analysis?",
    "text": "What is regression analysis?\n\n\nIn statistical modeling, regression analysis is a statistical method for estimating the relationship between a dependent variable (often called the outcome or response variable, or a label in machine learning parlance) and one or more independent variables (often called regressors, predictors, covariates, explanatory variables or features).[1][2]\n\nSource: Wikipedia (January 2026)"
  },
  {
    "objectID": "slides/01-welcome.html#linear-regression-in-practice",
    "href": "slides/01-welcome.html#linear-regression-in-practice",
    "title": "Welcome to STA 210!",
    "section": "Linear regression in practice",
    "text": "Linear regression in practice\n\n\n\n\n\n\n\nRodgers, J. L. (2024). Reading Harry Potter in French: Using Regression to Evaluate Foreign Language Vocabulary Learning by an Old Guy. CHANCE, 37(3), 13–21."
  },
  {
    "objectID": "slides/01-welcome.html#example-reading-harry-potter",
    "href": "slides/01-welcome.html#example-reading-harry-potter",
    "title": "Welcome to STA 210!",
    "section": "Example: Reading Harry Potter",
    "text": "Example: Reading Harry Potter\n\n\n\n\n\n\\[\n\\text{Lookups} = 23.0 - 0.04 \\times \\text{Page Number}\n\\]\n\n\nRodgers, J. L. (2024). Reading Harry Potter in French: Using Regression to Evaluate Foreign Language Vocabulary Learning by an Old Guy. CHANCE, 37(3), 13–21."
  },
  {
    "objectID": "slides/01-welcome.html#logistic-regression-in-practice",
    "href": "slides/01-welcome.html#logistic-regression-in-practice",
    "title": "Welcome to STA 210!",
    "section": "Logistic regression in practice",
    "text": "Logistic regression in practice\nPew Research Center conducted the 2025 What Web Browsing Data Tells Us About How AI Appears Online.\n\n\n\nSource: Pew Research\n\n\n\n\n\nChapekis, A., Lieb, A., Shah, S., Smith, A. (2025) What Web Browsing Data Tells Us about How AI Appears Online. Pew Research Center.https://www.pewresearch.org/data-labs/2025/05/23/what-web-browsing-data-tells-us-about-how-ai-appears-online/"
  },
  {
    "objectID": "slides/01-welcome.html#example-ai-mentions",
    "href": "slides/01-welcome.html#example-ai-mentions",
    "title": "Welcome to STA 210!",
    "section": "Example: AI mentions",
    "text": "Example: AI mentions\nResearchers used logistic regression to classify online articles in which AI was a central focus versus an incidental mention.\n\n\n\n\n\nSource: Pew Research Center\n\n\n\n\n\\[\n\\log\\Big(\\frac{\\pi}{1-\\pi}\\Big) = \\beta_0 + \\beta_1X_1 + \\dots + \\beta_pX_p\n\\]"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-sta-210",
    "href": "slides/01-welcome.html#what-is-sta-210",
    "title": "Welcome to STA 210!",
    "section": "What is STA 210?",
    "text": "What is STA 210?\nLearn how to use linear and and logistic regression models to analyze multivariable relationships and answer questions about real-world phenomena using a data-driven approach.\nThis course emphasizes application over mathematical theory.\nPre-requisites\n100-level Statistical Science course or Statistical Science 230, 231, or 240L\n\n\n\n\n\n\n\nNote\n\n\nIf you are interested in the theoretical aspects of regression and/or becoming a statistics major, STA 221 - Regression Analysis: Theory and Applications may be a better fit. Come talk with me after class!"
  },
  {
    "objectID": "slides/01-welcome.html#course-learning-objectives",
    "href": "slides/01-welcome.html#course-learning-objectives",
    "title": "Welcome to STA 210!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze real-world data to answer questions about multivariable relationships.\nuse R to fit and evaluate linear and logistic regression models.\nassess whether a proposed model is appropriate and describe its limitations.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions."
  },
  {
    "objectID": "slides/01-welcome.html#course-topics",
    "href": "slides/01-welcome.html#course-topics",
    "title": "Welcome to STA 210!",
    "section": "Course topics",
    "text": "Course topics\n\n\n\nLinear regression\n\nCoefficient estimation and interpretation\nPrediction\nInference\nModel evaluation\nModel assumptions and diagnostics\nTypes of predictors\nModel comparison + cross validation\n\n\n\n\nLogistic regression\n\nCoefficient estimation and interpretation\nPrediction\nModel evaluation\nInference\n\n\n\nSpecial topics\n\n\n\nGeneral topics\n\nComputing using R and GitHub\nPresenting statistical results\nCollaboration and teamwork\nEthics"
  },
  {
    "objectID": "slides/01-welcome.html#course-toolkit",
    "href": "slides/01-welcome.html#course-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Course toolkit",
    "text": "Course toolkit\n\nWebsite: https://sta210-sp26.github.io\n\nCentral hub for the course!\nTour of the website\n\nCanvas: https://canvas.duke.edu/courses/68771\n\nOffice hours\nGradebook\nAnnouncements\nGradescope\nEd Discussion\n\nGitHub: https://github.com/sta210-sp26\n\nDistribute assignments\nPlatform for version control and collaboration"
  },
  {
    "objectID": "slides/01-welcome.html#computing-toolkit",
    "href": "slides/01-welcome.html#computing-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Computing toolkit",
    "text": "Computing toolkit\n\n\n\n\n\n\n\n\n\n\n\nAll analyses using R, a statistical programming language\nWrite reproducible reports in Quarto\nAccess RStudio through Docker Containers (use containers labeled STA221)\n\n\n\n\n\n\n\n\n\n\n\n\nAccess assignments\nFacilitates version control and collaboration\nAll work in STA 210 course organization"
  },
  {
    "objectID": "slides/01-welcome.html#classroom-community",
    "href": "slides/01-welcome.html#classroom-community",
    "title": "Welcome to STA 210!",
    "section": "Classroom community",
    "text": "Classroom community\n\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know.\nPlease let me know your preferred pronouns, if you are comfortable sharing.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said or done in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/01-welcome.html#accessibility",
    "href": "slides/01-welcome.html#accessibility",
    "title": "Welcome to STA 210!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nIf you have documented accommodations from SDAO, please send the documentation as soon as possible.\nI am committed to making all course activities and materials accessible. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity",
    "href": "slides/01-welcome.html#syllabus-activity",
    "title": "Welcome to STA 210!",
    "section": "Syllabus activity",
    "text": "Syllabus activity\n\n\nIntroduce yourself to your group members.\nChoose a reporter. This person will share the group’s summary with the class.\nRead the portion of the syllabus assigned to your group.\nDiscuss the key points and questions you my have.\nThe reporter will share a summary with the class."
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity-assignments",
    "href": "slides/01-welcome.html#syllabus-activity-assignments",
    "title": "Welcome to STA 210!",
    "section": "Syllabus activity assignments",
    "text": "Syllabus activity assignments\n\nGroup 1: Labs\nGroup 2: Homework\nGroup 3: Exams\nGroup 4: Participation\nGroup 5: Academic honesty (except AI policy)\nGroup 6: AI policy\nGroup 7: Late work policy and waiver for extenuating circumstances"
  },
  {
    "objectID": "slides/01-welcome.html#syllabus-activity-report-out",
    "href": "slides/01-welcome.html#syllabus-activity-report-out",
    "title": "Welcome to STA 210!",
    "section": "Syllabus activity report out",
    "text": "Syllabus activity report out\n\nGroup 1: Labs\nGroup 2: Homework\nGroup 3: Exams\nGroup 4: Participation\nGroup 5: Academic honesty (except AI policy)\nGroup 6: AI policy\nGroup 7: Late work policy and waiver for extenuating circumstances"
  },
  {
    "objectID": "slides/01-welcome.html#grading",
    "href": "slides/01-welcome.html#grading",
    "title": "Welcome to STA 210!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nLabs\n10%\n\n\nHomework\n15%\n\n\nExam 01\n25%\n\n\nExam 02\n25%\n\n\nFinal project\n20%\n\n\nParticipation\n5%"
  },
  {
    "objectID": "slides/01-welcome.html#five-tips-for-success-in-sta-210",
    "href": "slides/01-welcome.html#five-tips-for-success-in-sta-210",
    "title": "Welcome to STA 210!",
    "section": "Five tips for success in STA 210",
    "text": "Five tips for success in STA 210\n\nComplete all prepare readings and tasks before class.\nActively participate and engage in lectures and labs.\nAsk questions frequently during lecture, in office hours, on Ed Discussion, and among your classmates.\nComplete all homework and labs, asking yourself “why” questions as you go through the steps to complete each exercise.\nStay current with the course material, as each new concept builds on previous ones."
  },
  {
    "objectID": "slides/01-welcome.html#minute-paper",
    "href": "slides/01-welcome.html#minute-paper",
    "title": "Welcome to STA 210!",
    "section": "Minute paper",
    "text": "Minute paper\nSubmit your response to the question below. The form will record your NetID. 🔗 https://forms.office.com/r/r6fsAxjCqQ"
  },
  {
    "objectID": "slides/01-welcome.html#before-next-class",
    "href": "slides/01-welcome.html#before-next-class",
    "title": "Welcome to STA 210!",
    "section": "Before next class",
    "text": "Before next class\n\nComplete Lecture 02 Prepare\nReview the syllabus\nLabs start on Monday, January 12\nOffice hours start on Monday, January 12"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html",
    "href": "slides/05-sim-testing-notes.html",
    "title": "SLR: Permutation test for the slope",
    "section": "",
    "text": "HW 01 due Tuesday, January 27 at 11:59pm\nLabs resume Monday (stayed tuned for any weather related updates)"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#announcements",
    "href": "slides/05-sim-testing-notes.html#announcements",
    "title": "SLR: Permutation test for the slope",
    "section": "",
    "text": "HW 01 due Tuesday, January 27 at 11:59pm\nLabs resume Monday (stayed tuned for any weather related updates)"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#topics",
    "href": "slides/05-sim-testing-notes.html#topics",
    "title": "SLR: Permutation test for the slope",
    "section": "Topics",
    "text": "Topics\n\nDescribe accuracy versus precision for confidence intervals\n\n\n\nEvaluate a claim about the slope using hypothesis testing\nConstruct a null distribution using simulation\nCompute a p-value and use it to draw conclusions"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#computational-setup",
    "href": "slides/05-sim-testing-notes.html#computational-setup",
    "title": "SLR: Permutation test for the slope",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables\nlibrary(kableExtra)  # also for neatly formatted tablesf\n\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#data-duke-forest-houses",
    "href": "slides/05-sim-testing-notes.html#data-duke-forest-houses",
    "title": "SLR: Permutation test for the slope",
    "section": "Data: Duke Forest houses",
    "text": "Data: Duke Forest houses"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#the-regression-model",
    "href": "slides/05-sim-testing-notes.html#the-regression-model",
    "title": "SLR: Permutation test for the slope",
    "section": "The regression model",
    "text": "The regression model\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n. . .\nSlope: For each additional square foot, we expect the sale price of Duke Forest houses to be higher by $159, on average."
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#inference-for-simple-linear-regression",
    "href": "slides/05-sim-testing-notes.html#inference-for-simple-linear-regression",
    "title": "SLR: Permutation test for the slope",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\)\nConduct a hypothesis test for the slope, \\(\\beta_1\\)"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#statistical-inference",
    "href": "slides/05-sim-testing-notes.html#statistical-inference",
    "title": "SLR: Permutation test for the slope",
    "section": "Statistical inference",
    "text": "Statistical inference\n\n\n\nImage source: Eugene Morgan © Penn State"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#sampling-is-natural",
    "href": "slides/05-sim-testing-notes.html#sampling-is-natural",
    "title": "SLR: Permutation test for the slope",
    "section": "Sampling is natural",
    "text": "Sampling is natural\n\n\n\n\n\n\nWhen you taste a spoonful of soup and decide the spoonful you tasted isn’t salty enough, that’s exploratory analysis\nIf you generalize and conclude that your entire soup needs salt, that’s an inference\nFor your inference to be valid, the spoonful you tasted (the sample) needs to be representative of the entire pot (the population)"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#confidence-interval-via-bootstrapping",
    "href": "slides/05-sim-testing-notes.html#confidence-interval-via-bootstrapping",
    "title": "SLR: Permutation test for the slope",
    "section": "Confidence interval via bootstrapping",
    "text": "Confidence interval via bootstrapping\n\nBootstrap new samples from the original sample\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-i",
    "href": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-i",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline I",
    "text": "Bootstrapping pipeline I\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area)\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-ii",
    "href": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-ii",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline II",
    "text": "Bootstrapping pipeline II\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98,000 × 3\n# Groups:   replicate [1,000]\n   replicate   price  area\n       &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1         1  290000  2414\n 2         1  285000  2108\n 3         1  265000  1300\n 4         1  416000  2949\n 5         1  541000  2740\n 6         1  525000  2256\n 7         1 1270000  3909\n 8         1  265000  1300\n 9         1  815000  3904\n10         1  535000  2937\n# ℹ 97,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-iii",
    "href": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-iii",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline III",
    "text": "Bootstrapping pipeline III\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  fit()\n\n# A tibble: 2,000 × 3\n# Groups:   replicate [1,000]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   80699.\n 2         1 area          168.\n 3         2 intercept  -18821.\n 4         2 area          205.\n 5         3 intercept  234297.\n 6         3 area          117.\n 7         4 intercept  134481.\n 8         4 area          150.\n 9         5 intercept   23861.\n10         5 area          190.\n# ℹ 1,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-iv",
    "href": "slides/05-sim-testing-notes.html#bootstrapping-pipeline-iv",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline IV",
    "text": "Bootstrapping pipeline IV\n\nset.seed(210)\n\nboot_dist &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  fit()"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#visualize-the-bootstrap-distribution",
    "href": "slides/05-sim-testing-notes.html#visualize-the-bootstrap-distribution",
    "title": "SLR: Permutation test for the slope",
    "section": "Visualize the bootstrap distribution",
    "text": "Visualize the bootstrap distribution\n\nboot_dist |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10)"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#compute-the-ci",
    "href": "slides/05-sim-testing-notes.html#compute-the-ci",
    "title": "SLR: Permutation test for the slope",
    "section": "Compute the CI",
    "text": "Compute the CI"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#but-first",
    "href": "slides/05-sim-testing-notes.html#but-first",
    "title": "SLR: Permutation test for the slope",
    "section": "But first…",
    "text": "But first…\n\nobs_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobs_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#compute-95-confidence-interval",
    "href": "slides/05-sim-testing-notes.html#compute-95-confidence-interval",
    "title": "SLR: Permutation test for the slope",
    "section": "Compute 95% confidence interval",
    "text": "Compute 95% confidence interval\n\nboot_dist |&gt;\n  get_confidence_interval(\n    point_estimate = obs_fit,\n    level = 0.95,\n    type = \"percentile\"\n  )\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          91.7     211.\n2 intercept -18290.   287711."
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#precision-vs.-accuracy",
    "href": "slides/05-sim-testing-notes.html#precision-vs.-accuracy",
    "title": "SLR: Permutation test for the slope",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n\n. . ."
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#precision-vs.-accuracy-1",
    "href": "slides/05-sim-testing-notes.html#precision-vs.-accuracy-1",
    "title": "SLR: Permutation test for the slope",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nHow can we get best of both worlds – high precision and high accuracy?\n\n\n. . .\n\nConsider a 90%, 95%, and 99% confidence interval.\n\nWhich interval is most precise?\nWhich is most accurate?"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#changing-confidence-level",
    "href": "slides/05-sim-testing-notes.html#changing-confidence-level",
    "title": "SLR: Permutation test for the slope",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = obs_fit, \n  level = 0.90, type = \"percentile\"\n) \n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          102.     206.\n2 intercept    5288.  264931.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = obs_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          65.4     229.\n2 intercept -47594.   362644."
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#research-question-and-hypotheses",
    "href": "slides/05-sim-testing-notes.html#research-question-and-hypotheses",
    "title": "SLR: Permutation test for the slope",
    "section": "Research question and hypotheses",
    "text": "Research question and hypotheses\n“Do the data provide sufficient evidence that \\(\\beta_1\\) (the true population slope) is different from 0?”\n. . .\nNull hypothesis: there is no linear relationship between area and price\n\\[\nH_0: \\beta_1 = 0\n\\]\n. . .\nAlternative hypothesis: there is a linear relationship between area and price\n\\[\nH_a: \\beta_1 \\ne 0\n\\]"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#hypothesis-testing-as-a-us-court-trial",
    "href": "slides/05-sim-testing-notes.html#hypothesis-testing-as-a-us-court-trial",
    "title": "SLR: Permutation test for the slope",
    "section": "Hypothesis testing as a US court trial",
    "text": "Hypothesis testing as a US court trial\n\n\nNull hypothesis, \\(H_0\\): Defendant is innocent\nAlternative hypothesis, \\(H_a\\): Defendant is guilty\nPresent the evidence: Collect data\nJudge the evidence: “Could these data plausibly have happened by chance if the null hypothesis were true?”\n\nYes: Fail to reject \\(H_0\\)\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#hypothesis-testing-framework",
    "href": "slides/05-sim-testing-notes.html#hypothesis-testing-framework",
    "title": "SLR: Permutation test for the slope",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\n\nStart with a null hypothesis, \\(H_0\\) that represents the status quo\nSet an alternative hypothesis, \\(H_a\\) that represents the research question, i.e. claim we’re testing\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of getting the observed or a more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#quantify-the-variability-of-the-slope",
    "href": "slides/05-sim-testing-notes.html#quantify-the-variability-of-the-slope",
    "title": "SLR: Permutation test for the slope",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor testing\n\n\nTwo approaches:\n\nVia simulation\nVia mathematical models\n\nUse Permutation to quantify the variability of the slope for the purpose of testing, under the assumption that the null hypothesis is true:\n\nSimulate new samples from the original sample via permutation\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the permuted slopes to conduct a hypothesis test"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-described",
    "href": "slides/05-sim-testing-notes.html#permutation-described",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation, described",
    "text": "Permutation, described\n\n\n\nUse permuting to simulate data under the assumption the null hypothesis is true and measure the natural variability in the data due to sampling, not due to variables being correlated\n\nPermute one variable to eliminate any existing relationship between the variables\n\nEach price value is randomly assigned to the area of a given house, i.e. area and price are no longer matched for a given house\n\n\n\n\n# A tibble: 98 × 3\n   price_Observed price_Permuted  area\n            &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1        1520000         342500  6040\n 2        1030000         750000  4475\n 3         420000         645000  1745\n 4         680000         697500  2091\n 5         428500         428500  1772\n 6         456000         481000  1950\n 7        1270000         610000  3909\n 8         557450         680000  2841\n 9         697500         485000  3924\n10         650000         105000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-visualized",
    "href": "slides/05-sim-testing-notes.html#permutation-visualized",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation, visualized",
    "text": "Permutation, visualized\n\n\n\nEach of the observed values for area (and for price) exist in both the observed data plot as well as the permuted price plot\nThe permutation removes the relationship between area and price"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-repeated",
    "href": "slides/05-sim-testing-notes.html#permutation-repeated",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation, repeated",
    "text": "Permutation, repeated\nRepeated permutations allow for quantifying the variability in the slope under the condition that there is no linear relationship (i.e., that the null hypothesis is true)"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#concluding-the-hypothesis-test",
    "href": "slides/05-sim-testing-notes.html#concluding-the-hypothesis-test",
    "title": "SLR: Permutation test for the slope",
    "section": "Concluding the hypothesis test",
    "text": "Concluding the hypothesis test\n\nIs the observed slope of \\(\\hat{\\beta_1} = 159\\) (or an even more extreme slope) a likely outcome under the null hypothesis that \\(\\beta = 0\\)? What does this mean for our original question: “Do the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?”"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-pipeline-i",
    "href": "slides/05-sim-testing-notes.html#permutation-pipeline-i",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline I",
    "text": "Permutation pipeline I\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area)\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-pipeline-ii",
    "href": "slides/05-sim-testing-notes.html#permutation-pipeline-ii",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline II",
    "text": "Permutation pipeline II\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: indepe...\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-pipeline-iii",
    "href": "slides/05-sim-testing-notes.html#permutation-pipeline-iii",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline III",
    "text": "Permutation pipeline III\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: indepe...\n# A tibble: 98,000 × 3\n# Groups:   replicate [1,000]\n     price  area replicate\n     &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;\n 1  290000  6040         1\n 2  285000  4475         1\n 3  265000  1745         1\n 4  416000  2091         1\n 5  541000  1772         1\n 6  525000  1950         1\n 7 1270000  3909         1\n 8  490000  2841         1\n 9  535000  3924         1\n10  481000  2173         1\n# ℹ 97,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-pipeline-iv",
    "href": "slides/05-sim-testing-notes.html#permutation-pipeline-iv",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline IV",
    "text": "Permutation pipeline IV\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\") |&gt;\n  fit()\n\n# A tibble: 2,000 × 3\n# Groups:   replicate [1,000]\n   replicate term        estimate\n       &lt;int&gt; &lt;chr&gt;          &lt;dbl&gt;\n 1         1 intercept 560741.   \n 2         1 area          -0.303\n 3         2 intercept 531330.   \n 4         2 area          10.3  \n 5         3 intercept 533014.   \n 6         3 area           9.67 \n 7         4 intercept 388765.   \n 8         4 area          61.6  \n 9         5 intercept 607389.   \n10         5 area         -17.1  \n# ℹ 1,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#permutation-pipeline-v",
    "href": "slides/05-sim-testing-notes.html#permutation-pipeline-v",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline V",
    "text": "Permutation pipeline V\n\nset.seed(210)\n\nnull_dist &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\") |&gt;\n  fit()"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#visualize-the-null-distribution",
    "href": "slides/05-sim-testing-notes.html#visualize-the-null-distribution",
    "title": "SLR: Permutation test for the slope",
    "section": "Visualize the null distribution",
    "text": "Visualize the null distribution\n\nnull_dist |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10, color = \"white\")"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#reason-around-the-p-value",
    "href": "slides/05-sim-testing-notes.html#reason-around-the-p-value",
    "title": "SLR: Permutation test for the slope",
    "section": "Reason around the p-value",
    "text": "Reason around the p-value\n\nIn a world where the there is no relationship between the area of a Duke Forest house and in its price (\\(\\beta_1 = 0\\)), what is the probability that we observe a sample of 98 houses where the slope fo the model predicting price from area is 159 or even more extreme?"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#compute-the-p-value",
    "href": "slides/05-sim-testing-notes.html#compute-the-p-value",
    "title": "SLR: Permutation test for the slope",
    "section": "Compute the p-value",
    "text": "Compute the p-value\n\nWhat does this warning mean?\n\n\nget_p_value(\n  null_dist,\n  obs_stat = obs_fit,\n  direction = \"two-sided\"\n)\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an approximation\nbased on the number of `reps` chosen in the `generate()` step.\nℹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\nPlease be cautious in reporting a p-value of 0. This result is an approximation\nbased on the number of `reps` chosen in the `generate()` step.\nℹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\n\n\n# A tibble: 2 × 2\n  term      p_value\n  &lt;chr&gt;       &lt;dbl&gt;\n1 area            0\n2 intercept       0"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#p-value-warning",
    "href": "slides/05-sim-testing-notes.html#p-value-warning",
    "title": "SLR: Permutation test for the slope",
    "section": "p-value warning",
    "text": "p-value warning\n\nQuestionSubmit\n\n\n\n\nWhat does the warning from R mean?\n\n🔗 https://forms.office.com/r/Ji4YKVRwSj"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#recap",
    "href": "slides/05-sim-testing-notes.html#recap",
    "title": "SLR: Permutation test for the slope",
    "section": "Recap",
    "text": "Recap\n\nDescribed accuracy versus precision for confidence intervals\nEvaluated a claim about the slope using hypothesis testing\nConstructed a null distribution using simulation\nComputed a p-value and use it to draw conclusions"
  },
  {
    "objectID": "slides/05-sim-testing-notes.html#for-next-class",
    "href": "slides/05-sim-testing-notes.html#for-next-class",
    "title": "SLR: Permutation test for the slope",
    "section": "For next class",
    "text": "For next class\n\nInference using mathematical models\nComplete Lecture 06 prepare"
  },
  {
    "objectID": "slides/05-sim-testing.html#announcements",
    "href": "slides/05-sim-testing.html#announcements",
    "title": "SLR: Permutation test for the slope",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01 due Tuesday, January 27 at 11:59pm\nLabs resume Monday (stayed tuned for any weather related updates)"
  },
  {
    "objectID": "slides/05-sim-testing.html#topics",
    "href": "slides/05-sim-testing.html#topics",
    "title": "SLR: Permutation test for the slope",
    "section": "Topics",
    "text": "Topics\n\nDescribe accuracy versus precision for confidence intervals\n\n\n\nEvaluate a claim about the slope using hypothesis testing\nConstruct a null distribution using simulation\nCompute a p-value and use it to draw conclusions"
  },
  {
    "objectID": "slides/05-sim-testing.html#computational-setup",
    "href": "slides/05-sim-testing.html#computational-setup",
    "title": "SLR: Permutation test for the slope",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables\nlibrary(kableExtra)  # also for neatly formatted tablesf\n\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/05-sim-testing.html#data-duke-forest-houses",
    "href": "slides/05-sim-testing.html#data-duke-forest-houses",
    "title": "SLR: Permutation test for the slope",
    "section": "Data: Duke Forest houses",
    "text": "Data: Duke Forest houses"
  },
  {
    "objectID": "slides/05-sim-testing.html#the-regression-model",
    "href": "slides/05-sim-testing.html#the-regression-model",
    "title": "SLR: Permutation test for the slope",
    "section": "The regression model",
    "text": "The regression model\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\nSlope: For each additional square foot, we expect the sale price of Duke Forest houses to be higher by $159, on average."
  },
  {
    "objectID": "slides/05-sim-testing.html#inference-for-simple-linear-regression",
    "href": "slides/05-sim-testing.html#inference-for-simple-linear-regression",
    "title": "SLR: Permutation test for the slope",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\)\nConduct a hypothesis test for the slope, \\(\\beta_1\\)"
  },
  {
    "objectID": "slides/05-sim-testing.html#statistical-inference",
    "href": "slides/05-sim-testing.html#statistical-inference",
    "title": "SLR: Permutation test for the slope",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nImage source: Eugene Morgan © Penn State"
  },
  {
    "objectID": "slides/05-sim-testing.html#sampling-is-natural",
    "href": "slides/05-sim-testing.html#sampling-is-natural",
    "title": "SLR: Permutation test for the slope",
    "section": "Sampling is natural",
    "text": "Sampling is natural\n\n\nWhen you taste a spoonful of soup and decide the spoonful you tasted isn’t salty enough, that’s exploratory analysis\nIf you generalize and conclude that your entire soup needs salt, that’s an inference\nFor your inference to be valid, the spoonful you tasted (the sample) needs to be representative of the entire pot (the population)"
  },
  {
    "objectID": "slides/05-sim-testing.html#confidence-interval-via-bootstrapping",
    "href": "slides/05-sim-testing.html#confidence-interval-via-bootstrapping",
    "title": "SLR: Permutation test for the slope",
    "section": "Confidence interval via bootstrapping",
    "text": "Confidence interval via bootstrapping\n\nBootstrap new samples from the original sample\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/05-sim-testing.html#bootstrapping-pipeline-i",
    "href": "slides/05-sim-testing.html#bootstrapping-pipeline-i",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline I",
    "text": "Bootstrapping pipeline I\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area)\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#bootstrapping-pipeline-ii",
    "href": "slides/05-sim-testing.html#bootstrapping-pipeline-ii",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline II",
    "text": "Bootstrapping pipeline II\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98,000 × 3\n# Groups:   replicate [1,000]\n   replicate   price  area\n       &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1         1  290000  2414\n 2         1  285000  2108\n 3         1  265000  1300\n 4         1  416000  2949\n 5         1  541000  2740\n 6         1  525000  2256\n 7         1 1270000  3909\n 8         1  265000  1300\n 9         1  815000  3904\n10         1  535000  2937\n# ℹ 97,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#bootstrapping-pipeline-iii",
    "href": "slides/05-sim-testing.html#bootstrapping-pipeline-iii",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline III",
    "text": "Bootstrapping pipeline III\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  fit()\n\n# A tibble: 2,000 × 3\n# Groups:   replicate [1,000]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   80699.\n 2         1 area          168.\n 3         2 intercept  -18821.\n 4         2 area          205.\n 5         3 intercept  234297.\n 6         3 area          117.\n 7         4 intercept  134481.\n 8         4 area          150.\n 9         5 intercept   23861.\n10         5 area          190.\n# ℹ 1,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#bootstrapping-pipeline-iv",
    "href": "slides/05-sim-testing.html#bootstrapping-pipeline-iv",
    "title": "SLR: Permutation test for the slope",
    "section": "Bootstrapping pipeline IV",
    "text": "Bootstrapping pipeline IV\n\nset.seed(210)\n\nboot_dist &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  fit()"
  },
  {
    "objectID": "slides/05-sim-testing.html#visualize-the-bootstrap-distribution",
    "href": "slides/05-sim-testing.html#visualize-the-bootstrap-distribution",
    "title": "SLR: Permutation test for the slope",
    "section": "Visualize the bootstrap distribution",
    "text": "Visualize the bootstrap distribution\n\nboot_dist |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10)"
  },
  {
    "objectID": "slides/05-sim-testing.html#compute-the-ci",
    "href": "slides/05-sim-testing.html#compute-the-ci",
    "title": "SLR: Permutation test for the slope",
    "section": "Compute the CI",
    "text": "Compute the CI"
  },
  {
    "objectID": "slides/05-sim-testing.html#but-first",
    "href": "slides/05-sim-testing.html#but-first",
    "title": "SLR: Permutation test for the slope",
    "section": "But first…",
    "text": "But first…\n\nobs_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobs_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/05-sim-testing.html#compute-95-confidence-interval",
    "href": "slides/05-sim-testing.html#compute-95-confidence-interval",
    "title": "SLR: Permutation test for the slope",
    "section": "Compute 95% confidence interval",
    "text": "Compute 95% confidence interval\n\nboot_dist |&gt;\n  get_confidence_interval(\n    point_estimate = obs_fit,\n    level = 0.95,\n    type = \"percentile\"\n  )\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          91.7     211.\n2 intercept -18290.   287711."
  },
  {
    "objectID": "slides/05-sim-testing.html#precision-vs.-accuracy",
    "href": "slides/05-sim-testing.html#precision-vs.-accuracy",
    "title": "SLR: Permutation test for the slope",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?"
  },
  {
    "objectID": "slides/05-sim-testing.html#precision-vs.-accuracy-1",
    "href": "slides/05-sim-testing.html#precision-vs.-accuracy-1",
    "title": "SLR: Permutation test for the slope",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nHow can we get best of both worlds – high precision and high accuracy?\n\n\n\n\nConsider a 90%, 95%, and 99% confidence interval.\n\nWhich interval is most precise?\nWhich is most accurate?"
  },
  {
    "objectID": "slides/05-sim-testing.html#changing-confidence-level",
    "href": "slides/05-sim-testing.html#changing-confidence-level",
    "title": "SLR: Permutation test for the slope",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = obs_fit, \n  level = 0.90, type = \"percentile\"\n) \n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          102.     206.\n2 intercept    5288.  264931.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = obs_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          65.4     229.\n2 intercept -47594.   362644."
  },
  {
    "objectID": "slides/05-sim-testing.html#research-question-and-hypotheses",
    "href": "slides/05-sim-testing.html#research-question-and-hypotheses",
    "title": "SLR: Permutation test for the slope",
    "section": "Research question and hypotheses",
    "text": "Research question and hypotheses\n“Do the data provide sufficient evidence that \\(\\beta_1\\) (the true population slope) is different from 0?”\n\nNull hypothesis: there is no linear relationship between area and price\n\\[\nH_0: \\beta_1 = 0\n\\]\n\n\nAlternative hypothesis: there is a linear relationship between area and price\n\\[\nH_a: \\beta_1 \\ne 0\n\\]"
  },
  {
    "objectID": "slides/05-sim-testing.html#hypothesis-testing-as-a-us-court-trial",
    "href": "slides/05-sim-testing.html#hypothesis-testing-as-a-us-court-trial",
    "title": "SLR: Permutation test for the slope",
    "section": "Hypothesis testing as a US court trial",
    "text": "Hypothesis testing as a US court trial\n\nNull hypothesis, \\(H_0\\): Defendant is innocent\nAlternative hypothesis, \\(H_a\\): Defendant is guilty\nPresent the evidence: Collect data\nJudge the evidence: “Could these data plausibly have happened by chance if the null hypothesis were true?”\n\nYes: Fail to reject \\(H_0\\)\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "slides/05-sim-testing.html#hypothesis-testing-framework",
    "href": "slides/05-sim-testing.html#hypothesis-testing-framework",
    "title": "SLR: Permutation test for the slope",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\nStart with a null hypothesis, \\(H_0\\) that represents the status quo\nSet an alternative hypothesis, \\(H_a\\) that represents the research question, i.e. claim we’re testing\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of getting the observed or a more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "slides/05-sim-testing.html#quantify-the-variability-of-the-slope",
    "href": "slides/05-sim-testing.html#quantify-the-variability-of-the-slope",
    "title": "SLR: Permutation test for the slope",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor testing\n\nTwo approaches:\n\nVia simulation\nVia mathematical models\n\nUse Permutation to quantify the variability of the slope for the purpose of testing, under the assumption that the null hypothesis is true:\n\nSimulate new samples from the original sample via permutation\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the permuted slopes to conduct a hypothesis test"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-described",
    "href": "slides/05-sim-testing.html#permutation-described",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation, described",
    "text": "Permutation, described\n\n\n\nUse permuting to simulate data under the assumption the null hypothesis is true and measure the natural variability in the data due to sampling, not due to variables being correlated\n\nPermute one variable to eliminate any existing relationship between the variables\n\nEach price value is randomly assigned to the area of a given house, i.e. area and price are no longer matched for a given house\n\n\n\n\n# A tibble: 98 × 3\n   price_Observed price_Permuted  area\n            &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1        1520000         342500  6040\n 2        1030000         750000  4475\n 3         420000         645000  1745\n 4         680000         697500  2091\n 5         428500         428500  1772\n 6         456000         481000  1950\n 7        1270000         610000  3909\n 8         557450         680000  2841\n 9         697500         485000  3924\n10         650000         105000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-visualized",
    "href": "slides/05-sim-testing.html#permutation-visualized",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation, visualized",
    "text": "Permutation, visualized\n\n\n\nEach of the observed values for area (and for price) exist in both the observed data plot as well as the permuted price plot\nThe permutation removes the relationship between area and price"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-repeated",
    "href": "slides/05-sim-testing.html#permutation-repeated",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation, repeated",
    "text": "Permutation, repeated\nRepeated permutations allow for quantifying the variability in the slope under the condition that there is no linear relationship (i.e., that the null hypothesis is true)"
  },
  {
    "objectID": "slides/05-sim-testing.html#concluding-the-hypothesis-test",
    "href": "slides/05-sim-testing.html#concluding-the-hypothesis-test",
    "title": "SLR: Permutation test for the slope",
    "section": "Concluding the hypothesis test",
    "text": "Concluding the hypothesis test\n\nIs the observed slope of \\(\\hat{\\beta_1} = 159\\) (or an even more extreme slope) a likely outcome under the null hypothesis that \\(\\beta = 0\\)? What does this mean for our original question: “Do the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?”"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-pipeline-i",
    "href": "slides/05-sim-testing.html#permutation-pipeline-i",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline I",
    "text": "Permutation pipeline I\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area)\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-pipeline-ii",
    "href": "slides/05-sim-testing.html#permutation-pipeline-ii",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline II",
    "text": "Permutation pipeline II\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: indepe...\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-pipeline-iii",
    "href": "slides/05-sim-testing.html#permutation-pipeline-iii",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline III",
    "text": "Permutation pipeline III\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: indepe...\n# A tibble: 98,000 × 3\n# Groups:   replicate [1,000]\n     price  area replicate\n     &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;\n 1  290000  6040         1\n 2  285000  4475         1\n 3  265000  1745         1\n 4  416000  2091         1\n 5  541000  1772         1\n 6  525000  1950         1\n 7 1270000  3909         1\n 8  490000  2841         1\n 9  535000  3924         1\n10  481000  2173         1\n# ℹ 97,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-pipeline-iv",
    "href": "slides/05-sim-testing.html#permutation-pipeline-iv",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline IV",
    "text": "Permutation pipeline IV\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\") |&gt;\n  fit()\n\n# A tibble: 2,000 × 3\n# Groups:   replicate [1,000]\n   replicate term        estimate\n       &lt;int&gt; &lt;chr&gt;          &lt;dbl&gt;\n 1         1 intercept 560741.   \n 2         1 area          -0.303\n 3         2 intercept 531330.   \n 4         2 area          10.3  \n 5         3 intercept 533014.   \n 6         3 area           9.67 \n 7         4 intercept 388765.   \n 8         4 area          61.6  \n 9         5 intercept 607389.   \n10         5 area         -17.1  \n# ℹ 1,990 more rows"
  },
  {
    "objectID": "slides/05-sim-testing.html#permutation-pipeline-v",
    "href": "slides/05-sim-testing.html#permutation-pipeline-v",
    "title": "SLR: Permutation test for the slope",
    "section": "Permutation pipeline V",
    "text": "Permutation pipeline V\n\nset.seed(210)\n\nnull_dist &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\") |&gt;\n  fit()"
  },
  {
    "objectID": "slides/05-sim-testing.html#visualize-the-null-distribution",
    "href": "slides/05-sim-testing.html#visualize-the-null-distribution",
    "title": "SLR: Permutation test for the slope",
    "section": "Visualize the null distribution",
    "text": "Visualize the null distribution\n\nnull_dist |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10, color = \"white\")"
  },
  {
    "objectID": "slides/05-sim-testing.html#reason-around-the-p-value",
    "href": "slides/05-sim-testing.html#reason-around-the-p-value",
    "title": "SLR: Permutation test for the slope",
    "section": "Reason around the p-value",
    "text": "Reason around the p-value\n\nIn a world where the there is no relationship between the area of a Duke Forest house and in its price (\\(\\beta_1 = 0\\)), what is the probability that we observe a sample of 98 houses where the slope fo the model predicting price from area is 159 or even more extreme?"
  },
  {
    "objectID": "slides/05-sim-testing.html#compute-the-p-value",
    "href": "slides/05-sim-testing.html#compute-the-p-value",
    "title": "SLR: Permutation test for the slope",
    "section": "Compute the p-value",
    "text": "Compute the p-value\n\nWhat does this warning mean?\n\n\nget_p_value(\n  null_dist,\n  obs_stat = obs_fit,\n  direction = \"two-sided\"\n)\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an approximation\nbased on the number of `reps` chosen in the `generate()` step.\nℹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\nPlease be cautious in reporting a p-value of 0. This result is an approximation\nbased on the number of `reps` chosen in the `generate()` step.\nℹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\n\n\n# A tibble: 2 × 2\n  term      p_value\n  &lt;chr&gt;       &lt;dbl&gt;\n1 area            0\n2 intercept       0"
  },
  {
    "objectID": "slides/05-sim-testing.html#p-value-warning",
    "href": "slides/05-sim-testing.html#p-value-warning",
    "title": "SLR: Permutation test for the slope",
    "section": "p-value warning",
    "text": "p-value warning\n\nQuestionSubmit\n\n\n\n\nWhat does the warning from R mean?\n\n🔗 https://forms.office.com/r/Ji4YKVRwSj"
  },
  {
    "objectID": "slides/05-sim-testing.html#recap",
    "href": "slides/05-sim-testing.html#recap",
    "title": "SLR: Permutation test for the slope",
    "section": "Recap",
    "text": "Recap\n\nDescribed accuracy versus precision for confidence intervals\nEvaluated a claim about the slope using hypothesis testing\nConstructed a null distribution using simulation\nComputed a p-value and use it to draw conclusions"
  },
  {
    "objectID": "slides/05-sim-testing.html#for-next-class",
    "href": "slides/05-sim-testing.html#for-next-class",
    "title": "SLR: Permutation test for the slope",
    "section": "For next class",
    "text": "For next class\n\nInference using mathematical models\nComplete Lecture 06 prepare"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio containers\n🔗 for Duke Container Manager\n\n\nCourse GitHub organization\n🔗 for GitHub\n\n\nCourse Canvas site\n🔗 for Canvas\n\n\nDiscussion forum\n🔗 to Ed Discussion\n\n\nAssignment submission\n🔗 to Gradescope\n\n\nLecture recording request\n🔗 to Lecture recording request form",
    "crumbs": [
      "Useful links"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "STA 210 Syllabus",
    "section": "",
    "text": "See Canvas for class meeting times and locations.\n\n\n\n\n\n\nName\nRole\n\n\n\n\nProf. Maria Tackett\nInstructor\n\n\nAdeli Hutton\nLab leader\n\n\nShane Rybacki\nLab leader\n\n\n\nSee Canvas for office hours.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-info",
    "href": "syllabus.html#course-info",
    "title": "STA 210 Syllabus",
    "section": "",
    "text": "See Canvas for class meeting times and locations.\n\n\n\n\n\n\nName\nRole\n\n\n\n\nProf. Maria Tackett\nInstructor\n\n\nAdeli Hutton\nLab leader\n\n\nShane Rybacki\nLab leader\n\n\n\nSee Canvas for office hours.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "STA 210 Syllabus",
    "section": "Course description",
    "text": "Course description\nIn STA 210, students will learn how linear and logistic regression models are used to explore multivariable relationships and apply these methods to answer relevant and engaging questions using a data-driven approach. Students will develop computing skills to implement a reproducible data analysis workflow and gain experience communicating statistical results. Throughout the semester, students will work on a team project where they will develop a research question, answer it using methods learned in the course, and share results through a written report and presentation.\nTopics include applications of linear and logistic regression, interpretation, diagnostics, model selection, and model assessment. Students will gain experience using the computing tools R and GitHub to analyze real-world data from a variety of fields. This class emphasizes data analysis over mathematical theory.\n\nPrerequisites\n100-level Statistical Science course or Statistical Science 230, 231, or 240L",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-learning-objectives",
    "href": "syllabus.html#course-learning-objectives",
    "title": "STA 210 Syllabus",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze real-world data to answer questions about multivariable relationships.\nuse R to fit and evaluate linear and logistic regression models.\nassess whether a proposed model is appropriate and describe its limitations.\nimplement a reproducible analysis workflow using R for analysis, Quarto to write reports and GitHub for version control and collaboration.\neffectively communicate statistical results to a general audience.\nassess the ethical considerations and implications of analysis decisions.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "STA 210 Syllabus",
    "section": "Course materials",
    "text": "Course materials\nMost readings in this course will come from Introduction to Regression Analysis: A Data Science Approach. It is freely available online (https://intro-regression.github.io). Readings from this text and other sources will be posted under the “prepare” column on the course schedule. We will use the statistical software R. Students will be able to access R through Docker containers provided by Duke Office of Information Technology. See the computing page for more information.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-community",
    "href": "syllabus.html#course-community",
    "title": "STA 210 Syllabus",
    "section": "Course community",
    "text": "Course community\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nUsing pronouns can help foster a respectful campus environment where all community members can thrive. Sharing pronouns is always optional for members of the Duke community. If you would like to share yours, you can update them in DukeHub. You can learn more at the DukeHub & Zoom Tutorials.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website, https://sta210-sp26.github.io.\nLinks to Zoom meetings may be found in Canvas. Periodic announcements will be sent via email and will also be available through Ed Discussion and Canvas Announcements. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nEmail\nIf you have questions about assignment extensions, accommodations, or any other matter not appropriate for the class discussion forum, please email me directly at maria.tackett@duke.edu. If you email me, please include “STA 210” in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#five-tips-for-success",
    "href": "syllabus.html#five-tips-for-success",
    "title": "STA 210 Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nThe TAs and I will provide materials, answer questions, and provide guidance to help you learn the material in this course. Below are five things you can do to be successful in STA 210:\n\nComplete all “prepare” readings and tasks before class.\nActively participate and engage in lectures and labs.\nAsk questions frequently during lecture, in office hours, on Ed Discussion, and among your classmates.\nComplete all homework and labs, asking yourself “why” questions as you go through the steps to complete each exercise.\nStay current with the course material, as each new concept builds on previous ones.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#getting-help-in-the-course",
    "href": "syllabus.html#getting-help-in-the-course",
    "title": "STA 210 Syllabus",
    "section": "Getting help in the course",
    "text": "Getting help in the course\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours1 to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. You are encouraged to use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the class discussion forum Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts in Ed Discussion before adding a new question. If you know the answer to a question posted in the discussion forum, you are encouraged to respond!\n\nCheck out the Support page for more resources.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#what-to-expect-in-the-course",
    "href": "syllabus.html#what-to-expect-in-the-course",
    "title": "STA 210 Syllabus",
    "section": "What to expect in the course",
    "text": "What to expect in the course\n\nLectures and labs\nLectures and labs are designed to be interactive, so you gain experience applying new concepts and learning from each other. My role as instructor is to introduce you to new methods, tools, and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities during the lectures and labs. You are expected to prepare for class by completing assigned readings, attend all lecture and lab sessions, and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded based on completing what we do in class.\nYou are expected to bring a laptop, tablet, or any device with internet and a keyboard to each class so that you can participate in the in-class exercises. Please make sure your device is fully charged before you come to class, as the number of outlets in the classroom will not be sufficient to accommodate everyone.\n\n\nTeams\nYou will work on a team for most labs throughout the semester. Teams will be assigned, and you will work with the team for 1 - 2 lab assignments. All team members are expected to contribute equally to the completion of the lab. You will be asked to complete teamwork evaluations and self-reflections throughout the semester. Failure to adequately contribute to an assignment can result in a penalty to your score relative to the team’s overall mark.\nYou are expected to make use of the provided GitHub repository as the central collaborative platform. Commits to this repository will be used as one of several metrics of each team member’s relative contribution for each assignment.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#activities-assessment",
    "href": "syllabus.html#activities-assessment",
    "title": "STA 210 Syllabus",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nYou will be assessed based on five components: labs, homework, exams, final project, and participation.\n\nLabs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation and communication. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s Git repository in the course’s GitHub organization as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nLabs will be graded based on completion and workflow. The lowest lab grade will be dropped at the end of the semester. The lowest lab grade will be dropped at the end of the semester.\n\n\nHomework\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis exercises and explain concepts. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be two exams in this course. Each exam will include a closed-note in-class component and an open-note take-home component. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. The exams will focus on both conceptual understanding and application through analysis and computational tasks. The exams will be based on content in prepare assignments, lectures, in-class activities, homework, and lab assignments. More detail about the exams will be given during the semester.\nIf you miss Exam 01 due to a reason documented by a Dean’s Excuse, the Exam 02 score will replace the missed exam score. If you miss Exam 02 due to a reason documented by a Dean’s Excuse, you will make up the exam during the final exam period.\n\n\nProject\nThe purpose of the final project is to apply what you’ve learned to analyze an interesting data-driven research question. More information about the project will be provided during the semester. You can learn more on the Project page.\n\n\nParticipation\nAttending and actively engaging in lecture is important to help you be successful in the course. Attendance and participation will be tracked by turning in some deliverable during lecture (e.g., responding to an online poll question, minute paper, etc.). There are 26 lectures this semester (this does not include exam days). You must participate in at least 18 lectures to get full credit on the participation component of the final course grade. Otherwise, the participation component of the final course grade is calculated as the percentage of lectures you attended and submitted the deliverable.\nThere are no make ups for the participation activities.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "STA 210 Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\n\nCategory\nPercentage\n\n\n\n\nLabs\n10%\n\n\nHomework\n15%\n\n\nExam 01\n25%\n\n\nExam 02\n25%\n\n\nFinal project\n20%\n\n\nParticipation\n5%\n\n\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "STA 210 Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nDuke Community Standard\nAll students must adhere to the Duke Community Standard(DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard, students agree:\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;and\nI will act if the Standard is compromised.\n\n\n\n\n\n\nAcademic honesty\nTL;DR: Don’t cheat!\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nFor the projects and team labs, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project or team labs across teams.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of artificial intelligence (AI): You should treat AI tools, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:2 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning. (2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\nAI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\nNo AI tools for narrative: Unless instructed otherwise, AI is not permitted for writing narrative that is copy and pasted into the assignment. In general, you may use AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\n\nIf you are unsure if the use of a particular resource complies with the academic honesty policy, please ask a member of the teaching team.\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one’s own work, following proper citation of sources, adhering to guidance around group work projects,and more).Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback in a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nThere is no late work permitted on lab assignments. These are graded for completion, so a lab assignment will be graded as “Not complete” if it is submitted after the deadline.\nHomework may be submitted up to 2 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThe late work policy for exams will be provided with the exam instructions.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a homework assignment by the stated due date, you may email me at maria.tackett@duke.edu before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let me know if you need help contacting your academic dean.\n\n\nRegrade Requests\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the last day of classes.\n\n\nAttendance policy\nEvery student is expected to attend and participate in lecture and labs. There may be times, however, when you cannot attend class. Lecture recordings are available upon request for students who have an excused absence. See the Lecture recording request policy for more detail. If you miss a lecture, make sure to review the material and complete the application exercise, if applicable, before the next lecture. Labs dedicated to completing the lab assignment and collaborating with your lab team. If you miss a lab session, make sure to communicate with your lab TA and teammates about how you can make up your contribution. If you know you’re going to miss a lab session and you’re feeling well enough to do so, notify your lab TA and teammates ahead of time.\nMore details on Trinity attendance policies are available here.\n\n\nLecture recording request\nLectures will be recorded on Panopto and will be made available to students with an excused absence upon request. Videos shared with such students will be available for a week after the lecture date. To request a particular lecture’s video, please fill out the form at the link below. Please submit the form within 24 hours of missing lecture to ensure you have sufficient time to watch the recording. Please also make sure that any official documentation, such as incapacitation forms, Dean’s excuses, NOVAPs, and quarantine/removal from class notices from student health are also uploaded to the form.\n🔗 https://forms.office.com/r/TwGidRkmb0\nAbout one week before each exam, the class recordings will be available to all students. These recordings will be available until the start of the exam.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#accommodations",
    "href": "syllabus.html#accommodations",
    "title": "STA 210 Syllabus",
    "section": "Accommodations",
    "text": "Accommodations\n\nAcademic accommodations\nIf you need accommodations for this class, you will need to register with the Student Disability Access Office (SDAO) and provide them with documentation related to your needs. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.\n\n\nReligious accommodations\nStudents are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: trinity.duke.edu/undergraduate/academic-policies/religious-holidays",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#academic-support",
    "href": "syllabus.html#academic-support",
    "title": "STA 210 Syllabus",
    "section": "Academic support",
    "text": "Academic support\n\nAcademic Resource Center\nThe Academic Resource Center (the ARC) offers services to support students academically during their undergraduate careers at Duke. The ARC can provide support with time management, academic skills and strategies, course-specific tutoring, presentation skills, public speaking, and more. ARC services are available free to all Duke undergraduate students studying any discipline. Learn more:\n\nLearning Consultations – time management, study strategies, learning preferences, and more\nVOICE Lab – strengthen public speaking, practice presentations, and more\n\nYou can contact the Academic Resource Center by phone at (919) 684-5917, by email at theARC@duke.edu, or by visiting http://arc.duke.edu/.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#important-dates",
    "href": "syllabus.html#important-dates",
    "title": "STA 210 Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nJanuary 7: Classes begin\nJanuary 19: Martin Luther King Jr. Day holiday.\nJanuary 21: Drop/Add ends\nMarch 9 - 13: Spring break\nMarch 25: Last day to withdraw with “W”\nApril 22: Classes end\nApril 23-26: Reading period\nApril 27 - May 2: Final exam period\n\nClick here for the full Duke academic calendar.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "STA 210 Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOffice hours are times the teaching team set aside each week to meet with students.↩︎\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D.↩︎↩︎",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Final project",
    "section": "",
    "text": "To be posted.",
    "crumbs": [
      "Project",
      "Instructions"
    ]
  },
  {
    "objectID": "slides/06-slr-math-models.html#announcements",
    "href": "slides/06-slr-math-models.html#announcements",
    "title": "SLR: Mathematical models for inference",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01 due TODAY at 11:59pm\nLab 01 due Thursday at 11:59pm\n\nQuestions?"
  },
  {
    "objectID": "slides/06-slr-math-models.html#topics",
    "href": "slides/06-slr-math-models.html#topics",
    "title": "SLR: Mathematical models for inference",
    "section": "Topics",
    "text": "Topics\n\nDefine mathematical models to conduct inference for the slope\nUse mathematical models to\n\ncalculate confidence interval for the slope\nconduct a hypothesis test for the slope\nconstruct intervals for predictions"
  },
  {
    "objectID": "slides/06-slr-math-models.html#computational-setup",
    "href": "slides/06-slr-math-models.html#computational-setup",
    "title": "SLR: Mathematical models for inference",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(kableExtra)  # also for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/06-slr-math-models.html#the-regression-model-revisited",
    "href": "slides/06-slr-math-models.html#the-regression-model-revisited",
    "title": "SLR: Mathematical models for inference",
    "section": "The regression model, revisited",
    "text": "The regression model, revisited\n\ndf_fit &lt;- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.325\n53302.463\n2.188\n0.031\n\n\narea\n159.483\n18.171\n8.777\n0.000"
  },
  {
    "objectID": "slides/06-slr-math-models.html#inference-revisited",
    "href": "slides/06-slr-math-models.html#inference-revisited",
    "title": "SLR: Mathematical models for inference",
    "section": "Inference, revisited",
    "text": "Inference, revisited\n\nEarlier we computed a confidence interval and conducted a hypothesis test via simulation:\n\nCI: Bootstrap the observed sample to simulate the distribution of the slope\nHT: Permute the observed sample to simulate the distribution of the slope under the assumption that the null hypothesis is true\n\nNow we’ll do these based on theoretical results, i.e., by using the Central Limit Theorem to define the distribution of the slope and use features (shape, center, spread) of this distribution to compute bounds of the confidence interval and the p-value for the hypothesis test"
  },
  {
    "objectID": "slides/06-slr-math-models.html#mathematical-representation-of-the-model",
    "href": "slides/06-slr-math-models.html#mathematical-representation-of-the-model",
    "title": "SLR: Mathematical models for inference",
    "section": "Mathematical representation of the model",
    "text": "Mathematical representation of the model\n\\[\n\\begin{aligned}\nY &= \\text{Model} + \\text{Error} \\\\[8pt]\n&= f(X) + \\epsilon \\\\[8pt]\n&= E(Y|X) + \\epsilon \\\\[8pt]\n&= \\beta_0 + \\beta_1 X + \\epsilon\n\\end{aligned}\n\\]\nwhere the errors are independent and normally distributed:\n\n\nindependent: Knowing the error term for one observation doesn’t tell you anything about the error term for another observation\nnormally distributed: \\(\\epsilon \\sim N(0, \\sigma_\\epsilon^2)\\)"
  },
  {
    "objectID": "slides/06-slr-math-models.html#side-note-expected-value-and-variance",
    "href": "slides/06-slr-math-models.html#side-note-expected-value-and-variance",
    "title": "SLR: Mathematical models for inference",
    "section": "Side note: Expected value and variance",
    "text": "Side note: Expected value and variance\nLet \\(X\\) be a random variable and \\(a\\) and \\(b\\) be constants.\n\nExpected value\n\\[\nE(aX+b) = E(aX) + E(b) = aE(X) + b\n\\]\n\nVariance\n\\[\nVar(aX + b) = a^2Var(X)\n\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#mathematical-representation-visualized",
    "href": "slides/06-slr-math-models.html#mathematical-representation-visualized",
    "title": "SLR: Mathematical models for inference",
    "section": "Mathematical representation, visualized",
    "text": "Mathematical representation, visualized\n\\[\nY|X \\sim N(\\beta_0 + \\beta_1 X, \\sigma_\\epsilon^2)\n\\]\n\n\n\n\n\nImage source: Introduction to the Practice of Statistics (5th ed)\n\n\n\n\nMean: \\(\\beta_0 + \\beta_1 X\\), the predicted value based on the regression model\nVariance: \\(\\sigma_\\epsilon^2\\), constant across the range of \\(X\\)\n\nHow do we estimate \\(\\sigma_\\epsilon^2\\)?"
  },
  {
    "objectID": "slides/06-slr-math-models.html#regression-standard-error",
    "href": "slides/06-slr-math-models.html#regression-standard-error",
    "title": "SLR: Mathematical models for inference",
    "section": "Regression standard error",
    "text": "Regression standard error\nOnce we fit the model, we can use the residuals to estimate the regression standard error, the average distance between the observed values and the regression line\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-2}} = \\sqrt{\\frac{\\sum_\\limits{i=1}^ne_i^2}{n-2}}\n\\]\n\n\n\nWhy divide by \\(n - 2\\)?\nWhy do we care about the value of the regression standard error?"
  },
  {
    "objectID": "slides/06-slr-math-models.html#standard-error-of-hatbeta_1",
    "href": "slides/06-slr-math-models.html#standard-error-of-hatbeta_1",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard error of \\(\\hat{\\beta}_1\\)",
    "text": "Standard error of \\(\\hat{\\beta}_1\\)\nThe standard error of \\(\\hat{\\beta}_1\\) quantifies the sampling variability in the estimated slopes\n\\[\nSE_{\\hat{\\beta}_1} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{(n-1)s_X^2}}\n\\]\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-for-the-slope",
    "href": "slides/06-slr-math-models.html#hypothesis-test-for-the-slope",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test for the slope",
    "text": "Hypothesis test for the slope\nHypotheses: \\(H_0: \\beta_1 = 0\\) vs. \\(H_a: \\beta_1 \\ne 0\\)\n\nTest statistic: Number of standard errors the estimate is away from the null\n\\[\nT = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} \\\\\n\\]\n\n\np-value: Probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\\[\n\\text{p-value} = P(|t| &gt; |T|),\n\\]\ncalculated from a \\(t\\) distribution with \\(n - 2\\) degrees of freedom"
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-test-statistic",
    "href": "slides/06-slr-math-models.html#hypothesis-test-test-statistic",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: Test statistic",
    "text": "Hypothesis test: Test statistic\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\\[\nT = \\frac{\\hat{\\beta}_1 - 0}{SE_{\\hat{\\beta}_1}} = \\frac{159.48 - 0}{18.17} = 8.78\n\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#interpreting-the-test-statistic",
    "href": "slides/06-slr-math-models.html#interpreting-the-test-statistic",
    "title": "SLR: Mathematical models for inference",
    "section": "Interpreting the test statistic",
    "text": "Interpreting the test statistic\n\nThe test statistic is 8.78. What is the best interpretation?\n\nThe estimated slope of 159.48 is 8.78 standard errors away from the mean.\nThe estimated slope of 159.48 is 8.78 standard errors above the mean.\nThe estimated slope of 159.48 is 8.78 standard errors above 0, the hypothesized mean.\nThe estimated slope of 159.48 is 8.78 standard errors away from 0, the hypothesized mean."
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-p-value",
    "href": "slides/06-slr-math-models.html#hypothesis-test-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: p-value",
    "text": "Hypothesis test: p-value\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-p-value-1",
    "href": "slides/06-slr-math-models.html#hypothesis-test-p-value-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: p-value",
    "text": "Hypothesis test: p-value\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\nA more exact p-value\n\n2 * pt(q = 8.78, df = 96, lower.tail = FALSE)\n\n[1] 6.19602e-14"
  },
  {
    "objectID": "slides/06-slr-math-models.html#interpreting-the-p-value",
    "href": "slides/06-slr-math-models.html#interpreting-the-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Interpreting the p-value",
    "text": "Interpreting the p-value\n\nWhat does the p-value mean in the context of the data?\n\nThe probability there is no linear relationship between area and price is approximately 0.\nGiven there is no linear relationship between area and price, the probability of observing a slope of 159.48 is approximately 0.\nGiven there is a linear relationship between area and price, the probability of observing a slope of 159.48 is approximately 0.\nGiven there is no linear relationship between area and price, the probability of observing a slope of 159.48 or more extreme is approximately 0."
  },
  {
    "objectID": "slides/06-slr-math-models.html#understanding-the-p-value",
    "href": "slides/06-slr-math-models.html#understanding-the-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Understanding the p-value",
    "text": "Understanding the p-value\n\n\n\nMagnitude of p-value\nInterpretation\n\n\n\n\np-value &lt; 0.01\nstrong evidence against \\(H_0\\)\n\n\n0.01 &lt; p-value &lt; 0.05\nmoderate evidence against \\(H_0\\)\n\n\n0.05 &lt; p-value &lt; 0.1\nweak evidence against \\(H_0\\)\n\n\np-value &gt; 0.1\neffectively no evidence against \\(H_0\\)\n\n\n\n\n\n\n\n\n\nImportant\n\n\nThese are general guidelines. The strength of evidence depends on the context of the problem."
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-conclusion-in-context",
    "href": "slides/06-slr-math-models.html#hypothesis-test-conclusion-in-context",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: Conclusion, in context",
    "text": "Hypothesis test: Conclusion, in context\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\nThe data provide convincing evidence that the population slope \\(\\beta_1\\) is different from 0.\nThe data provide convincing evidence of a linear relationship between area and price of houses in Duke Forest."
  },
  {
    "objectID": "slides/06-slr-math-models.html#confidence-interval-for-the-slope",
    "href": "slides/06-slr-math-models.html#confidence-interval-for-the-slope",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\n\\[\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n\\]\n\n\\[\n\\hat{\\beta}_1 \\pm t^* \\times SE_{\\hat{\\beta}_1}\n\\]\nwhere \\(t^*\\) is calculated from a \\(t\\) distribution with \\(n-2\\) degrees of freedom"
  },
  {
    "objectID": "slides/06-slr-math-models.html#confidence-interval-critical-value",
    "href": "slides/06-slr-math-models.html#confidence-interval-critical-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval: Critical value",
    "text": "Confidence interval: Critical value\n\n\n\n\n# confidence level: 95%\nqt(0.975, df = nrow(duke_forest) - 2)\n\n[1] 1.984984\n\n\n\n\n\n# confidence level: 90%\nqt(0.95, df = nrow(duke_forest) - 2)\n\n[1] 1.660881\n\n\n\n\n\n# confidence level: 99%\nqt(0.995, df = nrow(duke_forest) - 2)\n\n[1] 2.628016"
  },
  {
    "objectID": "slides/06-slr-math-models.html#ci-for-the-slope-calculation",
    "href": "slides/06-slr-math-models.html#ci-for-the-slope-calculation",
    "title": "SLR: Mathematical models for inference",
    "section": "95% CI for the slope: Calculation",
    "text": "95% CI for the slope: Calculation\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\\[\\hat{\\beta}_1 = 159.48 \\hspace{15mm} t^* = 1.98 \\hspace{15mm} SE_{\\hat{\\beta}_1} = 18.17\\]\n\n\\[\n159.48 \\pm 1.98 \\times 18.17 = (123.50, 195.46)\n\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#ci-for-the-slope-computation",
    "href": "slides/06-slr-math-models.html#ci-for-the-slope-computation",
    "title": "SLR: Mathematical models for inference",
    "section": "95% CI for the slope: Computation",
    "text": "95% CI for the slope: Computation\n\ntidy(df_fit, conf.int = TRUE, conf.level = 0.95) |&gt; \n  kable(digits = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n10847.77\n222456.88\n\n\narea\n159.48\n18.17\n8.78\n0.00\n123.41\n195.55"
  },
  {
    "objectID": "slides/06-slr-math-models.html#intervals-for-predictions-1",
    "href": "slides/06-slr-math-models.html#intervals-for-predictions-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Intervals for predictions",
    "text": "Intervals for predictions\n\nSuppose we want to answer the question “What is the predicted sale price of a Duke Forest house that is 2,800 square feet?”\nWe said reporting a single estimate for the slope is not wise, and we should report a plausible range instead\nSimilarly, reporting a single prediction for a new value is not wise, and we should report a plausible range instead"
  },
  {
    "objectID": "slides/06-slr-math-models.html#two-types-of-predictions",
    "href": "slides/06-slr-math-models.html#two-types-of-predictions",
    "title": "SLR: Mathematical models for inference",
    "section": "Two types of predictions",
    "text": "Two types of predictions\n\nPrediction for the mean: “What is the average predicted sale price of Duke Forest houses that are 2,800 square feet?”\nPrediction for an individual observation: “What is the predicted sale price of a Duke Forest house that is 2,800 square feet?”\n\n\n\nWhich would you expect to be more variable? The average prediction or the prediction for an individual observation? Based on your answer, how would you expect the widths of plausible ranges for these two predictions to compare?"
  },
  {
    "objectID": "slides/06-slr-math-models.html#uncertainty-in-predictions",
    "href": "slides/06-slr-math-models.html#uncertainty-in-predictions",
    "title": "SLR: Mathematical models for inference",
    "section": "Uncertainty in predictions",
    "text": "Uncertainty in predictions\nConfidence interval for the mean outcome: \\[\\large{\\hat{y} \\pm t_{n-2}^* \\times \\color{purple}{\\mathbf{SE}_{\\hat{\\boldsymbol{\\mu}}}}}\\]\n\nPrediction interval for an individual observation: \\[\\large{\\hat{y} \\pm t_{n-2}^* \\times \\color{purple}{\\mathbf{SE_{\\hat{y}}}}}\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#standard-errors",
    "href": "slides/06-slr-math-models.html#standard-errors",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard errors",
    "text": "Standard errors\nStandard error of the mean outcome: \\[SE_{\\hat{\\mu}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]\n\nStandard error of an individual outcome: \\[SE_{\\hat{y}} = \\hat{\\sigma}_\\epsilon\\sqrt{1 + \\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#standard-errors-1",
    "href": "slides/06-slr-math-models.html#standard-errors-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard errors",
    "text": "Standard errors\nStandard error of the mean outcome: \\[SE_{\\hat{\\mu}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]\nStandard error of an individual outcome: \\[SE_{\\hat{y}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\mathbf{\\color{purple}{\\Large{1}}} + \\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#confidence-interval",
    "href": "slides/06-slr-math-models.html#confidence-interval",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval",
    "text": "Confidence interval\nThe 95% confidence interval for the mean outcome:\n\nnew_house &lt;- tibble(area = 2800)\n\npredict(df_fit, new_house, interval = \"confidence\", level = 0.95) |&gt;\n  kable()\n\n\n\n\nfit\nlwr\nupr\n\n\n\n\n563205.5\n529351\n597060.1\n\n\n\n\n\n\nWe are 95% confident that mean sale price of Duke Forest houses that are 2,800 square feet is between $529,351 and $597,060."
  },
  {
    "objectID": "slides/06-slr-math-models.html#prediction-interval",
    "href": "slides/06-slr-math-models.html#prediction-interval",
    "title": "SLR: Mathematical models for inference",
    "section": "Prediction interval",
    "text": "Prediction interval\nThe 95% prediction interval for an individual outcome:\n\nnew_house &lt;- tibble(area = 2800)\n\npredict(df_fit, new_house, interval = \"prediction\", level = 0.95) |&gt;\n  kable()\n\n\n\n\nfit\nlwr\nupr\n\n\n\n\n563205.5\n226438.3\n899972.7\n\n\n\n\n\n\nWe are 95% confident that predicted sale price of a Duke Forest house that is 2,800 square feet is between $226,438 and $899,973."
  },
  {
    "objectID": "slides/06-slr-math-models.html#comparing-intervals",
    "href": "slides/06-slr-math-models.html#comparing-intervals",
    "title": "SLR: Mathematical models for inference",
    "section": "Comparing intervals",
    "text": "Comparing intervals"
  },
  {
    "objectID": "slides/06-slr-math-models.html#extrapolation",
    "href": "slides/06-slr-math-models.html#extrapolation",
    "title": "SLR: Mathematical models for inference",
    "section": "Extrapolation",
    "text": "Extrapolation\nUsing the model to predict for values outside the range of the original data is extrapolation.\n\n\n\n\nCalculate the prediction interval for the sale price of a “tiny house” in Duke Forest that is 225 square feet.\n\n\n\n\n\n\n\n\n\n\nNo, thanks!"
  },
  {
    "objectID": "slides/06-slr-math-models.html#next-class",
    "href": "slides/06-slr-math-models.html#next-class",
    "title": "SLR: Mathematical models for inference",
    "section": "Next class",
    "text": "Next class\n\nMultiple linear regression\nComplete Lecture 07 prepare"
  },
  {
    "objectID": "slides/06-slr-math-models.html#interpreting-the-test-statistic---make-a-submit-question",
    "href": "slides/06-slr-math-models.html#interpreting-the-test-statistic---make-a-submit-question",
    "title": "SLR: Mathematical models for inference",
    "section": "Interpreting the test statistic - Make a Submit question!",
    "text": "Interpreting the test statistic - Make a Submit question!\n\nThe test statistic is 8.78. What is the best interpretation?\n\nThe estimated slope of 159.48 is 8.78 standard errors away from the mean.\nThe estimated slope of 159.48 is 8.78 standard errors above the mean.\nThe estimated slope of 159.48 is 8.78 standard errors above 0, the hypothesized mean.\nThe estimated slope of 159.48 is 8.78 standard errors away from 0, the hypothesized mean."
  },
  {
    "objectID": "slides/06-slr-math-models.html#interpreting-the-p-value---make-a-submit-question",
    "href": "slides/06-slr-math-models.html#interpreting-the-p-value---make-a-submit-question",
    "title": "SLR: Mathematical models for inference",
    "section": "Interpreting the p-value - Make a submit question",
    "text": "Interpreting the p-value - Make a submit question\n\nWhat does the p-value mean in the context of the data?\n\nThe probability there is no linear relationship between area and price is approximately 0.\nGiven there is no linear relationship between area and price, the probability of observing a slope of 159.48 is approximately 0.\nGiven there is a linear relationship between area and price, the probability of observing a slope of 159.48 is approximately 0.\nGiven there is no linear relationship between area and price, the probability of observing a slope of 159.48 or more extreme is approximately 0."
  }
]