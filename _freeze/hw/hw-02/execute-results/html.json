{
  "hash": "e71eae4a0a16c8cb7906b4da6a18abcd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"HW 02: Multiple linear regression\" \neditor: visual\nexecute:\n  freeze: auto\n  echo: true\n  eval: false\n  warning: false\n  message: false\nbibliography: references.bib\n---\n\n::: callout-important\nThis assignment is due on **Tuesday, February 11 at 11:59pm.** To be considered on time, the following must be done by the due date:\n\n-   Final `.qmd` and `.pdf` files pushed to your GitHub repo\n\n-   Final `.pdf` file submitted on Gradescope\n:::\n\n# Introduction\n\nIn this analysis you will use multiple linear regression to fit and evaluate models using characteristics of LEGO sets to understand variability in the price.\n\n# Learning goals\n\nIn this assignment, you will...\n\n-   Conduct exploratory data analysis\n-   Create new variables\n-   Evaluate and compare models\n-   Use inference to draw conclusions\n-   Continue developing a workflow for reproducible data analysis\n\n# Getting started\n\n-   Go to the [sta210-sp25](https://www.github.com/sta210-sp25) organization on GitHub. Click on the repo with the prefix **hw-02**. It contains the starter documents you need to complete the lab.\n\n-   Clone the repo and start a new project in RStudio. See the [Lab 00](https://sta210-sp25.netlify.app/labs/lab-00#getting-started) for details on cloning a repo and starting a new project in R.\n\nThe following packages will be used in this assignment:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)  # for data wrangling \nlibrary(tidymodels) # for modeling and inference \nlibrary(knitr)      # to neatly format tables \nlibrary(patchwork)  # to arrange plots in a grid\n\n# load other packages as needed \n```\n:::\n\n\n# Data: LEGO sets\n\nThe data for this analysis includes information about LEGO sets from themes produced January 1, 2018 and September 11, 2020. The data were originally scraped from Brickset.com, an online LEGO set guide and were obtained for this assignment from @peterson2021.\n\nYou will work with data on about 400 randomly selected LEGO sets produced during this time period. The primary variables are interest in this analysis are\n\n-   `Amazon_Price`: Amazon price of the set scraped from brickset.com (in U.S. dollars)\n-   `Size`: General size of the interlocking bricks (Large = LEGO Duplo sets - which include large brick pieces safe for children ages 1 to 5, Small = LEGO sets which- include the traditional smaller brick pieces created for age groups 5 and - older, e.g., City, Friends)\n-   `Theme`: Theme of the LEGO set\n-   `Pages`: Number of pages in the instruction booklet\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlegos <- read_csv(\"data/lego-sample.csv\") |>\n  select(Size, Theme, Amazon_Price, Pages) |>\n  drop_na()\n```\n:::\n\n\n# Exercises[^1]\n\n[^1]: Exercise 9 is based on an exercise in @montgomery2021introduction .\n\n::: callout-important\nAll narrative should be written in complete sentences, and all visualizations should have informative titles and axis labels.\n:::\n\n## Exercise 1\n\nThere are some observations that have missing data for any of the variables of interest .\n\na.  Remove observations that have missing data for any of the variables of interest - `Size`, `Theme`, `Pages`, and `Amazon_Price`. Your updated data set will have 374 observations.\nb.  What is a disadvantage of dropping observations that have missing values, instead of using a method to impute, i.e., fill in, the missing data? How might dropping these observations impact the generalizability of conclusions?\n\n## Exercise 2\n\na.  Visualize the distributions of the predictor variables `Size` and `Pages`. Neatly arrange the plots using the [patchwork](https://patchwork.data-imaginist.com/index.html) package.\nb.  Use the plots in part (a) to write an observation about each distribution.\n\n## Exercise 3\n\nThe distribution of `Theme` is shown below. The bars are ordered by the frequency they occur in the data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlegos |>\n  count(Theme) |>\nggplot(aes(x = fct_reorder(Theme, n), y = n)) +\n  geom_col() + \n    labs(title = \"Lego Set Theme\", \n         x = \"Theme\", \n         y = \"Number of LEGO sets\") + \n  coord_flip()\n```\n\n::: {.cell-output-display}\n![](hw-02_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\na.  What is one reason we may want to avoid putting the variable `Theme` in a model as is?\nb.  We will create a new variable that collapses some of the levels of `Theme`. Make a new variable called `Theme_Col` that has levels for the top four most frequent themes, then the category `Other` for all other themes.\nc.  How many observations are in each level for the new variable created in part (b)?\n\n::: callout-note\nYou will use `Theme_Col`, the collapsed `Theme` variable, for the remainder of the assignment.\n:::\n\n## Exercise 4\n\na.  Fit a model using `Size`, `Pages`, and `Theme_Col` to predict `Amazon_Price`. Fit the model such that the intercept has a meaningful interpretation. Neatly display the model using three digits.\nb.  Interpret the intercept in the context of the data.\nc.  The model output suggests that as the number of pages in the instruction booklet increases, the price of the set on Amazon is expected to increase. On the surface, it does not seem that the number of pages in the booklet would be a major predictor of the price on Amazon. What do you think this variable is actually measuring or is actually representing?\n\n## Exercise 5\n\nNow let's consider a model that allows for different effects of pages based on theme.\n\na.  Make a plot that can be used to visualize the effect of pages on the Amazon.com price based on the theme.\nb.  Based on the plot in part (a), does the effect of the number of pages appear to differ based on theme? Briefly explain why or why not.\nc.  Modify the model from Exercise 4 such that the effect of the number of pages differs based on the theme. The intercept should still have a meaningful interpretation. Neatly display the model using three digits.\n\n## Exercise 6\n\na.  Describe the effect of pages for the baseline level in the context of the data.\nb.  Describe the effect of pages for LEGOS in the Star Wars theme in the context of the data.\nc.  Based on the p-values, do the data provide evidence that the effect of pages differs based on theme? Briefly explain. You can use a threshold of 0.05 for your assessment.\n\n## Exercise 7\n\na.  Compute RMSE for the model in Exercise 5. Interpret this value in the context of the data.\n\nb.  Compute $R^2$ for the model in Exercise 5. Interpret this value in the context of the data.\n\n## Perceived threat of COVID-19\n\n::: callout-important\nUse the following paper for Exercises 8 and 9.\n:::\n\n@garbe2020 aimed to examine the relationship between personality traits, perceived threat of Covid-19 and stockpiling toilet paper. For this study, researchers conducted an online survey March 23 - 29, 2020 and used the results to fit multiple linear regression models to draw conclusions about their research questions. From their survey, they collected data on adults across 35 countries. Given the small number of responses from people outside of the United States, Canada, and Europe, only responses from people in these three locations were included in the regression analysis.\n\nLet's consider their results for the model looking at the effect on **perceived threat of Covid-19**. The model can be found on page 6 of the paper. The perceived threat of Covid was quantified using the responses to the following survey question:\n\n> How threatened do you feel by Coronavirus? \\[Users select on a 10-point visual analogue scale (Not at all threatened to Extremely Threatened)\\]\n\nAs stated on page 5 of the paper \"*To ease interpretation, continuous variables were z-standardized and categorical variables were dummy-coded in all models.\"*\n\n[Click here](https://canvas.duke.edu/courses/47067/files/folder/articles?preview=2585026) to access a PDF of the paper.\n\n## Exercise 8\n\na.  Interpret the coefficient of Age (0.072) in the context of the analysis.\n\nb.  Interpret the coefficient of Place of residence in the context of the analysis. You can assume `Emotionality = 0` in the interpretation.\n\nc.  The model includes an interaction between Place of residence and Emotionality. The authors describe Emotionality as a measure of \"fearfulness, anxiety, dependence, sentimentality\". What does the coefficient for the interaction (0.101) mean in the context of the data?\n\n::: callout-important\nThe following are general questions about linear regression. They are not specific to any of the previous analyses.\n:::\n\n## Exercise 9\n\nProve that the maximum value of $R^2$ must be less than 1 if the data set contains observations such that there are different observed values of the response for the same value of the predictor (e.g., the data set contains observations $(x_i, y_i)$ and $(x_j, y_j)$ such that $x_i = x_j$ and $y_i \\neq y_j$ .\n\n## Exercise 10\n\nIn [lecture](https://sta210-sp25.netlify.app/slides/06-slr-math-models#/mathematical-representation-visualized) we discussed how the distribution of the error terms (and thus the distribution of the response variable $Y$) for a given value of the predictor $X$ has a variance of $\\sigma^2_{\\epsilon}$. Therefore, we are assuming this variance is the same for all values of the predictor when we conduct inference.\n\nBriefly explain why this assumption is important when we conduct inference based on mathematical models but is not necessary for conducting simulation-based inference.\n\n# Submission\n\n::: callout-warning\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\n\nRemember – you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n:::\n\nTo submit your assignment:\n\n-   Access Gradescope through the [STA 210 Canvas site](https://canvas.duke.edu/courses/47067).\n\n-   Click on the assignment, and you’ll be prompted to submit it.\n\n-   Mark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be “checked”).\n\n-   Select the first page of your .PDF submission to be associated with the *“Workflow & formatting”* section.\n\n# Grading (50 points)\n\n| Component             | Points |\n|-----------------------|--------|\n| Ex 1                  | 3      |\n| Ex 2                  | 5      |\n| Ex 3                  | 4      |\n| Ex 4                  | 6      |\n| Ex 5                  | 6      |\n| Ex 6                  | 6      |\n| Ex 7                  | 4      |\n| Ex 8                  | 6      |\n| Ex 9                  | 4      |\n| Ex 10                 | 3      |\n| Workflow & formatting | 3      |\n\nThe “Workflow & formatting” grade is to assess the reproducible workflow and document format for the applied exercises. This includes having at least 3 informative commit messages, a neatly organized document with readable code and your name and the date updated in the YAML.\n\n## References\n",
    "supporting": [
      "hw-02_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}