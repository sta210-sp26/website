{
  "hash": "a24177cf87c9547f59fef178e698b40a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"SLR: Permutation test for the slope\"\nauthor: \"Prof. Maria Tackett\"\ndate: \"01-22-2026\"\ndate-format: \"MMMM DD, YYYY\"\nfooter: \"ðŸ”— [sta210-sp26.github.io](https://sta210-sp26.github.io)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs: \n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: true\n    incremental: false \n    chalkboard: true\n    include-before: [ '<script type=\"text/x-mathjax-config\">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']\n  html: \n    output-file: 05-sim-testing-notes.html\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib\n---\n\n\n\n## Announcements\n\n-   HW 01 due Tuesday, January 27 at 11:59pm\n\n-   Labs resume Monday (stayed tuned for any weather related updates)\n\n## Topics\n\n-   Describe accuracy versus precision for confidence intervals\n\n<!-- -->\n\n-   Evaluate a claim about the slope using hypothesis testing\n\n-   Construct a null distribution using simulation\n\n-   Compute a p-value and use it to draw conclusions\n\n## Computational setup\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables\nlibrary(kableExtra)  # also for neatly formatted tablesf\n\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n```\n:::\n\n\n# Recap of last lecture\n\n## Data: Duke Forest houses\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-sim-testing_files/figure-revealjs/unnamed-chunk-1-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## The regression model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_fit <- lm(price ~ area, data = duke_forest)\n\ntidy(df_fit) |>\n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|term        |  estimate| std.error| statistic| p.value|\n|:-----------|---------:|---------:|---------:|-------:|\n|(Intercept) | 116652.33|  53302.46|      2.19|    0.03|\n|area        |    159.48|     18.17|      8.78|    0.00|\n\n\n:::\n:::\n\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n**Slope:** For each additional square foot, we expect the sale price of Duke Forest houses to be higher by $159, on average.\n\n## Inference for simple linear regression\n\n-   Calculate a confidence interval for the slope, $\\beta_1$\n\n-   Conduct a hypothesis test for the slope, $\\beta_1$\n\n## Statistical inference\n\n![Image source: Eugene Morgan Â© Penn State](images/04/inference.png){fig-align=\"center\"}\n\n## Sampling is natural {.midi}\n\n![](images/05/soup.png){fig-alt=\"Illustration of a bowl of soup\" fig-align=\"center\"}\n\n-   When you taste a spoonful of soup and decide the spoonful you tasted isn't salty enough, that's exploratory analysis\n-   If you generalize and conclude that your entire soup needs salt, that's an inference\n-   For your inference to be valid, the spoonful you tasted (the sample) needs to be representative of the entire pot (the population)\n\n## Confidence interval via bootstrapping\n\n-   Bootstrap new samples from the original sample\n-   Fit models to each of the samples and estimate the slope\n-   Use features of the distribution of the bootstrapped slopes to construct a confidence interval\n\n## Bootstrapping pipeline I\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|1|3|4\"}\nset.seed(210)\n\nduke_forest |>\n  specify(price ~ area)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 Ã— 2\n     price  area\n     <dbl> <dbl>\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# â„¹ 88 more rows\n```\n\n\n:::\n:::\n\n\n## Bootstrapping pipeline II\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|5\"}\nset.seed(210)\n\nduke_forest |>\n  specify(price ~ area) |>\n  generate(reps = 1000, type = \"bootstrap\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98,000 Ã— 3\n# Groups:   replicate [1,000]\n   replicate   price  area\n       <int>   <dbl> <dbl>\n 1         1  290000  2414\n 2         1  285000  2108\n 3         1  265000  1300\n 4         1  416000  2949\n 5         1  541000  2740\n 6         1  525000  2256\n 7         1 1270000  3909\n 8         1  265000  1300\n 9         1  815000  3904\n10         1  535000  2937\n# â„¹ 97,990 more rows\n```\n\n\n:::\n:::\n\n\n## Bootstrapping pipeline III\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|6\"}\nset.seed(210)\n\nduke_forest |>\n  specify(price ~ area) |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  fit()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2,000 Ã— 3\n# Groups:   replicate [1,000]\n   replicate term      estimate\n       <int> <chr>        <dbl>\n 1         1 intercept   80699.\n 2         1 area          168.\n 3         2 intercept  -18821.\n 4         2 area          205.\n 5         3 intercept  234297.\n 6         3 area          117.\n 7         4 intercept  134481.\n 8         4 area          150.\n 9         5 intercept   23861.\n10         5 area          190.\n# â„¹ 1,990 more rows\n```\n\n\n:::\n:::\n\n\n## Bootstrapping pipeline IV\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|3\"}\nset.seed(210)\n\nboot_dist <- duke_forest |>\n  specify(price ~ area) |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  fit()\n```\n:::\n\n\n## Visualize the bootstrap distribution\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|2\"}\nboot_dist |>\n  filter(term == \"area\") |>\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10)\n```\n\n::: {.cell-output-display}\n![](05-sim-testing_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Compute the CI\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-sim-testing_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## But first...\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nobs_fit <- duke_forest |>\n  specify(price ~ area) |>\n  fit()\n\nobs_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 2\n  term      estimate\n  <chr>        <dbl>\n1 intercept  116652.\n2 area          159.\n```\n\n\n:::\n:::\n\n\n## Compute 95% confidence interval {.midi}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nboot_dist |>\n  get_confidence_interval(\n    point_estimate = obs_fit,\n    level = 0.95,\n    type = \"percentile\"\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 3\n  term      lower_ci upper_ci\n  <chr>        <dbl>    <dbl>\n1 area          91.7     211.\n2 intercept -18290.   287711.\n```\n\n\n:::\n:::\n\n\n## Precision vs. accuracy\n\n::: question\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n:::\n\n. . .\n\n![](images/05/snow-forecast.jpg){fig-align=\"center\" width=\"50%\"}\n\n## Precision vs. accuracy\n\n::: question\nHow can we get best of both worlds -- high precision and high accuracy?\n:::\n\n<br>\n\n. . .\n\n::: question\nConsider a 90%, 95%, and 99% confidence interval.\n\n-   Which interval is most precise?\n-   Which is most accurate?\n:::\n\n## Changing confidence level {.midi}\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = obs_fit, \n  level = 0.90, type = \"percentile\"\n) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 3\n  term      lower_ci upper_ci\n  <chr>        <dbl>    <dbl>\n1 area          102.     206.\n2 intercept    5288.  264931.\n```\n\n\n:::\n\n```{.r .cell-code}\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = obs_fit, \n  level = 0.99, type = \"percentile\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 3\n  term      lower_ci upper_ci\n  <chr>        <dbl>    <dbl>\n1 area          65.4     229.\n2 intercept -47594.   362644.\n```\n\n\n:::\n:::\n\n\n# Hypothesis test for the slope\n\n## Research question and hypotheses\n\n\"Do the data provide sufficient evidence that $\\beta_1$ (the true population slope) is different from 0?\"\n\n. . .\n\n**Null hypothesis**: there is no linear relationship between `area` and `price`\n\n$$\nH_0: \\beta_1 = 0\n$$\n\n. . .\n\n**Alternative hypothesis**: there is a linear relationship between `area` and `price`\n\n$$\nH_a: \\beta_1 \\ne 0\n$$\n\n## Hypothesis testing as a US court trial\n\n::: incremental\n-   **Null hypothesis**, $H_0$: Defendant is innocent\n-   **Alternative hypothesis**, $H_a$: Defendant is guilty\n-   **Present the evidence:** Collect data\n-   **Judge the evidence:** \"Could these data plausibly have happened by chance if the null hypothesis were true?\"\n    -   Yes: Fail to reject $H_0$\n\n    -   No: Reject $H_0$\n:::\n\n## Hypothesis testing framework {.midi}\n\n::: incremental\n-   Start with a null hypothesis, $H_0$ that represents the status quo\n-   Set an alternative hypothesis, $H_a$ that represents the research question, i.e. claim we're testing\n-   Conduct a hypothesis test under the assumption that the null hypothesis is true and calculate a **p-value** (probability of getting the observed or a more extreme outcome given that the null hypothesis is true)\n    -   if the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\n    -   if they do, then reject the null hypothesis in favor of the alternative\n:::\n\n## Quantify the variability of the slope {.midi}\n\n**for testing**\n\n::: incremental\n-   Two approaches:\n    1.  Via simulation\n    2.  Via mathematical models\n-   Use **Permutation** to quantify the variability of the slope for the purpose of testing, *under the assumption that the null hypothesis is true*:\n    -   Simulate new samples from the original sample via permutation\n    -   Fit models to each of the samples and estimate the slope\n    -   Use features of the distribution of the permuted slopes to conduct a hypothesis test\n:::\n\n## Permutation, described {.smaller}\n\n::::: columns\n::: {.column width=\"40%\"}\n-   Use permuting to simulate data under the assumption the null hypothesis is true and measure the natural variability in the data due to sampling, [**not**]{.underline} due to variables being correlated\n    -   Permute one variable to eliminate any existing relationship between the variables\n-   Each `price` value is randomly assigned to the `area` of a given house, i.e. `area` and `price` are no longer matched for a given house\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 98 Ã— 3\n   price_Observed price_Permuted  area\n            <dbl>          <dbl> <dbl>\n 1        1520000         342500  6040\n 2        1030000         750000  4475\n 3         420000         645000  1745\n 4         680000         697500  2091\n 5         428500         428500  1772\n 6         456000         481000  1950\n 7        1270000         610000  3909\n 8         557450         680000  2841\n 9         697500         485000  3924\n10         650000         105000  2173\n# â„¹ 88 more rows\n```\n\n\n:::\n:::\n\n:::\n:::::\n\n## Permutation, visualized\n\n::::: columns\n::: {.column width=\"50%\"}\n-   Each of the observed values for `area` (and for `price`) exist in both the observed data plot as well as the permuted `price` plot\n-   The permutation removes the relationship between `area` and `price`\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-sim-testing_files/figure-revealjs/unnamed-chunk-15-1.png){fig-align='center' width=100%}\n:::\n:::\n\n:::\n:::::\n\n## Permutation, repeated\n\nRepeated permutations allow for quantifying the variability in the slope under the condition that there is no linear relationship (i.e., that the null hypothesis is true)\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-sim-testing_files/figure-revealjs/unnamed-chunk-16-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Concluding the hypothesis test {.smaller}\n\n::: question\nIs the observed slope of $\\hat{\\beta_1} = 159$ (or an even more extreme slope) a likely outcome under the null hypothesis that $\\beta = 0$? What does this mean for our original question: \"Do the data provide sufficient evidence that $\\beta_1$ (the true slope for the population) is different from 0?\"\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-sim-testing_files/figure-revealjs/unnamed-chunk-17-1.png){fig-align='center' width=60%}\n:::\n:::\n\n\n## Permutation pipeline I\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|1|3|4\"}\nset.seed(210)\n\nduke_forest |>\n  specify(price ~ area)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 Ã— 2\n     price  area\n     <dbl> <dbl>\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# â„¹ 88 more rows\n```\n\n\n:::\n:::\n\n\n## Permutation pipeline II\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|5\"}\nset.seed(210)\n\nduke_forest |>\n  specify(price ~ area) |>\n  hypothesize(null = \"independence\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: indepe...\n# A tibble: 98 Ã— 2\n     price  area\n     <dbl> <dbl>\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# â„¹ 88 more rows\n```\n\n\n:::\n:::\n\n\n## Permutation pipeline III\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|6\"}\nset.seed(210)\n\nduke_forest |>\n  specify(price ~ area) |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = 1000, type = \"permute\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: indepe...\n# A tibble: 98,000 Ã— 3\n# Groups:   replicate [1,000]\n     price  area replicate\n     <dbl> <dbl>     <int>\n 1  290000  6040         1\n 2  285000  4475         1\n 3  265000  1745         1\n 4  416000  2091         1\n 5  541000  1772         1\n 6  525000  1950         1\n 7 1270000  3909         1\n 8  490000  2841         1\n 9  535000  3924         1\n10  481000  2173         1\n# â„¹ 97,990 more rows\n```\n\n\n:::\n:::\n\n\n## Permutation pipeline IV\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|7\"}\nset.seed(210)\n\nduke_forest |>\n  specify(price ~ area) |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = 1000, type = \"permute\") |>\n  fit()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2,000 Ã— 3\n# Groups:   replicate [1,000]\n   replicate term        estimate\n       <int> <chr>          <dbl>\n 1         1 intercept 560741.   \n 2         1 area          -0.303\n 3         2 intercept 531330.   \n 4         2 area          10.3  \n 5         3 intercept 533014.   \n 6         3 area           9.67 \n 7         4 intercept 388765.   \n 8         4 area          61.6  \n 9         5 intercept 607389.   \n10         5 area         -17.1  \n# â„¹ 1,990 more rows\n```\n\n\n:::\n:::\n\n\n## Permutation pipeline V\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|3\"}\nset.seed(210)\n\nnull_dist <- duke_forest |>\n  specify(price ~ area) |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = 1000, type = \"permute\") |>\n  fit()\n```\n:::\n\n\n## Visualize the null distribution\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|2\"}\nnull_dist |>\n  filter(term == \"area\") |>\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10, color = \"white\")\n```\n\n::: {.cell-output-display}\n![](05-sim-testing_files/figure-revealjs/unnamed-chunk-23-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Reason around the p-value {.smaller}\n\n::: question\nIn a world where the there is no relationship between the area of a Duke Forest house and in its price ($\\beta_1 = 0$), what is the probability that we observe a sample of 98 houses where the slope fo the model predicting price from area is 159 or even more extreme?\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](05-sim-testing_files/figure-revealjs/unnamed-chunk-24-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Compute the p-value\n\n::: question\nWhat does this warning mean?\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nget_p_value(\n  null_dist,\n  obs_stat = obs_fit,\n  direction = \"two-sided\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Please be cautious in reporting a p-value of 0. This result is an approximation\nbased on the number of `reps` chosen in the `generate()` step.\nâ„¹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\nPlease be cautious in reporting a p-value of 0. This result is an approximation\nbased on the number of `reps` chosen in the `generate()` step.\nâ„¹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 2\n  term      p_value\n  <chr>       <dbl>\n1 area            0\n2 intercept       0\n```\n\n\n:::\n:::\n\n\n## p-value warning\n\n::::: panel-tabset\n## Question\n\n:::: midi\n::: appex\nWhat does the warning from R mean?\n:::\n\nðŸ”— <https://forms.office.com/r/Ji4YKVRwSj>\n::::\n\n## Submit\n\n```{=html}\n<center><iframe width=\"640px\" height=\"480px\" src=\"https://forms.office.com/r/Ji4YKVRwSj?embed=true\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" style=\"border: none; max-width:100%; max-height:100vh\" allowfullscreen webkitallowfullscreen mozallowfullscreen msallowfullscreen> </iframe></center>\n```\n:::::\n\n# Application exercise\n\n::: appex\nðŸ“‹ [https://sta210-sp26.github.io/ae/ae-05-sim-testing.html](../ae/ae-05-sim-testing.html)\n:::\n\n-   Find **ae-05** repo on GitHub\n\n## Recap\n\n-   Described accuracy versus precision for confidence intervals\n\n-   Evaluated a claim about the slope using hypothesis testing\n\n-   Constructed a null distribution using simulation\n\n-   Computed a p-value and use it to draw conclusions\n\n## For next class\n\n-   Inference using mathematical models\n\n-   Complete [Lecture 06 prepare](../prepare/prepare-lec06.html)\n",
    "supporting": [
      "05-sim-testing_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}